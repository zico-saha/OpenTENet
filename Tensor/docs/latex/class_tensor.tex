\doxysection{Tensor Class Reference}
\hypertarget{class_tensor}{}\label{class_tensor}\index{Tensor@{Tensor}}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_tensor_aec22e6d528af637133d7d17f1d7f8ad5}{Tensor}} (const std\+::vector$<$ int $>$ \&shape, double value=0)
\begin{DoxyCompactList}\small\item\em Constructs a \doxylink{class_tensor}{Tensor} with the specified shape, initialized with a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_a2b070e826df180db62c05d0cdfd85b43}{Tensor}} (const std\+::vector$<$ int $>$ \&shape, const std\+::vector$<$ double $>$ \&data)
\begin{DoxyCompactList}\small\item\em Constructs a \doxylink{class_tensor}{Tensor} from a specified shape and data vector. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_a127562a0fad3d73c672ef0c926a5df02}{Tensor}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em Copy constructor (performs a deep copy of the tensor). \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_ac9b2a793615586ac29b2e7215261b844}{Unique\+Data}} ()
\begin{DoxyCompactList}\small\item\em Ensures this \doxylink{class_tensor}{Tensor} has unique ownership of its data buffer. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \mbox{\hyperlink{class_tensor_a039914aee51bfae847dbe28209ad69ff}{operator\mbox{[}$\,$\mbox{]}}} (int index)
\begin{DoxyCompactList}\small\item\em Returns a proxy object for accessing and modifying a slice along the first dimension. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a63f36d923fe1a8bdfa5127dcdb606b35}{operator\mbox{[}$\,$\mbox{]}}} (int index) const
\begin{DoxyCompactList}\small\item\em Returns an independent copy of a slice along the first dimension (const version). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a0b7d70c72543fd055cdb101b73cec827}{operator=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em Assignment operator (deep copy semantics). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a47812d7a29b100dd87bcd67e91c64482}{operator+}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise addition of a scalar value to all tensor elements. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aaab66abb66d3aa8ac54b985cade60f7e}{operator-\/}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise subtraction of a scalar value from all tensor elements. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a6658b84a8e2b71220c7f55f8610e6bbe}{operator\texorpdfstring{$\ast$}{*}}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise multiplication of all tensor elements by a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ac7a5df6dc6c7857650e0adbf66b4c422}{operator/}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise division of all tensor elements by a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a6bee0bb8cea232b7f2a589e8d48a4d27}{operator+}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise addition of two tensors. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aef9ba3fe1189eb11d47cd8f1dd573a1b}{operator-\/}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise subtraction of two tensors. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a75728ffb3911510ebfb73c113d97f7ec}{operator\texorpdfstring{$\ast$}{*}}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise multiplication of two tensors (Hadamard product). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a4a881f8f18dbbb2aa29aeec5f81ec018}{operator/}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise division of two tensors. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a45a758479b01bfce56ca3c7bede0493b}{operator+=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise addition of a scalar value. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a7e6db16f013c048474b050fda7da2a01}{operator-\/=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise subtraction of a scalar value. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a81868ded9686e9083f30666e68fdef6e}{operator\texorpdfstring{$\ast$}{*}=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise multiplication by a scalar value. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a513698bd5959d9c531849c91ef8c4c6a}{operator/=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise division by a scalar value. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a634382ed2b871ed0476b7207cdbbbe15}{operator+=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise addition with another tensor. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a609462c373a6263269bfec6c305b38c3}{operator-\/=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise subtraction with another tensor. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a93f7554458d7ae9a3cad5dc76eb07027}{operator\texorpdfstring{$\ast$}{*}=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise multiplication with another tensor (Hadamard product). \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a21809015e47552d25e7330bd0707cb1d}{operator/=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise division by another tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a50ffbfbb2e300be5346c894226d72812}{Reshape}} (const std\+::vector$<$ int $>$ \&new\+\_\+shape) const
\begin{DoxyCompactList}\small\item\em Reshapes the \doxylink{class_tensor}{Tensor} to a new specified shape without changing data order. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aa5215a8751f54d02e66b38c4982537f9}{Expand\+Rank}} (int axis=0) const
\begin{DoxyCompactList}\small\item\em Expands the rank of the \doxylink{class_tensor}{Tensor} by inserting a dimension of size 1 at a specified axis. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ab580be2efba7d27e6b6da689eee4732e}{Flatten}} (int axis\+\_\+from, int axis\+\_\+upto) const
\begin{DoxyCompactList}\small\item\em Flattens a range of consecutive axes into a single dimension. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_acdf40158e4bd7edd14f59bfc2c52ff92}{Slice}} (int axis, int index) const
\begin{DoxyCompactList}\small\item\em Extracts a slice of the \doxylink{class_tensor}{Tensor} along a specified axis at a given index. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ad2a6207e2f4dcb9571e4530490fcd439}{Slice}} (int axis, int index\+\_\+from, int index\+\_\+upto) const
\begin{DoxyCompactList}\small\item\em Extracts a range of slices from the \doxylink{class_tensor}{Tensor} along a given axis. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_a91a2c79fe15521fb9a3742da4263f60c}{Append}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor, int axis=-\/1)
\begin{DoxyCompactList}\small\item\em Appends a lower-\/rank \doxylink{class_tensor}{Tensor} along a specified axis (in-\/place operation). \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_aee9562ed6e3368ac6cd664373556cca4}{Insert}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor, int axis=-\/1, int index=0)
\begin{DoxyCompactList}\small\item\em Inserts a lower-\/rank \doxylink{class_tensor}{Tensor} at a specific position along an axis (in-\/place operation). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_af7dda240cea62631125c2272e38ffaa1}{Pad}} (int axis, int pad\+\_\+before\+\_\+size, int pad\+\_\+after\+\_\+size, double value=0.\+0) const
\begin{DoxyCompactList}\small\item\em Adds padding elements before and/or after the tensor along a specified axis. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a52b3acaaf5f1d9bad285fd7ae88399ac}{Tile}} (const std\+::vector$<$ int $>$ \&repetitions) const
\begin{DoxyCompactList}\small\item\em Repeats the entire tensor structure along each axis a specified number of times. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aa5fba58b033578d704f4634977982c66}{Broadcast}} (const std\+::vector$<$ int $>$ \&shape) const
\begin{DoxyCompactList}\small\item\em Broadcasts the tensor to a target shape following Num\+Py-\/style broadcasting rules. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a699a4b1ec7d7d244e7c10643bf533f98}{Transpose}} (const std\+::vector$<$ int $>$ \&permutation) const
\begin{DoxyCompactList}\small\item\em Transposes (permutes) the tensor\textquotesingle{}s axes according to a specified permutation. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a0adf81cbee9f45641c9c3bd70ec5c2b4}{Mat\+Mul}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Performs matrix multiplication with another tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ae88a978596e4f4d82ca5a27b8b79073f}{Convolve}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&filter, const std\+::vector$<$ int $>$ \&strides, const std\+::vector$<$ int $>$ \&padding)
\begin{DoxyCompactList}\small\item\em Performs N-\/dimensional convolution between this tensor and a filter kernel. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ad378cc1c1af81074204c05bc0ff4f00d}{Max\+Pool}} (const std\+::vector$<$ int $>$ \&pool\+\_\+shape, const std\+::vector$<$ int $>$ \&strides=\{\})
\begin{DoxyCompactList}\small\item\em Performs max pooling operation by taking the maximum value within sliding windows. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ad1f64c43e7267629a150a2cc7d7ad75b}{Min\+Pool}} (const std\+::vector$<$ int $>$ \&pool\+\_\+shape, const std\+::vector$<$ int $>$ \&strides=\{\})
\begin{DoxyCompactList}\small\item\em Performs min pooling operation by taking the minimum value within sliding windows. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a40fb78ab8fbcfab0ab57eeaa5c05676a}{Avg\+Pool}} (const std\+::vector$<$ int $>$ \&pool\+\_\+shape, const std\+::vector$<$ int $>$ \&strides=\{\})
\begin{DoxyCompactList}\small\item\em Performs average pooling operation by computing the mean value within sliding windows. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_af2642442d55d275a7a21fca2e3dfb4b5}{Sign}} (bool heaviside=false) const
\begin{DoxyCompactList}\small\item\em Computes the sign function element-\/wise. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a34014716594913b10f8c606c0b0389de}{Reduce\+Sum}} (int axis=0) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the sum. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a279fd0fb9be2315140b21feeb2e51034}{Reduce\+Mean}} (int axis=0) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the mean (average). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aa5366dcad0b31362b2c4a42c7452adcf}{Reduce\+Var}} (int axis=0, bool inference=false) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the variance. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a4f4b299f874a72509a053c270bbb0aa9}{Reduce\+Max}} (int axis=0) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the maximum. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a3e92b91cfe84cfd666751d7f5431a642}{Reduce\+Min}} (int axis=0) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the minimum. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_adb9ce076a4629b3bbc897e17f39b7573}{Sum}} () const
\begin{DoxyCompactList}\small\item\em Computes the sum of all elements in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_aac4651bb52521e86e875d2e8c1e8643a}{Mean}} () const
\begin{DoxyCompactList}\small\item\em Computes the mean (average) of all elements in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_aceb3777b0c462d3596781b6031a234b6}{Var}} (bool inference=false) const
\begin{DoxyCompactList}\small\item\em Computes the variance of all elements in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_a46e3d36946b41f93fef4b0edcc48ba2e}{Max}} () const
\begin{DoxyCompactList}\small\item\em Finds the maximum value in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_a759daa212e3786fda070af4732f3ee15}{Min}} () const
\begin{DoxyCompactList}\small\item\em Finds the minimum value in the tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aa9330e265d36beb2e217c75f6a03a41e}{Abs}} () const
\begin{DoxyCompactList}\small\item\em Computes the absolute value of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a6ecaeb0e29c326798d82d6a2cccc28cf}{Floor}} () const
\begin{DoxyCompactList}\small\item\em Rounds each element down to the nearest integer (floor function). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ac1228f81de00883e64f49ee19e7d6021}{Ceil}} () const
\begin{DoxyCompactList}\small\item\em Rounds each element up to the nearest integer (ceiling function). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a0f50736794c3594411fe96aeb337b7b5}{Round}} (int decimal\+\_\+place=0) const
\begin{DoxyCompactList}\small\item\em Rounds each element to a specified number of decimal places. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a7de1cf7ec97265fcb0f776ea47fd9236}{Clip}} (double min\+\_\+value, double max\+\_\+value) const
\begin{DoxyCompactList}\small\item\em Clips (clamps) each element to be within a specified range. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a0bb8eea690681cb13ffbe53fa66d7183}{Power}} (double exponent) const
\begin{DoxyCompactList}\small\item\em Raises each element to a specified power (exponentiation). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a4c7df16dc4a4fc10cbdf5bfa20e25ba7}{Sqrt}} () const
\begin{DoxyCompactList}\small\item\em Computes the square root of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a40481e1178fdb80dae8934a8ed75adbb}{Log}} (double base=std\+::numbers\+::e) const
\begin{DoxyCompactList}\small\item\em Computes the logarithm of each element with a specified base. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ae9f79fc49610fe4ba20ade7d3cbafe30}{Exp}} () const
\begin{DoxyCompactList}\small\item\em Computes e raised to the power of each element (exponential function). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aafd911eab8af5c4ec79593d67f7823df}{Mod}} (double mod\+\_\+value) const
\begin{DoxyCompactList}\small\item\em Computes the modulus (remainder) of each element divided by a value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a7183546c868b2cac8075f0434376dccb}{Sin}} () const
\begin{DoxyCompactList}\small\item\em Computes the sine of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a9f691219cdb0a10a8111db8573128666}{Cos}} () const
\begin{DoxyCompactList}\small\item\em Computes the cosine of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a8148f97acf80f5e6aa685544ecc22be2}{Tan}} () const
\begin{DoxyCompactList}\small\item\em Computes the tangent of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a0dfe79c9b87996847a2c898578c240ff}{Csc}} () const
\begin{DoxyCompactList}\small\item\em Computes the cosecant (reciprocal of sine) of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a85eaa3e12b1a044e82d5f5912460aee8}{Sec}} () const
\begin{DoxyCompactList}\small\item\em Computes the secant (reciprocal of cosine) of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a9cff3aed7469fd72059da70444170b41}{Cot}} () const
\begin{DoxyCompactList}\small\item\em Computes the cotangent (reciprocal of tangent) of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ae58831c074bbc7eec61f1ea6a1644d91}{Asin}} () const
\begin{DoxyCompactList}\small\item\em Computes the arcsine (inverse sine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a8639798951ac43fcf9edbb510b65dd5b}{Acos}} () const
\begin{DoxyCompactList}\small\item\em Computes the arccosine (inverse cosine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_af9cb1919c5b966567b5d7d485b24dc56}{Atan}} () const
\begin{DoxyCompactList}\small\item\em Computes the arctangent (inverse tangent) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a7fe84551eed81225a551e784bd528f8c}{Acsc}} () const
\begin{DoxyCompactList}\small\item\em Computes the arccosecant (inverse cosecant) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aeb8b24b1035217d354520b1aa16117e7}{Asec}} () const
\begin{DoxyCompactList}\small\item\em Computes the arcsecant (inverse secant) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a769bd806f3e8a44ccb621b548f617505}{Acot}} () const
\begin{DoxyCompactList}\small\item\em Computes the arccotangent (inverse cotangent) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a2cbc29f90925cf18d54d62d9cc6ebbe3}{Sinh}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic sine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a65a86d44bf78501dbdcaa52ba72d7bd3}{Cosh}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic cosine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_aee8ad1fde49129b199ad87b4dd85c07f}{Tanh}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic tangent of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a2ddab39bf92ee11ab318b3d3374b391c}{Csch}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a03d0593a8715bad32098cbda433451f1}{Sech}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a4b4030aa4413ca8c4714526965986657}{Coth}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a7d4ff3c3c4775b55bd8fc94d9d3e4479}{Asinh}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic sine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a626ba6c6dc620d5de32c6bc81a594381}{Acosh}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic cosine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ad6e896aed6bc70bfe19fb1f9cd2d527d}{Atanh}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic tangent of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ada3b749b1a67fedb986ff69a05350c63}{Acsch}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic cosecant of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a5144a947b733c6ca5a5dcc5430f8df29}{Asech}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic secant of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_ad24f26852c9f77f4924bb7f921c470fd}{Acoth}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic cotangent of each element. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{class_tensor_ae00c340a459f86d5053466a73ef210e4}{Rank}} () const
\begin{DoxyCompactList}\small\item\em Returns the rank (number of dimensions) of the tensor. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{class_tensor_ad7155b38d35344550fde1eeb7f0fbd61}{Volume}} () const
\begin{DoxyCompactList}\small\item\em Returns the total number of elements (volume) in the tensor. \end{DoxyCompactList}\item 
std\+::vector$<$ int $>$ \mbox{\hyperlink{class_tensor_adb8cd0e538a8410157ca2a17a5055f02}{Shape}} () const
\begin{DoxyCompactList}\small\item\em Returns the shape of the tensor as a vector of dimension sizes. \end{DoxyCompactList}\item 
bool \mbox{\hyperlink{class_tensor_a767884250837a4894e6d8b592a9d3450}{Is\+Empty}} () const
\begin{DoxyCompactList}\small\item\em Checks whether the tensor contains no elements. \end{DoxyCompactList}\item 
bool \mbox{\hyperlink{class_tensor_a203a74ae4428ecadfd1efbebd85d753d}{Is\+Scalar}} () const
\begin{DoxyCompactList}\small\item\em Checks whether the tensor represents a scalar (single) value. \end{DoxyCompactList}\item 
\Hypertarget{class_tensor_a5fe1cfdcbe51b9df6f87b9f07f98f0ff}\label{class_tensor_a5fe1cfdcbe51b9df6f87b9f07f98f0ff} 
void {\bfseries Clear} ()
\item 
void \mbox{\hyperlink{class_tensor_a5e012653a230fcafd531ac6063e0067a}{Print}} (int depth=0) const
\begin{DoxyCompactList}\small\item\em Prints the tensor contents to standard output in a readable, nested format. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_ad3b998f18ac3263bf5e02b88026a166f}{To\+Scalar}} () const
\begin{DoxyCompactList}\small\item\em Converts a scalar tensor to a double value. \end{DoxyCompactList}\item 
std\+::vector$<$ double $>$ \mbox{\hyperlink{class_tensor_a577b089b89971b6ab7a1bfab790e4edc}{To\+Vector}} () const
\begin{DoxyCompactList}\small\item\em Converts a rank-\/1 tensor to a standard vector. \end{DoxyCompactList}\item 
std\+::vector$<$ std\+::vector$<$ double $>$ $>$ \mbox{\hyperlink{class_tensor_abd4b0bfabe2a7c378318d6132ec84936}{To\+Matrix}} () const
\begin{DoxyCompactList}\small\item\em Converts a rank-\/2 tensor to a 2D vector (matrix). \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsubsection*{Static Public Member Functions}
\begin{DoxyCompactItemize}
\item 
static \mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a4d525a3d5051c3a704db5a254b654706}{Concat}} (const std\+::vector$<$ \mbox{\hyperlink{class_tensor}{Tensor}} $>$ \&tensors, int axis=-\/1)
\begin{DoxyCompactList}\small\item\em Concatenates multiple Tensors along a specified axis. \end{DoxyCompactList}\item 
static \mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a7d2ad35ec705991518a2ecbec8ffd318}{Stack}} (const std\+::vector$<$ \mbox{\hyperlink{class_tensor}{Tensor}} $>$ \&tensors, int axis=0)
\begin{DoxyCompactList}\small\item\em Stacks multiple Tensors along a new dimension. \end{DoxyCompactList}\item 
static \mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_a33ee78056cb83d4381fdcbe3c79cde96}{Mat\+Mul}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor\+\_\+1, const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor\+\_\+2)
\begin{DoxyCompactList}\small\item\em Performs matrix multiplication between two tensors with automatic broadcasting. \end{DoxyCompactList}\item 
static \mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_abde6f09589147296a9035bce10cc8c49}{Tensor\+Dot}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor\+\_\+1, const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor\+\_\+2, const std\+::vector$<$ int $>$ \&contract\+\_\+axes\+\_\+1, const std\+::vector$<$ int $>$ \&contract\+\_\+axes\+\_\+2)
\begin{DoxyCompactList}\small\item\em Performs generalized tensor contraction over specified axes. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsubsection*{Friends}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{class_tensor_a290d8628c199bad78fb29560685327bf}\label{class_tensor_a290d8628c199bad78fb29560685327bf} 
class {\bfseries Tensor\+Slice}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}


\label{doc-constructors}
\Hypertarget{class_tensor_doc-constructors}
\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{class_tensor_aec22e6d528af637133d7d17f1d7f8ad5}\index{Tensor@{Tensor}!Tensor@{Tensor}}
\index{Tensor@{Tensor}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Tensor()}{Tensor()}\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \label{class_tensor_aec22e6d528af637133d7d17f1d7f8ad5} 
Tensor\+::\+Tensor (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{shape}{, }\item[{double}]{value}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Constructs a \doxylink{class_tensor}{Tensor} with the specified shape, initialized with a scalar value. 

This constructor creates a new \doxylink{class_tensor}{Tensor} with the given shape dimensions and fills all elements with the provided scalar value. It handles both scalar tensors (rank-\/0, empty shape) and multi-\/dimensional tensors.

For scalar tensors (empty shape), a rank-\/0 tensor is created containing a single value. For multi-\/dimensional tensors, all elements are initialized to the same value.


\begin{DoxyParams}{Parameters}
{\em shape} & A vector of positive integers representing the tensor dimensions. For a scalar tensor, pass an empty vector {\ttfamily \{\}}. For example\+: {\ttfamily \{2, 3, 4\}} creates a 2{\ucr}3{\ucr}4 tensor.\\
\hline
{\em value} & The scalar value used to initialize all elements. Default is 0.\+0. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A newly constructed \doxylink{class_tensor}{Tensor} object.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The value is NaN or infinity.
\item The shape contains non-\/positive dimensions (i.\+e., any dimension ? 0).
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if the total volume (product of all dimensions) exceeds INT\+\_\+\+MAX, indicating potential memory overflow.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
The tensor\textquotesingle{}s internal data is stored in row-\/major order. Strides are automatically computed from the shape. 
\end{DoxyNote}
\Hypertarget{class_tensor_a2b070e826df180db62c05d0cdfd85b43}\index{Tensor@{Tensor}!Tensor@{Tensor}}
\index{Tensor@{Tensor}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Tensor()}{Tensor()}\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \label{class_tensor_a2b070e826df180db62c05d0cdfd85b43} 
Tensor\+::\+Tensor (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{shape}{, }\item[{const std\+::vector$<$ double $>$ \&}]{data}{}\end{DoxyParamCaption})}



Constructs a \doxylink{class_tensor}{Tensor} from a specified shape and data vector. 

This constructor creates a new \doxylink{class_tensor}{Tensor} by combining shape metadata with raw data. The provided data vector is copied into the tensor\textquotesingle{}s internal shared storage. All data elements are validated to ensure they are finite values.

For scalar tensors (empty shape), the data vector must contain exactly one element. For multi-\/dimensional tensors, the total number of elements in the data vector must match the volume implied by the shape (product of all dimensions).


\begin{DoxyParams}{Parameters}
{\em shape} & A vector of positive integers representing the tensor dimensions. For a scalar tensor, pass an empty vector {\ttfamily \{\}}. For example\+: {\ttfamily \{2, 3, 4\}} creates a 2{\ucr}3{\ucr}4 tensor.\\
\hline
{\em data} & A vector of doubles containing all tensor elements in row-\/major order. Must be non-\/empty and contain only finite values (no NaN or infinity). The size must equal the volume computed from the shape.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A newly constructed \doxylink{class_tensor}{Tensor} object with independent data ownership.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The data vector is empty.
\item The data contains NaN or infinity values.
\item The shape contains non-\/positive dimensions (i.\+e., any dimension ? 0).
\item For scalar tensors (empty shape), data contains more than one element.
\item The shape volume does not match the data size.
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if the total volume (product of all dimensions) exceeds INT\+\_\+\+MAX, indicating potential memory overflow.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
The data is copied, so modifications to the original vector do not affect the tensor. Internal strides are automatically computed from the shape. Data is stored in row-\/major order. 
\end{DoxyNote}
\Hypertarget{class_tensor_a127562a0fad3d73c672ef0c926a5df02}\index{Tensor@{Tensor}!Tensor@{Tensor}}
\index{Tensor@{Tensor}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Tensor()}{Tensor()}\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \label{class_tensor_a127562a0fad3d73c672ef0c926a5df02} 
Tensor\+::\+Tensor (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



Copy constructor (performs a deep copy of the tensor). 

Creates a new \doxylink{class_tensor}{Tensor} that is completely independent from the source tensor. All metadata (rank, shape, strides) is copied, and the data is deep copied into a new shared storage buffer. Modifying the new tensor does not affect the original tensor in any way.

If the source tensor is a view (a slice of another tensor), only the visible data range {\ttfamily \mbox{[}start, end)} is copied, not the entire underlying buffer. The resulting tensor is always a complete, standalone tensor (never a view).


\begin{DoxyParams}{Parameters}
{\em tensor} & The source \doxylink{class_tensor}{Tensor} to copy from.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A newly constructed \doxylink{class_tensor}{Tensor} object with independent data ownership.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This is a {\bfseries{deep copy operation}}. For large tensors, this can be expensive in terms of both time and memory. If you need to avoid copying, consider using the indexing operator {\ttfamily \mbox{[}\mbox{]}} which returns a view (for const tensors) or using explicit move semantics if available.

The resulting tensor always has {\ttfamily start = 0} and {\ttfamily end = volume}, meaning it is never a view of another tensor\textquotesingle{}s data. 
\end{DoxyNote}


\label{doc-func-members}
\Hypertarget{class_tensor_doc-func-members}
\doxysubsection{Member Function Documentation}
\Hypertarget{class_tensor_aa9330e265d36beb2e217c75f6a03a41e}\index{Tensor@{Tensor}!Abs@{Abs}}
\index{Abs@{Abs}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Abs()}{Abs()}}
{\footnotesize\ttfamily \label{class_tensor_aa9330e265d36beb2e217c75f6a03a41e} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Abs (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the absolute value of each element. 

Returns a new tensor where each element is the absolute value (magnitude) of the corresponding element in the original tensor. For any value x, the result is \texorpdfstring{$\vert$}{|}x\texorpdfstring{$\vert$}{|}, which is always non-\/negative.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing absolute values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a8639798951ac43fcf9edbb510b65dd5b}\index{Tensor@{Tensor}!Acos@{Acos}}
\index{Acos@{Acos}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Acos()}{Acos()}}
{\footnotesize\ttfamily \label{class_tensor_a8639798951ac43fcf9edbb510b65dd5b} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Acos (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arccosine (inverse cosine) of each element. 

Returns a new tensor where each element is the arccosine of the corresponding element in the original tensor. The result is in radians in the range \mbox{[}0, π\mbox{]}.

The arccosine function is only defined for input values in the range \mbox{[}-\/1, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arccosine values in radians, ranging from 0 to π.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is outside the range \mbox{[}-\/1, 1\mbox{]}.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/π. 
\end{DoxyNote}
\Hypertarget{class_tensor_a626ba6c6dc620d5de32c6bc81a594381}\index{Tensor@{Tensor}!Acosh@{Acosh}}
\index{Acosh@{Acosh}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Acosh()}{Acosh()}}
{\footnotesize\ttfamily \label{class_tensor_a626ba6c6dc620d5de32c6bc81a594381} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Acosh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic cosine of each element. 

Returns a new tensor where each element is the inverse hyperbolic cosine (also called area hyperbolic cosine) of the corresponding element in the original tensor. It is defined as\+: acosh(x) = ln(x + sqrt(x² -\/ 1))

The inverse hyperbolic cosine is only defined for values ≥ 1.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic cosine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is less than 1 (where acosh is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a769bd806f3e8a44ccb621b548f617505}\index{Tensor@{Tensor}!Acot@{Acot}}
\index{Acot@{Acot}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Acot()}{Acot()}}
{\footnotesize\ttfamily \label{class_tensor_a769bd806f3e8a44ccb621b548f617505} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Acot (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arccotangent (inverse cotangent) of each element. 

Returns a new tensor where each element is the arccotangent of the corresponding element in the original tensor. The result is in radians in the range (0, π).

The arccotangent function is defined for all real numbers. For zero, it returns π/2. For negative values, the result is adjusted to maintain the range \mbox{[}0, π\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arccotangent values in radians, ranging from 0 to π.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/π. 
\end{DoxyNote}
\Hypertarget{class_tensor_ad24f26852c9f77f4924bb7f921c470fd}\index{Tensor@{Tensor}!Acoth@{Acoth}}
\index{Acoth@{Acoth}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Acoth()}{Acoth()}}
{\footnotesize\ttfamily \label{class_tensor_ad24f26852c9f77f4924bb7f921c470fd} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Acoth (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic cotangent of each element. 

Returns a new tensor where each element is the inverse hyperbolic cotangent of the corresponding element in the original tensor. It is computed as\+: acoth(x) = atanh(1/x)

The inverse hyperbolic cotangent is only defined for values in (-\/∞, -\/1) ∪ (1, ∞). Values in the range \mbox{[}-\/1, 1\mbox{]} are undefined.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic cotangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is in the range \mbox{[}-\/1, 1\mbox{]} (where acoth is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a7fe84551eed81225a551e784bd528f8c}\index{Tensor@{Tensor}!Acsc@{Acsc}}
\index{Acsc@{Acsc}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Acsc()}{Acsc()}}
{\footnotesize\ttfamily \label{class_tensor_a7fe84551eed81225a551e784bd528f8c} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Acsc (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arccosecant (inverse cosecant) of each element. 

Returns a new tensor where each element is the arccosecant of the corresponding element in the original tensor. The result is in radians.

The arccosecant function is only defined for values in (-\/∞, -\/1\mbox{]} ∪ \mbox{[}1, ∞). It is computed as asin(1/x).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arccosecant values in radians.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is in the range (-\/1, 1), where arccosecant is undefined.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/π. 
\end{DoxyNote}
\Hypertarget{class_tensor_ada3b749b1a67fedb986ff69a05350c63}\index{Tensor@{Tensor}!Acsch@{Acsch}}
\index{Acsch@{Acsch}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Acsch()}{Acsch()}}
{\footnotesize\ttfamily \label{class_tensor_ada3b749b1a67fedb986ff69a05350c63} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Acsch (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic cosecant of each element. 

Returns a new tensor where each element is the inverse hyperbolic cosecant of the corresponding element in the original tensor. It is computed as\+: acsch(x) = asinh(1/x)

The inverse hyperbolic cosecant is undefined at zero.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic cosecant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately zero (where acsch is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a91a2c79fe15521fb9a3742da4263f60c}\index{Tensor@{Tensor}!Append@{Append}}
\index{Append@{Append}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Append()}{Append()}}
{\footnotesize\ttfamily \label{class_tensor_a91a2c79fe15521fb9a3742da4263f60c} 
void Tensor\+::\+Append (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{, }\item[{int}]{axis}{ = {\ttfamily -\/1}}\end{DoxyParamCaption})}



Appends a lower-\/rank \doxylink{class_tensor}{Tensor} along a specified axis (in-\/place operation). 

This method appends a \doxylink{class_tensor}{Tensor} of rank {\ttfamily n-\/1} to the current \doxylink{class_tensor}{Tensor} of rank {\ttfamily n} by inserting it along a specified axis. The appended tensor must match all dimensions of the current tensor except for the append axis, where the dimension is increased by 1.

The operation modifies the current \doxylink{class_tensor}{Tensor} in-\/place by\+:
\begin{DoxyEnumerate}
\item Ensuring unique data ownership (calls \doxylink{class_tensor_ac9b2a793615586ac29b2e7215261b844}{Unique\+Data()}).
\item Interleaving the new tensor\textquotesingle{}s data at the appropriate positions.
\item Updating shape, strides, and volume metadata.
\end{DoxyEnumerate}

If axis is -\/1 (default), the method automatically determines the axis by finding the dimension mismatch between the two tensors\textquotesingle{} shapes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The \doxylink{class_tensor}{Tensor} to append. Must have rank = {\ttfamily this-\/\texorpdfstring{$>$}{>}rank -\/ 1}. All dimensions except the append axis must match the current tensor\textquotesingle{}s shape.\\
\hline
{\em axis} & The axis along which to append. Default is -\/1 (auto-\/detect). Must satisfy\+: {\ttfamily -\/1 ≤ axis \texorpdfstring{$<$}{<} rank}. If -\/1, the axis is inferred from the shape mismatch.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is less than -\/1 or \texorpdfstring{$>$}{>}= rank.\\
\hline
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The tensor\textquotesingle{}s rank is not exactly {\ttfamily rank -\/ 1}.
\item The shapes are not compatible for appending along the specified axis.
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if the resulting shape volume exceeds INT\+\_\+\+MAX.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an {\bfseries{in-\/place operation}} that modifies the current \doxylink{class_tensor}{Tensor}. The original data is replaced with the merged result.

This method calls \doxylink{class_tensor_ac9b2a793615586ac29b2e7215261b844}{Unique\+Data()} to ensure safe modification without affecting other tensors that might share the data buffer. 
\end{DoxyNote}
\Hypertarget{class_tensor_aeb8b24b1035217d354520b1aa16117e7}\index{Tensor@{Tensor}!Asec@{Asec}}
\index{Asec@{Asec}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Asec()}{Asec()}}
{\footnotesize\ttfamily \label{class_tensor_aeb8b24b1035217d354520b1aa16117e7} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Asec (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arcsecant (inverse secant) of each element. 

Returns a new tensor where each element is the arcsecant of the corresponding element in the original tensor. The result is in radians.

The arcsecant function is only defined for values in (-\/∞, -\/1\mbox{]} ∪ \mbox{[}1, ∞). It is computed as acos(1/x).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arcsecant values in radians.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is in the range (-\/1, 1), where arcsecant is undefined.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/π. 
\end{DoxyNote}
\Hypertarget{class_tensor_a5144a947b733c6ca5a5dcc5430f8df29}\index{Tensor@{Tensor}!Asech@{Asech}}
\index{Asech@{Asech}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Asech()}{Asech()}}
{\footnotesize\ttfamily \label{class_tensor_a5144a947b733c6ca5a5dcc5430f8df29} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Asech (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic secant of each element. 

Returns a new tensor where each element is the inverse hyperbolic secant of the corresponding element in the original tensor. It is computed as\+: asech(x) = acosh(1/x)

The inverse hyperbolic secant is only defined for values in the range (0, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic secant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is ≤ 0 or \texorpdfstring{$>$}{>} 1 (where asech is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_ae58831c074bbc7eec61f1ea6a1644d91}\index{Tensor@{Tensor}!Asin@{Asin}}
\index{Asin@{Asin}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Asin()}{Asin()}}
{\footnotesize\ttfamily \label{class_tensor_ae58831c074bbc7eec61f1ea6a1644d91} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Asin (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arcsine (inverse sine) of each element. 

Returns a new tensor where each element is the arcsine of the corresponding element in the original tensor. The result is in radians in the range \mbox{[}-\/π/2, π/2\mbox{]}.

The arcsine function is only defined for input values in the range \mbox{[}-\/1, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arcsine values in radians, ranging from -\/π/2 to π/2.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is outside the range \mbox{[}-\/1, 1\mbox{]}.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/π. 
\end{DoxyNote}
\Hypertarget{class_tensor_a7d4ff3c3c4775b55bd8fc94d9d3e4479}\index{Tensor@{Tensor}!Asinh@{Asinh}}
\index{Asinh@{Asinh}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Asinh()}{Asinh()}}
{\footnotesize\ttfamily \label{class_tensor_a7d4ff3c3c4775b55bd8fc94d9d3e4479} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Asinh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic sine of each element. 

Returns a new tensor where each element is the inverse hyperbolic sine (also called area hyperbolic sine) of the corresponding element in the original tensor. It is defined as\+: asinh(x) = ln(x + sqrt(x² + 1))

The inverse hyperbolic sine is defined for all real numbers.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic sine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_af9cb1919c5b966567b5d7d485b24dc56}\index{Tensor@{Tensor}!Atan@{Atan}}
\index{Atan@{Atan}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Atan()}{Atan()}}
{\footnotesize\ttfamily \label{class_tensor_af9cb1919c5b966567b5d7d485b24dc56} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Atan (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arctangent (inverse tangent) of each element. 

Returns a new tensor where each element is the arctangent of the corresponding element in the original tensor. The result is in radians in the range (-\/π/2, π/2).

The arctangent function is defined for all real numbers.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arctangent values in radians, ranging from -\/π/2 to π/2.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/π. 
\end{DoxyNote}
\Hypertarget{class_tensor_ad6e896aed6bc70bfe19fb1f9cd2d527d}\index{Tensor@{Tensor}!Atanh@{Atanh}}
\index{Atanh@{Atanh}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Atanh()}{Atanh()}}
{\footnotesize\ttfamily \label{class_tensor_ad6e896aed6bc70bfe19fb1f9cd2d527d} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Atanh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic tangent of each element. 

Returns a new tensor where each element is the inverse hyperbolic tangent (also called area hyperbolic tangent) of the corresponding element in the original tensor. It is defined as\+: atanh(x) = 0.\+5 × ln((1 + x) / (1 -\/ x))

The inverse hyperbolic tangent is only defined for values in the open interval (-\/1, 1).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic tangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is ≤ -\/1 or ≥ 1 (where atanh is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a40fb78ab8fbcfab0ab57eeaa5c05676a}\index{Tensor@{Tensor}!AvgPool@{AvgPool}}
\index{AvgPool@{AvgPool}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{AvgPool()}{AvgPool()}}
{\footnotesize\ttfamily \label{class_tensor_a40fb78ab8fbcfab0ab57eeaa5c05676a} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Avg\+Pool (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{pool\+\_\+shape}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{ = {\ttfamily \{\}}}\end{DoxyParamCaption})}



Performs average pooling operation by computing the mean value within sliding windows. 

Average pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the arithmetic mean (average) of all values in each region. It provides smoother downsampling compared to max pooling and is commonly used in convolutional neural networks for dimensionality reduction while preserving more global information.

The operation slides a window (defined by pool\+\_\+shape) across the input tensor according to the specified strides, and at each position, computes the average of all values within that window to form the output.

The pool\+\_\+shape can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the pool\+\_\+shape rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

If strides is empty, it defaults to the broadcasted pool\+\_\+shape, resulting in non-\/overlapping pooling windows (most common usage). Otherwise, strides must match the tensor\textquotesingle{}s rank.

Mathematical formulation for each output element\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{output[i,j,...]\ =\ (1/N)\ ×\ Σ\ input[window\ elements]}
\DoxyCodeLine{where\ N\ =\ number\ of\ elements\ in\ the\ pooling\ window}

\end{DoxyCode}



\begin{DoxyParams}{Parameters}
{\em pool\+\_\+shape} & A vector specifying the size of the pooling window for each dimension. Must have rank ≤ this tensor\textquotesingle{}s rank. Each dimension of the pool must be ≤ the corresponding dimension of the input. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool\+\_\+shape (non-\/overlapping windows). If provided, must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the average-\/pooled result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} -\/ pool\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The pool\+\_\+shape is not compatible with the tensor (pool dimensions exceed input dimensions).
\item The strides vector is non-\/empty and its size does not match the tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (≤ 0).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Average pooling provides smoother gradients during backpropagation compared to max pooling, as all values in the window contribute to the output.

The output represents the average intensity or activation level within each pooling region. 
\end{DoxyNote}
\Hypertarget{class_tensor_aa5fba58b033578d704f4634977982c66}\index{Tensor@{Tensor}!Broadcast@{Broadcast}}
\index{Broadcast@{Broadcast}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Broadcast()}{Broadcast()}}
{\footnotesize\ttfamily \label{class_tensor_aa5fba58b033578d704f4634977982c66} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Broadcast (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{shape}{}\end{DoxyParamCaption}) const}



Broadcasts the tensor to a target shape following Num\+Py-\/style broadcasting rules. 

This method expands the tensor\textquotesingle{}s dimensions to match a target shape by replicating data along singleton dimensions (dimensions of size 1) and adding new leading dimensions as needed. Broadcasting allows operations between tensors of different but compatible shapes.

Broadcasting rules\+:
\begin{DoxyItemize}
\item Dimensions are aligned from the rightmost (trailing) dimension.
\item Two dimensions are compatible if they are equal or one of them is 1.
\item Missing leading dimensions are treated as size 1.
\end{DoxyItemize}

For scalar tensors (rank 0), broadcasting simply fills the target shape with the scalar value.


\begin{DoxyParams}{Parameters}
{\em shape} & The target shape to broadcast to. Must contain only positive integers. The shape must be broadcast-\/compatible with the current tensor\textquotesingle{}s shape.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the broadcasted shape and expanded data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The target shape is empty or contains non-\/positive values.
\item The tensor is empty (volume = 0).
\item The shapes are not broadcast-\/compatible.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor} with its own data buffer. The original tensor remains unchanged.

For large target shapes, broadcasting can be memory-\/intensive as data is replicated. 
\end{DoxyNote}
\Hypertarget{class_tensor_ac1228f81de00883e64f49ee19e7d6021}\index{Tensor@{Tensor}!Ceil@{Ceil}}
\index{Ceil@{Ceil}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Ceil()}{Ceil()}}
{\footnotesize\ttfamily \label{class_tensor_ac1228f81de00883e64f49ee19e7d6021} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Ceil (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Rounds each element up to the nearest integer (ceiling function). 

Returns a new tensor where each element is rounded up to the smallest integer greater than or equal to the original value. For example, 2.\+3 becomes 3, and -\/2.\+7 becomes -\/2.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing ceiled values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a7de1cf7ec97265fcb0f776ea47fd9236}\index{Tensor@{Tensor}!Clip@{Clip}}
\index{Clip@{Clip}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Clip()}{Clip()}}
{\footnotesize\ttfamily \label{class_tensor_a7de1cf7ec97265fcb0f776ea47fd9236} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Clip (\begin{DoxyParamCaption}\item[{double}]{min\+\_\+value}{, }\item[{double}]{max\+\_\+value}{}\end{DoxyParamCaption}) const}



Clips (clamps) each element to be within a specified range. 

Returns a new tensor where each element is constrained to lie within the range \mbox{[}min\+\_\+value, max\+\_\+value\mbox{]}. Values less than min\+\_\+value are set to min\+\_\+value, values greater than max\+\_\+value are set to max\+\_\+value, and values within the range remain unchanged.

This operation is useful for gradient clipping in neural networks, enforcing value bounds, and numerical stability.


\begin{DoxyParams}{Parameters}
{\em min\+\_\+value} & The minimum allowed value. Must be finite and ≤ max\+\_\+value. \\
\hline
{\em max\+\_\+value} & The maximum allowed value. Must be finite and ≥ min\+\_\+value.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing clipped values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item min\+\_\+value is not finite (NaN or infinity).
\item max\+\_\+value is not finite (NaN or infinity).
\item min\+\_\+value \texorpdfstring{$>$}{>} max\+\_\+value (invalid range).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

If min\+\_\+value equals max\+\_\+value, all output elements will be set to that value. 
\end{DoxyNote}
\Hypertarget{class_tensor_a4d525a3d5051c3a704db5a254b654706}\index{Tensor@{Tensor}!Concat@{Concat}}
\index{Concat@{Concat}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Concat()}{Concat()}}
{\footnotesize\ttfamily \label{class_tensor_a4d525a3d5051c3a704db5a254b654706} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Concat (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ \mbox{\hyperlink{class_tensor}{Tensor}} $>$ \&}]{tensors}{, }\item[{int}]{axis}{ = {\ttfamily -\/1}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Concatenates multiple Tensors along a specified axis. 

This static method joins a vector of Tensors along a given axis. All tensors must have the same rank and identical shapes along all axes except the concatenation axis. The dimension along the concatenation axis in the result equals the sum of all input tensors\textquotesingle{} dimensions along that axis.

If axis is -\/1 (default), the method automatically detects the concatenation axis by finding the dimension where shapes differ. If all shapes are identical, axis 0 is used by default.

The operation creates a new independent \doxylink{class_tensor}{Tensor}; input tensors remain unchanged.


\begin{DoxyParams}{Parameters}
{\em tensors} & A vector of Tensors to concatenate. Must not be empty. All tensors must have the same rank. Shapes must match on all axes except the concatenation axis.\\
\hline
{\em axis} & The axis along which to concatenate. Default is -\/1 (auto-\/detect). Must satisfy\+: {\ttfamily -\/1 ≤ axis \texorpdfstring{$<$}{<} rank}. If -\/1, the axis is inferred from shape differences, or defaults to 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the concatenated data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The axis is less than -\/1.
\item The tensors vector is empty.
\item Tensors have mismatched ranks.
\item Shapes are incompatible for concatenation along the specified axis.
\end{DoxyItemize}\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is \texorpdfstring{$>$}{>}= the tensors\textquotesingle{} rank.\\
\hline
{\em std\+::overflow\+\_\+error} & if the resulting shape volume exceeds INT\+\_\+\+MAX.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a static method -\/ call it as {\ttfamily \doxylink{class_tensor_a4d525a3d5051c3a704db5a254b654706}{Tensor\+::\+Concat}(\{t1, t2, t3\})}.

The concatenation is performed by copying data in row-\/major order, using stride calculations for efficient memory layout. 
\end{DoxyNote}
\Hypertarget{class_tensor_ae88a978596e4f4d82ca5a27b8b79073f}\index{Tensor@{Tensor}!Convolve@{Convolve}}
\index{Convolve@{Convolve}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Convolve()}{Convolve()}}
{\footnotesize\ttfamily \label{class_tensor_ae88a978596e4f4d82ca5a27b8b79073f} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Convolve (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{filter}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{, }\item[{const std\+::vector$<$ int $>$ \&}]{padding}{}\end{DoxyParamCaption})}



Performs N-\/dimensional convolution between this tensor and a filter kernel. 

This method computes the discrete convolution of the current tensor with a given filter kernel, supporting arbitrary dimensions, custom strides, and padding.

The operation applies the filter kernel across the input tensor using a sliding window approach. At each position, element-\/wise multiplication is performed between the kernel and the corresponding input region, followed by summation to produce a single output value.

The filter kernel can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the filter rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

Mathematical formulation for each output element\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{output[i,j,...]\ =\ Σ\ input[i*stride\ +\ m,\ j*stride\ +\ n,\ ...]\ ×\ kernel[m,\ n,\ ...]}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ m,n,...}

\end{DoxyCode}



\begin{DoxyParams}{Parameters}
{\em filter} & The convolution kernel/filter tensor. Must have rank ≤ this tensor\textquotesingle{}s rank. Each dimension of the filter must be ≤ the corresponding padded dimension of the input tensor (aligned from the rightmost dimension).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. Must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0). Larger strides reduce output size and computational cost. Example\+: \{1, 1\} for dense convolution, \{2, 2\} for downsampling.\\
\hline
{\em padding} & A vector specifying the number of zero-\/padding elements to add before and after each dimension. Must have length equal to this tensor\textquotesingle{}s rank. All values must be non-\/negative (≥ 0). Padding controls output spatial dimensions and edge behavior. Example\+: \{1, 1\} adds one zero on each side of each dimension.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the convolution result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} + 2\texorpdfstring{$\ast$}{*}padding\mbox{[}i\mbox{]} -\/ filter\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The strides vector size does not match this tensor\textquotesingle{}s rank.
\item The padding vector size does not match this tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (≤ 0).
\item Any padding value is negative (\texorpdfstring{$<$}{<} 0).
\item The filter shape is not compatible with the padded input shape (filter dimensions exceed corresponding padded input dimensions).
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if the padded tensor shape would cause integer overflow (total volume exceeds INT\+\_\+\+MAX).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The convolution is computed in the spatial domain (direct method), not using FFT. For large kernels or tensors, this may be computationally expensive.

This implements "{}valid"{} convolution semantics after padding is applied. For "{}same"{} convolution (output size = input size), set padding appropriately\+: {\ttfamily padding\mbox{[}i\mbox{]} = (filter\+\_\+shape\mbox{[}i\mbox{]} -\/ 1) / 2} for odd-\/sized filters with stride=1.

The filter kernel is applied as-\/is without rotation. This is technically cross-\/correlation rather than true mathematical convolution, which is the standard convention in deep learning frameworks. 
\end{DoxyNote}
\Hypertarget{class_tensor_a9f691219cdb0a10a8111db8573128666}\index{Tensor@{Tensor}!Cos@{Cos}}
\index{Cos@{Cos}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Cos()}{Cos()}}
{\footnotesize\ttfamily \label{class_tensor_a9f691219cdb0a10a8111db8573128666} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Cos (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the cosine of each element (in radians). 

Returns a new tensor where each element is the cosine of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The cosine function maps any real number to the range \mbox{[}-\/1, 1\mbox{]} and is periodic with period 2π.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing cosine values in the range \mbox{[}-\/1, 1\mbox{]}.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by π/180. 
\end{DoxyNote}
\Hypertarget{class_tensor_a65a86d44bf78501dbdcaa52ba72d7bd3}\index{Tensor@{Tensor}!Cosh@{Cosh}}
\index{Cosh@{Cosh}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Cosh()}{Cosh()}}
{\footnotesize\ttfamily \label{class_tensor_a65a86d44bf78501dbdcaa52ba72d7bd3} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Cosh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic cosine of each element. 

Returns a new tensor where each element is the hyperbolic cosine of the corresponding element in the original tensor. The hyperbolic cosine is defined as\+: cosh(x) = (e\texorpdfstring{$^\wedge$}{\string^}x + e\texorpdfstring{$^\wedge$}{\string^}(-\/x)) / 2

The hyperbolic cosine function is defined for all real numbers and is an even function.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic cosine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a9cff3aed7469fd72059da70444170b41}\index{Tensor@{Tensor}!Cot@{Cot}}
\index{Cot@{Cot}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Cot()}{Cot()}}
{\footnotesize\ttfamily \label{class_tensor_a9cff3aed7469fd72059da70444170b41} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Cot (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the cotangent (reciprocal of tangent) of each element (in radians). 

Returns a new tensor where each element is the cotangent (1/tan(x) or cos(x)/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The cotangent function is undefined at multiples of π (where sine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing cotangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately a multiple of π (where cotangent is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by π/180. 
\end{DoxyNote}
\Hypertarget{class_tensor_a4b4030aa4413ca8c4714526965986657}\index{Tensor@{Tensor}!Coth@{Coth}}
\index{Coth@{Coth}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Coth()}{Coth()}}
{\footnotesize\ttfamily \label{class_tensor_a4b4030aa4413ca8c4714526965986657} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Coth (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element. 

Returns a new tensor where each element is the hyperbolic cotangent (1/tanh(x) or cosh(x)/sinh(x)) of the corresponding element in the original tensor.

The hyperbolic cotangent is undefined at zero (where sinh equals zero).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic cotangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately zero (where hyperbolic cotangent is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a0dfe79c9b87996847a2c898578c240ff}\index{Tensor@{Tensor}!Csc@{Csc}}
\index{Csc@{Csc}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Csc()}{Csc()}}
{\footnotesize\ttfamily \label{class_tensor_a0dfe79c9b87996847a2c898578c240ff} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Csc (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the cosecant (reciprocal of sine) of each element (in radians). 

Returns a new tensor where each element is the cosecant (1/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The cosecant function is undefined at multiples of π (where sine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing cosecant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately a multiple of π (where cosecant is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by π/180. 
\end{DoxyNote}
\Hypertarget{class_tensor_a2ddab39bf92ee11ab318b3d3374b391c}\index{Tensor@{Tensor}!Csch@{Csch}}
\index{Csch@{Csch}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Csch()}{Csch()}}
{\footnotesize\ttfamily \label{class_tensor_a2ddab39bf92ee11ab318b3d3374b391c} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Csch (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element. 

Returns a new tensor where each element is the hyperbolic cosecant (1/sinh(x)) of the corresponding element in the original tensor.

The hyperbolic cosecant is undefined at zero (where sinh equals zero).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic cosecant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately zero (where hyperbolic cosecant is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_ae9f79fc49610fe4ba20ade7d3cbafe30}\index{Tensor@{Tensor}!Exp@{Exp}}
\index{Exp@{Exp}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Exp()}{Exp()}}
{\footnotesize\ttfamily \label{class_tensor_ae9f79fc49610fe4ba20ade7d3cbafe30} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Exp (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes e raised to the power of each element (exponential function). 

Returns a new tensor where each element is e\texorpdfstring{$^\wedge$}{\string^}x, where e ≈ 2.\+71828 (Euler\textquotesingle{}s number) and x is the corresponding element in the original tensor. This is the inverse operation of the natural logarithm.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing exponential values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The exponential function grows very rapidly. Large input values may result in overflow (infinity).

Special values\+:
\begin{DoxyItemize}
\item exp(0) = 1
\item exp(1) = e ≈ 2.\+71828
\item exp(ln(x)) = x 
\end{DoxyItemize}
\end{DoxyNote}
\Hypertarget{class_tensor_aa5215a8751f54d02e66b38c4982537f9}\index{Tensor@{Tensor}!ExpandRank@{ExpandRank}}
\index{ExpandRank@{ExpandRank}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ExpandRank()}{ExpandRank()}}
{\footnotesize\ttfamily \label{class_tensor_aa5215a8751f54d02e66b38c4982537f9} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Expand\+Rank (\begin{DoxyParamCaption}\item[{int}]{axis}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Expands the rank of the \doxylink{class_tensor}{Tensor} by inserting a dimension of size 1 at a specified axis. 

This operation increases the \doxylink{class_tensor}{Tensor}\textquotesingle{}s rank by 1 by inserting a new axis with dimension 1 at the specified position. The data remains unchanged; only the shape metadata is modified. This is analogous to Num\+Py\textquotesingle{}s {\ttfamily np.\+expand\+\_\+dims()} function.

The new dimension allows for operations such as broadcasting or stacking without modifying the underlying data. The axis parameter determines where the new dimension is inserted in the shape vector.


\begin{DoxyParams}{Parameters}
{\em axis} & The position where the new dimension (of size 1) will be inserted. Must satisfy\+: {\ttfamily 0 ≤ axis ≤ rank}.
\begin{DoxyItemize}
\item {\ttfamily axis = 0}\+: Insert at the beginning (becomes the new outermost dimension).
\item {\ttfamily axis = rank}\+: Append at the end (becomes the new innermost dimension). Default value is 0.
\end{DoxyItemize}\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with rank increased by 1 and a dimension of size 1 at the specified axis.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or greater than the current rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor} via reshaping. The original \doxylink{class_tensor}{Tensor} is unchanged.

The total volume (number of elements) remains the same. 
\end{DoxyNote}
\Hypertarget{class_tensor_ab580be2efba7d27e6b6da689eee4732e}\index{Tensor@{Tensor}!Flatten@{Flatten}}
\index{Flatten@{Flatten}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Flatten()}{Flatten()}}
{\footnotesize\ttfamily \label{class_tensor_ab580be2efba7d27e6b6da689eee4732e} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Flatten (\begin{DoxyParamCaption}\item[{int}]{axis\+\_\+from}{, }\item[{int}]{axis\+\_\+upto}{}\end{DoxyParamCaption}) const}



Flattens a range of consecutive axes into a single dimension. 

This operation collapses multiple consecutive dimensions between {\ttfamily axis\+\_\+from} (inclusive) and {\ttfamily axis\+\_\+upto} (exclusive) into a single flattened dimension. The axes before {\ttfamily axis\+\_\+from} and after {\ttfamily axis\+\_\+upto} remain unchanged. The resulting \doxylink{class_tensor}{Tensor} has a reduced rank.

The flattened dimension\textquotesingle{}s size is the product of all collapsed dimensions. The data order (row-\/major) remains unchanged; only the shape metadata is modified.


\begin{DoxyParams}{Parameters}
{\em axis\+\_\+from} & The starting axis index (inclusive) for flattening. Must satisfy\+: {\ttfamily 0 ≤ axis\+\_\+from \texorpdfstring{$<$}{<} axis\+\_\+upto}.\\
\hline
{\em axis\+\_\+upto} & The ending axis index (exclusive) for flattening. Must satisfy\+: {\ttfamily axis\+\_\+from \texorpdfstring{$<$}{<} axis\+\_\+upto ≤ rank}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with reduced rank where the specified axes are flattened.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the \doxylink{class_tensor}{Tensor} is rank-\/0 (scalar) or rank-\/1 (already flat, cannot flatten further).\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item {\ttfamily axis\+\_\+from} is negative.
\item {\ttfamily axis\+\_\+upto} is greater than the current rank.
\end{DoxyItemize}\\
\hline
{\em std\+::invalid\+\_\+argument} & if {\ttfamily axis\+\_\+from \texorpdfstring{$>$}{>}= axis\+\_\+upto} (invalid range specification).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

The total volume (number of elements) remains constant. 
\end{DoxyNote}
\Hypertarget{class_tensor_a6ecaeb0e29c326798d82d6a2cccc28cf}\index{Tensor@{Tensor}!Floor@{Floor}}
\index{Floor@{Floor}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Floor()}{Floor()}}
{\footnotesize\ttfamily \label{class_tensor_a6ecaeb0e29c326798d82d6a2cccc28cf} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Floor (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Rounds each element down to the nearest integer (floor function). 

Returns a new tensor where each element is rounded down to the largest integer less than or equal to the original value. For example, 2.\+7 becomes 2, and -\/2.\+3 becomes -\/3.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing floored values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_aee9562ed6e3368ac6cd664373556cca4}\index{Tensor@{Tensor}!Insert@{Insert}}
\index{Insert@{Insert}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Insert()}{Insert()}}
{\footnotesize\ttfamily \label{class_tensor_aee9562ed6e3368ac6cd664373556cca4} 
void Tensor\+::\+Insert (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{, }\item[{int}]{axis}{ = {\ttfamily -\/1}, }\item[{int}]{index}{ = {\ttfamily 0}}\end{DoxyParamCaption})}



Inserts a lower-\/rank \doxylink{class_tensor}{Tensor} at a specific position along an axis (in-\/place operation). 

This method inserts a \doxylink{class_tensor}{Tensor} of rank {\ttfamily n-\/1} into the current \doxylink{class_tensor}{Tensor} of rank {\ttfamily n} at a specified position along a given axis. The inserted tensor must match all dimensions of the current tensor except for the insertion axis, where the dimension is increased by 1.

Unlike Append (which adds at the end), Insert allows placement at any valid position, including the beginning (index = 0), middle, or end (index = shape\mbox{[}axis\mbox{]}).

If axis is -\/1 (default), the method automatically determines the axis by finding the dimension mismatch between the two tensors\textquotesingle{} shapes.

The operation modifies the current \doxylink{class_tensor}{Tensor} in-\/place by\+:
\begin{DoxyEnumerate}
\item Ensuring unique data ownership (calls \doxylink{class_tensor_ac9b2a793615586ac29b2e7215261b844}{Unique\+Data()}).
\item Interleaving data\+: elements before insertion, inserted tensor, elements after insertion.
\item Updating shape, strides, and volume metadata.
\end{DoxyEnumerate}


\begin{DoxyParams}{Parameters}
{\em tensor} & The \doxylink{class_tensor}{Tensor} to insert. Must have rank = {\ttfamily this-\/\texorpdfstring{$>$}{>}rank -\/ 1}. All dimensions except the insertion axis must match the current tensor\textquotesingle{}s shape.\\
\hline
{\em axis} & The axis along which to insert. Default is -\/1 (auto-\/detect). Must satisfy\+: {\ttfamily -\/1 ≤ axis \texorpdfstring{$<$}{<} rank}. If -\/1, the axis is inferred from the shape mismatch.\\
\hline
{\em index} & The position along the axis where the tensor will be inserted. Must satisfy\+: {\ttfamily 0 ≤ index ≤ shape\mbox{[}axis\mbox{]}}.
\begin{DoxyItemize}
\item index = 0\+: Insert at the beginning.
\item index = shape\mbox{[}axis\mbox{]}\+: Insert at the end (equivalent to Append).
\end{DoxyItemize}\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item The axis is less than -\/1 or \texorpdfstring{$>$}{>}= rank.
\item The index is negative or \texorpdfstring{$>$}{>} shape\mbox{[}axis\mbox{]}.
\end{DoxyItemize}\\
\hline
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The tensor\textquotesingle{}s rank is not exactly {\ttfamily rank -\/ 1}.
\item The shapes are not compatible for insertion along the specified axis.
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if the resulting shape volume exceeds INT\+\_\+\+MAX.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an {\bfseries{in-\/place operation}} that modifies the current \doxylink{class_tensor}{Tensor}. The original data is replaced with the merged result.

This method calls \doxylink{class_tensor_ac9b2a793615586ac29b2e7215261b844}{Unique\+Data()} to ensure safe modification without affecting other tensors that might share the data buffer. 
\end{DoxyNote}
\Hypertarget{class_tensor_a767884250837a4894e6d8b592a9d3450}\index{Tensor@{Tensor}!IsEmpty@{IsEmpty}}
\index{IsEmpty@{IsEmpty}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{IsEmpty()}{IsEmpty()}}
{\footnotesize\ttfamily \label{class_tensor_a767884250837a4894e6d8b592a9d3450} 
bool Tensor\+::\+Is\+Empty (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Checks whether the tensor contains no elements. 

A tensor is considered empty if its volume (total number of elements) is zero. This can occur when any dimension in the shape is zero.

\begin{DoxyReturn}{Returns}
true if the tensor has zero elements (volume = 0), false otherwise.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
An empty tensor is different from a scalar tensor.
\begin{DoxyItemize}
\item Empty\+: volume = 0, no data stored
\item Scalar\+: volume = 1, single value stored 
\end{DoxyItemize}
\end{DoxyNote}
\Hypertarget{class_tensor_a203a74ae4428ecadfd1efbebd85d753d}\index{Tensor@{Tensor}!IsScalar@{IsScalar}}
\index{IsScalar@{IsScalar}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{IsScalar()}{IsScalar()}}
{\footnotesize\ttfamily \label{class_tensor_a203a74ae4428ecadfd1efbebd85d753d} 
bool Tensor\+::\+Is\+Scalar (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Checks whether the tensor represents a scalar (single) value. 

A tensor is considered scalar if it has rank 0 (empty shape) and contains exactly one element. Scalar tensors represent single numerical values.

\begin{DoxyReturn}{Returns}
true if the tensor is a scalar (rank 0 and volume 1), false otherwise.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
A scalar tensor has\+:
\begin{DoxyItemize}
\item Empty shape\+: shape = \{\}
\item Volume of 1\+: exactly one element
\item Rank of 0\+: zero dimensions 
\end{DoxyItemize}
\end{DoxyNote}
\Hypertarget{class_tensor_a40481e1178fdb80dae8934a8ed75adbb}\index{Tensor@{Tensor}!Log@{Log}}
\index{Log@{Log}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Log()}{Log()}}
{\footnotesize\ttfamily \label{class_tensor_a40481e1178fdb80dae8934a8ed75adbb} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Log (\begin{DoxyParamCaption}\item[{double}]{base}{ = {\ttfamily std\+:\+:numbers\+:\+:e}}\end{DoxyParamCaption}) const}



Computes the logarithm of each element with a specified base. 

Returns a new tensor where each element is the logarithm (base-\/b) of the corresponding element in the original tensor. The operation computes log\+\_\+b(x) for each element x.

Uses the change of base formula\+: log\+\_\+b(x) = ln(x) / ln(b)


\begin{DoxyParams}{Parameters}
{\em base} & The logarithm base. Must be positive (\texorpdfstring{$>$}{>} 0) and not equal to 1. Common values\+: e ≈ 2.\+71828 (natural log), 10 (common log), 2 (binary log). Default is e (natural logarithm).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing logarithm values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The base is zero, negative, or approximately zero.
\item The base is 1 (logarithm base 1 is undefined).
\item Any element is zero, negative, or approximately zero (log undefined for non-\/positive values).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Special values\+:
\begin{DoxyItemize}
\item log\+\_\+b(1) = 0 for any valid base b
\item log\+\_\+b(b) = 1
\item log\+\_\+b(b\texorpdfstring{$^\wedge$}{\string^}n) = n 
\end{DoxyItemize}
\end{DoxyNote}
\Hypertarget{class_tensor_a0adf81cbee9f45641c9c3bd70ec5c2b4}\index{Tensor@{Tensor}!MatMul@{MatMul}}
\index{MatMul@{MatMul}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{MatMul()}{MatMul()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a0adf81cbee9f45641c9c3bd70ec5c2b4} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Mat\+Mul (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Performs matrix multiplication with another tensor. 

Convenience method that calls the static Mat\+Mul function. Equivalent to\+: Tensor\+::\+Mat\+Mul(\texorpdfstring{$\ast$}{*}this, other)


\begin{DoxyParams}{Parameters}
{\em other} & The right operand tensor. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the matrix multiplication result.
\end{DoxyReturn}
\begin{DoxySeeAlso}{See also}
\doxylink{class_tensor_a33ee78056cb83d4381fdcbe3c79cde96}{Mat\+Mul(const Tensor\&, const Tensor\&)} 
\end{DoxySeeAlso}
\Hypertarget{class_tensor_a33ee78056cb83d4381fdcbe3c79cde96}\index{Tensor@{Tensor}!MatMul@{MatMul}}
\index{MatMul@{MatMul}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{MatMul()}{MatMul()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a33ee78056cb83d4381fdcbe3c79cde96} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Mat\+Mul (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor\+\_\+1}{, }\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor\+\_\+2}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Performs matrix multiplication between two tensors with automatic broadcasting. 

This static method implements batched matrix multiplication following Num\+Py-\/style broadcasting rules. It handles vectors (rank-\/1), matrices (rank-\/2), and higher-\/dimensional tensors by treating the last two dimensions as matrix dimensions and broadcasting over batch dimensions.

Rank-\/1 tensors (vectors) are automatically expanded\+:
\begin{DoxyItemize}
\item Left vector\+: (n,) → (1, n)
\item Right vector\+: (n,) → (n, 1)
\end{DoxyItemize}

For higher-\/rank tensors, the last two dimensions are treated as matrix dimensions, and earlier dimensions are treated as batch dimensions that are broadcast together.


\begin{DoxyParams}{Parameters}
{\em tensor\+\_\+1} & The left operand tensor. Must have rank ≥ 1. \\
\hline
{\em tensor\+\_\+2} & The right operand tensor. Must have rank ≥ 1.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the matrix multiplication result.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item Either tensor has rank 0 (scalar).
\item Inner matrix dimensions don\textquotesingle{}t match (tensor\+\_\+1\textquotesingle{}s last dim ≠ tensor\+\_\+2\textquotesingle{}s second-\/to-\/last dim).
\item Batch dimensions are not broadcast-\/compatible.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Input tensors remain unchanged.

Broadcasting rules apply only to batch dimensions (all dimensions except the last two). Matrix dimensions must satisfy the standard matrix multiplication constraint. 
\end{DoxyNote}
\Hypertarget{class_tensor_a46e3d36946b41f93fef4b0edcc48ba2e}\index{Tensor@{Tensor}!Max@{Max}}
\index{Max@{Max}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Max()}{Max()}}
{\footnotesize\ttfamily \label{class_tensor_a46e3d36946b41f93fef4b0edcc48ba2e} 
double Tensor\+::\+Max (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Finds the maximum value in the tensor. 

Returns the largest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The maximum element value.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
\end{DoxyExceptions}
\Hypertarget{class_tensor_ad378cc1c1af81074204c05bc0ff4f00d}\index{Tensor@{Tensor}!MaxPool@{MaxPool}}
\index{MaxPool@{MaxPool}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{MaxPool()}{MaxPool()}}
{\footnotesize\ttfamily \label{class_tensor_ad378cc1c1af81074204c05bc0ff4f00d} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Max\+Pool (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{pool\+\_\+shape}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{ = {\ttfamily \{\}}}\end{DoxyParamCaption})}



Performs max pooling operation by taking the maximum value within sliding windows. 

Max pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the maximum value in each region. It is commonly used in convolutional neural networks for spatial dimensionality reduction, feature extraction, and translation invariance.

The operation slides a window (defined by pool\+\_\+shape) across the input tensor according to the specified strides, and at each position, selects the maximum value within that window to form the output.

The pool\+\_\+shape can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the pool\+\_\+shape rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

If strides is empty, it defaults to the broadcasted pool\+\_\+shape, resulting in non-\/overlapping pooling windows (most common usage). Otherwise, strides must match the tensor\textquotesingle{}s rank.


\begin{DoxyParams}{Parameters}
{\em pool\+\_\+shape} & A vector specifying the size of the pooling window for each dimension. Must have rank ≤ this tensor\textquotesingle{}s rank. Each dimension of the pool must be ≤ the corresponding dimension of the input. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool\+\_\+shape (non-\/overlapping windows). If provided, must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the max-\/pooled result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} -\/ pool\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The pool\+\_\+shape is not compatible with the tensor (pool dimensions exceed input dimensions).
\item The strides vector is non-\/empty and its size does not match the tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (≤ 0).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Max pooling provides translation invariance and is robust to small spatial shifts in the input features, making it popular in computer vision tasks.

The output captures the most prominent features within each pooling region. 
\end{DoxyNote}
\Hypertarget{class_tensor_aac4651bb52521e86e875d2e8c1e8643a}\index{Tensor@{Tensor}!Mean@{Mean}}
\index{Mean@{Mean}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Mean()}{Mean()}}
{\footnotesize\ttfamily \label{class_tensor_aac4651bb52521e86e875d2e8c1e8643a} 
double Tensor\+::\+Mean (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the mean (average) of all elements in the tensor. 

Returns the arithmetic mean of all elements as a scalar value. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The mean of all elements.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
Formula\+: Mean = Sum / Volume 
\end{DoxyNote}
\Hypertarget{class_tensor_a759daa212e3786fda070af4732f3ee15}\index{Tensor@{Tensor}!Min@{Min}}
\index{Min@{Min}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Min()}{Min()}}
{\footnotesize\ttfamily \label{class_tensor_a759daa212e3786fda070af4732f3ee15} 
double Tensor\+::\+Min (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Finds the minimum value in the tensor. 

Returns the smallest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The minimum element value.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
\end{DoxyExceptions}
\Hypertarget{class_tensor_ad1f64c43e7267629a150a2cc7d7ad75b}\index{Tensor@{Tensor}!MinPool@{MinPool}}
\index{MinPool@{MinPool}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{MinPool()}{MinPool()}}
{\footnotesize\ttfamily \label{class_tensor_ad1f64c43e7267629a150a2cc7d7ad75b} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Min\+Pool (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{pool\+\_\+shape}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{ = {\ttfamily \{\}}}\end{DoxyParamCaption})}



Performs min pooling operation by taking the minimum value within sliding windows. 

Min pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the minimum value in each region. While less common than max pooling, it can be useful in specific applications where detecting the lowest activation or darkest features is important, such as certain image processing tasks or anomaly detection.

The operation slides a window (defined by pool\+\_\+shape) across the input tensor according to the specified strides, and at each position, selects the minimum value within that window to form the output.

The pool\+\_\+shape can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the pool\+\_\+shape rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

If strides is empty, it defaults to the broadcasted pool\+\_\+shape, resulting in non-\/overlapping pooling windows (most common usage). Otherwise, strides must match the tensor\textquotesingle{}s rank.


\begin{DoxyParams}{Parameters}
{\em pool\+\_\+shape} & A vector specifying the size of the pooling window for each dimension. Must have rank ≤ this tensor\textquotesingle{}s rank. Each dimension of the pool must be ≤ the corresponding dimension of the input. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool\+\_\+shape (non-\/overlapping windows). If provided, must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the min-\/pooled result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} -\/ pool\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The pool\+\_\+shape is not compatible with the tensor (pool dimensions exceed input dimensions).
\item The strides vector is non-\/empty and its size does not match the tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (≤ 0).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Min pooling is sensitive to the smallest values in each region, making it useful for detecting low-\/intensity features or for applications requiring conservative feature selection.

The output captures the least prominent (minimum) features within each pooling region. 
\end{DoxyNote}
\Hypertarget{class_tensor_aafd911eab8af5c4ec79593d67f7823df}\index{Tensor@{Tensor}!Mod@{Mod}}
\index{Mod@{Mod}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Mod()}{Mod()}}
{\footnotesize\ttfamily \label{class_tensor_aafd911eab8af5c4ec79593d67f7823df} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Mod (\begin{DoxyParamCaption}\item[{double}]{mod\+\_\+value}{}\end{DoxyParamCaption}) const}



Computes the modulus (remainder) of each element divided by a value. 

Returns a new tensor where each element is the remainder of dividing the corresponding element by the specified modulus value. Uses the fmod function which computes the floating-\/point remainder of the division.

The result has the same sign as the dividend (the tensor element).


\begin{DoxyParams}{Parameters}
{\em mod\+\_\+value} & The divisor for the modulus operation. Must be non-\/zero.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing modulus values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if mod\+\_\+value is approximately zero (division by zero).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The result sign follows the dividend\+: fmod(-\/5, 3) = -\/2, fmod(5, -\/3) = 2 
\end{DoxyNote}
\Hypertarget{class_tensor_a75728ffb3911510ebfb73c113d97f7ec}\index{Tensor@{Tensor}!operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}}
\index{operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}()}{operator*()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a75728ffb3911510ebfb73c113d97f7ec} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator\texorpdfstring{$\ast$}{*} (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise multiplication of two tensors (Hadamard product). 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the product of corresponding elements from both tensors. If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.

This is element-\/wise multiplication (Hadamard product), NOT matrix multiplication.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to multiply with. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise products with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 

This is NOT matrix multiplication. For matrix multiplication, use a separate Mat\+Mul method. 
\end{DoxyNote}
\Hypertarget{class_tensor_a6658b84a8e2b71220c7f55f8610e6bbe}\index{Tensor@{Tensor}!operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}}
\index{operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}()}{operator*()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a6658b84a8e2b71220c7f55f8610e6bbe} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator\texorpdfstring{$\ast$}{*} (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise multiplication of all tensor elements by a scalar value. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the product of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise products.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a93f7554458d7ae9a3cad5dc76eb07027}\index{Tensor@{Tensor}!operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}}
\index{operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}=()}{operator*=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a93f7554458d7ae9a3cad5dc76eb07027} 
void Tensor\+::operator\texorpdfstring{$\ast$}{*}= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise multiplication with another tensor (Hadamard product). 

Multiplies this tensor with the given tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

This is element-\/wise multiplication (Hadamard product), NOT matrix multiplication.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to multiply with. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

This is NOT matrix multiplication. For matrix multiplication, use a separate Mat\+Mul method. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A \texorpdfstring{$\ast$}{*} B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_a81868ded9686e9083f30666e68fdef6e}\index{Tensor@{Tensor}!operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}}
\index{operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}=()}{operator*=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a81868ded9686e9083f30666e68fdef6e} 
void Tensor\+::operator\texorpdfstring{$\ast$}{*}= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise multiplication by a scalar value. 

Multiplies all elements of this tensor by the scalar value in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A \texorpdfstring{$\ast$}{*} value;} 
\end{DoxyNote}
\Hypertarget{class_tensor_a6bee0bb8cea232b7f2a589e8d48a4d27}\index{Tensor@{Tensor}!operator+@{operator+}}
\index{operator+@{operator+}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator+()}{operator+()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a6bee0bb8cea232b7f2a589e8d48a4d27} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator+ (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise addition of two tensors. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the sum of corresponding elements from both tensors. If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.

Broadcasting allows operations between tensors of different but compatible shapes by automatically expanding dimensions where needed.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to add. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise sums with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 
\end{DoxyNote}
\Hypertarget{class_tensor_a47812d7a29b100dd87bcd67e91c64482}\index{Tensor@{Tensor}!operator+@{operator+}}
\index{operator+@{operator+}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator+()}{operator+()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a47812d7a29b100dd87bcd67e91c64482} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator+ (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise addition of a scalar value to all tensor elements. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the sum of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to add to each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise sums.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a634382ed2b871ed0476b7207cdbbbe15}\index{Tensor@{Tensor}!operator+=@{operator+=}}
\index{operator+=@{operator+=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator+=()}{operator+=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a634382ed2b871ed0476b7207cdbbbe15} 
void Tensor\+::operator+= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise addition with another tensor. 

Adds the given tensor to this tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to add. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A + B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_a45a758479b01bfce56ca3c7bede0493b}\index{Tensor@{Tensor}!operator+=@{operator+=}}
\index{operator+=@{operator+=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator+=()}{operator+=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a45a758479b01bfce56ca3c7bede0493b} 
void Tensor\+::operator+= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise addition of a scalar value. 

Adds the scalar value to all elements of this tensor in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to add to each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A + value;} 
\end{DoxyNote}
\Hypertarget{class_tensor_aef9ba3fe1189eb11d47cd8f1dd573a1b}\index{Tensor@{Tensor}!operator-\/@{operator-\/}}
\index{operator-\/@{operator-\/}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator-\/()}{operator-()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_aef9ba3fe1189eb11d47cd8f1dd573a1b} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator-\/ (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise subtraction of two tensors. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the difference between corresponding elements from both tensors (this -\/ tensor). If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to subtract. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise differences with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 

Order matters\+: A -\/ B ≠ B -\/ A 
\end{DoxyNote}
\Hypertarget{class_tensor_aaab66abb66d3aa8ac54b985cade60f7e}\index{Tensor@{Tensor}!operator-\/@{operator-\/}}
\index{operator-\/@{operator-\/}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator-\/()}{operator-()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_aaab66abb66d3aa8ac54b985cade60f7e} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator-\/ (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise subtraction of a scalar value from all tensor elements. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the difference between the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise differences.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a609462c373a6263269bfec6c305b38c3}\index{Tensor@{Tensor}!operator-\/=@{operator-\/=}}
\index{operator-\/=@{operator-\/=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator-\/=()}{operator-=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a609462c373a6263269bfec6c305b38c3} 
void Tensor\+::operator-\/= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise subtraction with another tensor. 

Subtracts the given tensor from this tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to subtract. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A -\/ B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_a7e6db16f013c048474b050fda7da2a01}\index{Tensor@{Tensor}!operator-\/=@{operator-\/=}}
\index{operator-\/=@{operator-\/=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator-\/=()}{operator-=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a7e6db16f013c048474b050fda7da2a01} 
void Tensor\+::operator-\/= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise subtraction of a scalar value. 

Subtracts the scalar value from all elements of this tensor in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A -\/ value;} 
\end{DoxyNote}
\Hypertarget{class_tensor_a4a881f8f18dbbb2aa29aeec5f81ec018}\index{Tensor@{Tensor}!operator/@{operator/}}
\index{operator/@{operator/}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator/()}{operator/()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a4a881f8f18dbbb2aa29aeec5f81ec018} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator/ (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise division of two tensors. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the quotient of corresponding elements from both tensors (this / tensor). If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.

Division by elements close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon \texorpdfstring{$\ast$}{*} EPSILON\+\_\+\+SCALE) is detected and throws an exception to prevent numerical instability.


\begin{DoxyParams}{Parameters}
{\em tensor} & The divisor tensor. Must be non-\/empty, broadcast-\/compatible, and contain no near-\/zero values.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise quotients with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method). \\
\hline
{\em std\+::domain\+\_\+error} & if any element in the divisor tensor is close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon \texorpdfstring{$\ast$}{*} EPSILON\+\_\+\+SCALE).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 

Order matters\+: A / B ≠ B / A 

Division-\/by-\/zero check is performed for each element individually during iteration. 
\end{DoxyNote}
\Hypertarget{class_tensor_ac7a5df6dc6c7857650e0adbf66b4c422}\index{Tensor@{Tensor}!operator/@{operator/}}
\index{operator/@{operator/}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator/()}{operator/()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_ac7a5df6dc6c7857650e0adbf66b4c422} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator/ (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise division of all tensor elements by a scalar value. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the quotient of the corresponding element in this tensor divided by the scalar value. The operation is broadcast across all elements.

Division by values very close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} 1e-\/9) is treated as division by zero to prevent numerical instability.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise quotients.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity. \\
\hline
{\em std\+::domain\+\_\+error} & if the absolute value of the divisor is less than epsilon × EPSILON\+\_\+\+SCALE (division by \texorpdfstring{$\sim$}{\string~}zero).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The threshold 1e-\/9 is used to detect near-\/zero values and prevent numerical errors. 
\end{DoxyNote}
\Hypertarget{class_tensor_a21809015e47552d25e7330bd0707cb1d}\index{Tensor@{Tensor}!operator/=@{operator/=}}
\index{operator/=@{operator/=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator/=()}{operator/=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a21809015e47552d25e7330bd0707cb1d} 
void Tensor\+::operator/= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise division by another tensor. 

Divides this tensor by the given tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

Division by elements close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE) is detected and throws an exception to prevent numerical instability.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The divisor tensor. Must be non-\/empty, broadcast-\/compatible, and contain no near-\/zero values.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method). \\
\hline
{\em std\+::domain\+\_\+error} & if any element in the divisor tensor is close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

Division-\/by-\/zero check is performed for each element individually during iteration. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A / B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_a513698bd5959d9c531849c91ef8c4c6a}\index{Tensor@{Tensor}!operator/=@{operator/=}}
\index{operator/=@{operator/=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator/=()}{operator/=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a513698bd5959d9c531849c91ef8c4c6a} 
void Tensor\+::operator/= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise division by a scalar value. 

Divides all elements of this tensor by the scalar value in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.

Division by values very close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE) is treated as division by zero to prevent numerical instability.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity. \\
\hline
{\em std\+::domain\+\_\+error} & if the absolute value of the divisor is less than epsilon × EPSILON\+\_\+\+SCALE (division by \texorpdfstring{$\sim$}{\string~}zero).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A / value;} 
\end{DoxyNote}
\Hypertarget{class_tensor_a0b7d70c72543fd055cdb101b73cec827}\index{Tensor@{Tensor}!operator=@{operator=}}
\index{operator=@{operator=}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator=()}{operator=()}}
{\footnotesize\ttfamily \label{class_tensor_a0b7d70c72543fd055cdb101b73cec827} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



Assignment operator (deep copy semantics). 

Assigns the contents of another \doxylink{class_tensor}{Tensor} to the current \doxylink{class_tensor}{Tensor} by performing a deep copy. The right-\/hand side tensor is copied completely, including all metadata (rank, shape, strides) and data. The resulting tensors are completely independent {\ucr} modifying one does not affect the other.

If the right-\/hand side tensor represents a data range from a larger buffer, only the relevant data range \mbox{[}start, end) is copied into the new buffer.


\begin{DoxyParams}{Parameters}
{\em T} & The source \doxylink{class_tensor}{Tensor} to assign from.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A reference to the current \doxylink{class_tensor}{Tensor} (\texorpdfstring{$\ast$}{*}this), allowing assignment chaining.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This operator performs a deep copy, which can be expensive for large tensors in terms of both time and memory. Each assignment allocates a new data buffer.

Self-\/assignment (e.\+g., {\ttfamily A = A;}) is detected and handled efficiently with no unnecessary copying.

After assignment, the tensor always has {\ttfamily start = 0} and {\ttfamily end = volume}, representing a complete, non-\/sliced tensor. 
\end{DoxyNote}
\Hypertarget{class_tensor_a039914aee51bfae847dbe28209ad69ff}\index{Tensor@{Tensor}!operator\mbox{[}\mbox{]}@{operator[]}}
\index{operator\mbox{[}\mbox{]}@{operator[]}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator[]()}{operator[]()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_a039914aee51bfae847dbe28209ad69ff} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} Tensor\+::operator\mbox{[}$\,$\mbox{]} (\begin{DoxyParamCaption}\item[{int}]{index}{}\end{DoxyParamCaption})}



Returns a proxy object for accessing and modifying a slice along the first dimension. 

This operator indexes the \doxylink{class_tensor}{Tensor} along the first dimension (axis 0) and returns a \doxylink{class_tensor_slice}{Tensor\+Slice} proxy object. The proxy enables two key behaviors\+:


\begin{DoxyEnumerate}
\item {\bfseries{Independent copy on conversion}}\+: When converted to a \doxylink{class_tensor}{Tensor} (e.\+g., {\ttfamily \doxylink{class_tensor}{Tensor} t = A\mbox{[}i\mbox{]};}), it creates an independent copy of the slice data.
\item {\bfseries{Modification of the original}}\+: When assigned to (e.\+g., {\ttfamily A\mbox{[}i\mbox{]} = other\+\_\+tensor;}), the assignment modifies the original \doxylink{class_tensor}{Tensor} at that index.
\end{DoxyEnumerate}

The proxy also supports chaining of index operations (e.\+g., {\ttfamily A\mbox{[}i\mbox{]}\mbox{[}j\mbox{]}\mbox{[}k\mbox{]} = value;}) through its own {\ttfamily operator\mbox{[}\mbox{]}} methods.


\begin{DoxyParams}{Parameters}
{\em index} & The zero-\/based index along the first dimension. Must satisfy\+: {\ttfamily 0 ? index \texorpdfstring{$<$}{<} shape\mbox{[}0\mbox{]}}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A \doxylink{class_tensor_slice}{Tensor\+Slice} proxy object that references this \doxylink{class_tensor}{Tensor} and the given index.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the \doxylink{class_tensor}{Tensor} is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the index is negative or \texorpdfstring{$>$}{>}= shape\mbox{[}0\mbox{]}.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operator uses the proxy pattern to enable both copy and reference semantics. Chaining is supported\+: {\ttfamily A\mbox{[}i\mbox{]}\mbox{[}j\mbox{]}\mbox{[}k\mbox{]}} creates nested proxies with index chains. 
\end{DoxyNote}
\Hypertarget{class_tensor_a63f36d923fe1a8bdfa5127dcdb606b35}\index{Tensor@{Tensor}!operator\mbox{[}\mbox{]}@{operator[]}}
\index{operator\mbox{[}\mbox{]}@{operator[]}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{operator[]()}{operator[]()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_a63f36d923fe1a8bdfa5127dcdb606b35} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::operator\mbox{[}$\,$\mbox{]} (\begin{DoxyParamCaption}\item[{int}]{index}{}\end{DoxyParamCaption}) const}



Returns an independent copy of a slice along the first dimension (const version). 

This const-\/qualified operator indexes a const \doxylink{class_tensor}{Tensor} along the first dimension and returns an independent copy of the slice as a new \doxylink{class_tensor}{Tensor}. Since this is a const operation, only read-\/only access is possible, and modifications to the returned \doxylink{class_tensor}{Tensor} do not affect the original.


\begin{DoxyParams}{Parameters}
{\em index} & The zero-\/based index along the first dimension. Must satisfy\+: {\ttfamily 0 ? index \texorpdfstring{$<$}{<} shape\mbox{[}0\mbox{]}}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing an independent copy of the slice data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the \doxylink{class_tensor}{Tensor} is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the index is negative or \texorpdfstring{$>$}{>}= shape\mbox{[}0\mbox{]}.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This returns a complete \doxylink{class_tensor}{Tensor}, not a proxy. The returned \doxylink{class_tensor}{Tensor} is always independent with its own data buffer.

Chaining is supported on const tensors\+: {\ttfamily const\+\_\+A\mbox{[}i\mbox{]}\mbox{[}j\mbox{]}\mbox{[}k\mbox{]}} returns a \doxylink{class_tensor}{Tensor}. 
\end{DoxyNote}
\Hypertarget{class_tensor_af7dda240cea62631125c2272e38ffaa1}\index{Tensor@{Tensor}!Pad@{Pad}}
\index{Pad@{Pad}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Pad()}{Pad()}}
{\footnotesize\ttfamily \label{class_tensor_af7dda240cea62631125c2272e38ffaa1} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Pad (\begin{DoxyParamCaption}\item[{int}]{axis}{, }\item[{int}]{pad\+\_\+before\+\_\+size}{, }\item[{int}]{pad\+\_\+after\+\_\+size}{, }\item[{double}]{value}{ = {\ttfamily 0.0}}\end{DoxyParamCaption}) const}



Adds padding elements before and/or after the tensor along a specified axis. 

This method creates a new \doxylink{class_tensor}{Tensor} with additional elements (padding) inserted before and after the original data along the specified axis. The padding elements are filled with a constant value (default is 0.\+0).

The resulting tensor has the same rank but an increased dimension along the padded axis\+: {\ttfamily new\+\_\+shape\mbox{[}axis\mbox{]} = original\+\_\+shape\mbox{[}axis\mbox{]} + pad\+\_\+before\+\_\+size + pad\+\_\+after\+\_\+size}.

This operation is commonly used in convolutional neural networks, signal processing, and boundary handling in various algorithms.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to add padding. Must satisfy\+: {\ttfamily 0 ≤ axis \texorpdfstring{$<$}{<} rank}.\\
\hline
{\em pad\+\_\+before\+\_\+size} & The number of padding elements to add before the data along the axis. Must be non-\/negative (≥ 0).\\
\hline
{\em pad\+\_\+after\+\_\+size} & The number of padding elements to add after the data along the axis. Must be non-\/negative (≥ 0).\\
\hline
{\em value} & The constant value to fill the padding elements with. Default is 0.\+0. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with padding added along the specified axis.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
{\em std\+::invalid\+\_\+argument} & if pad\+\_\+before\+\_\+size or pad\+\_\+after\+\_\+size is negative.\\
\hline
{\em std\+::overflow\+\_\+error} & if the resulting shape volume exceeds INT\+\_\+\+MAX.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

If both pad\+\_\+before\+\_\+size and pad\+\_\+after\+\_\+size are 0, the returned tensor is a copy of the original.

Internally, this method uses Concat to join padding tensors with the original data. 
\end{DoxyNote}
\Hypertarget{class_tensor_a0bb8eea690681cb13ffbe53fa66d7183}\index{Tensor@{Tensor}!Power@{Power}}
\index{Power@{Power}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Power()}{Power()}}
{\footnotesize\ttfamily \label{class_tensor_a0bb8eea690681cb13ffbe53fa66d7183} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Power (\begin{DoxyParamCaption}\item[{double}]{exponent}{}\end{DoxyParamCaption}) const}



Raises each element to a specified power (exponentiation). 

Returns a new tensor where each element is raised to the given exponent. The operation computes x\texorpdfstring{$^\wedge$}{\string^}exponent for each element x.

For negative bases with non-\/integer exponents, the result would be a complex number, so an exception is thrown to maintain real number semantics.


\begin{DoxyParams}{Parameters}
{\em exponent} & The power to raise each element to. Can be any real number.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing the results of exponentiation.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is negative and the exponent is non-\/integer (would result in a complex number).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Special cases\+:
\begin{DoxyItemize}
\item x\texorpdfstring{$^\wedge$}{\string^}0 = 1 for any x (including 0)
\item x\texorpdfstring{$^\wedge$}{\string^}1 = x
\item 0\texorpdfstring{$^\wedge$}{\string^}n = 0 for positive n 
\end{DoxyItemize}
\end{DoxyNote}
\Hypertarget{class_tensor_a5e012653a230fcafd531ac6063e0067a}\index{Tensor@{Tensor}!Print@{Print}}
\index{Print@{Print}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Print()}{Print()}}
{\footnotesize\ttfamily \label{class_tensor_a5e012653a230fcafd531ac6063e0067a} 
void Tensor\+::\+Print (\begin{DoxyParamCaption}\item[{int}]{depth}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Prints the tensor contents to standard output in a readable, nested format. 

This method displays the tensor\textquotesingle{}s structure and values in a Num\+Py-\/like format with appropriate indentation for multi-\/dimensional tensors. It recursively prints nested structures, making it easy to visualize the tensor\textquotesingle{}s shape and data.

Special cases\+:
\begin{DoxyItemize}
\item Empty tensors are printed as {\ttfamily \mbox{[}\mbox{]}}
\item Scalar tensors print the single value directly
\item Multi-\/dimensional tensors use nested brackets with indentation
\end{DoxyItemize}


\begin{DoxyParams}{Parameters}
{\em depth} & Internal indentation level used during recursive printing. This parameter is automatically managed and should not be modified by users. Default is 0 (no indentation).\\
\hline
\end{DoxyParams}
\begin{DoxyNote}{Note}
This method is primarily intended for debugging and inspection. For programmatic string representation, consider implementing a To\+String() method.

The output format includes\+:
\begin{DoxyItemize}
\item Newlines and indentation for readability in multi-\/dimensional tensors
\item Commas between elements
\item Nested brackets representing each dimension
\end{DoxyItemize}

This method uses the const indexing operator {\ttfamily \mbox{[}\mbox{]}} internally, which triggers the conversion from \doxylink{class_tensor_slice}{Tensor\+Slice} to \doxylink{class_tensor}{Tensor}, creating temporary copies during recursion. 
\end{DoxyNote}
\Hypertarget{class_tensor_ae00c340a459f86d5053466a73ef210e4}\index{Tensor@{Tensor}!Rank@{Rank}}
\index{Rank@{Rank}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Rank()}{Rank()}}
{\footnotesize\ttfamily \label{class_tensor_ae00c340a459f86d5053466a73ef210e4} 
int Tensor\+::\+Rank (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Returns the rank (number of dimensions) of the tensor. 

The rank represents the number of axes or dimensions in the tensor. For example, a scalar has rank 0, a vector has rank 1, a matrix has rank 2, etc.

\begin{DoxyReturn}{Returns}
The rank of the tensor as an integer.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
A scalar tensor (single value) has rank 0. 

An empty tensor also reports its rank correctly based on its shape. 
\end{DoxyNote}
\Hypertarget{class_tensor_a4f4b299f874a72509a053c270bbb0aa9}\index{Tensor@{Tensor}!ReduceMax@{ReduceMax}}
\index{ReduceMax@{ReduceMax}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ReduceMax()}{ReduceMax()}}
{\footnotesize\ttfamily \label{class_tensor_a4f4b299f874a72509a053c270bbb0aa9} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Reduce\+Max (\begin{DoxyParamCaption}\item[{int}]{axis}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the maximum. 

Finds the maximum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to find the maximum. Must satisfy\+: 0 ≤ axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing maximum values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 
\end{DoxyNote}
\Hypertarget{class_tensor_a279fd0fb9be2315140b21feeb2e51034}\index{Tensor@{Tensor}!ReduceMean@{ReduceMean}}
\index{ReduceMean@{ReduceMean}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ReduceMean()}{ReduceMean()}}
{\footnotesize\ttfamily \label{class_tensor_a279fd0fb9be2315140b21feeb2e51034} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Reduce\+Mean (\begin{DoxyParamCaption}\item[{int}]{axis}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the mean (average). 

Computes the arithmetic mean of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to compute the mean. Must satisfy\+: 0 ≤ axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing means.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 

Implemented as Reduce\+Sum(axis) / size. 
\end{DoxyNote}
\Hypertarget{class_tensor_a3e92b91cfe84cfd666751d7f5431a642}\index{Tensor@{Tensor}!ReduceMin@{ReduceMin}}
\index{ReduceMin@{ReduceMin}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ReduceMin()}{ReduceMin()}}
{\footnotesize\ttfamily \label{class_tensor_a3e92b91cfe84cfd666751d7f5431a642} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Reduce\+Min (\begin{DoxyParamCaption}\item[{int}]{axis}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the minimum. 

Finds the minimum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to find the minimum. Must satisfy\+: 0 ≤ axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing minimum values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 
\end{DoxyNote}
\Hypertarget{class_tensor_a34014716594913b10f8c606c0b0389de}\index{Tensor@{Tensor}!ReduceSum@{ReduceSum}}
\index{ReduceSum@{ReduceSum}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ReduceSum()}{ReduceSum()}}
{\footnotesize\ttfamily \label{class_tensor_a34014716594913b10f8c606c0b0389de} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Reduce\+Sum (\begin{DoxyParamCaption}\item[{int}]{axis}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the sum. 

Computes the sum of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to compute the sum. Must satisfy\+: 0 ≤ axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing sums.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 
\end{DoxyNote}
\Hypertarget{class_tensor_aa5366dcad0b31362b2c4a42c7452adcf}\index{Tensor@{Tensor}!ReduceVar@{ReduceVar}}
\index{ReduceVar@{ReduceVar}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ReduceVar()}{ReduceVar()}}
{\footnotesize\ttfamily \label{class_tensor_aa5366dcad0b31362b2c4a42c7452adcf} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Reduce\+Var (\begin{DoxyParamCaption}\item[{int}]{axis}{ = {\ttfamily 0}, }\item[{bool}]{inference}{ = {\ttfamily false}}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the variance. 

Computes the variance of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.

Variance measures how spread out the values are from their mean.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to compute the variance. Must satisfy\+: 0 ≤ axis \texorpdfstring{$<$}{<} rank. Default is 0. \\
\hline
{\em inference} & If true, uses Bessel\textquotesingle{}s correction (divides by n-\/1 for sample variance). If false, divides by n (population variance). Default is false.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing variances.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 

Formula\+: Var = sum((x -\/ mean)²) / n (or n-\/1 if inference=true) 
\end{DoxyNote}
\Hypertarget{class_tensor_a50ffbfbb2e300be5346c894226d72812}\index{Tensor@{Tensor}!Reshape@{Reshape}}
\index{Reshape@{Reshape}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Reshape()}{Reshape()}}
{\footnotesize\ttfamily \label{class_tensor_a50ffbfbb2e300be5346c894226d72812} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Reshape (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{new\+\_\+shape}{}\end{DoxyParamCaption}) const}



Reshapes the \doxylink{class_tensor}{Tensor} to a new specified shape without changing data order. 

Creates a new \doxylink{class_tensor}{Tensor} with the given shape, containing the same data elements in the same row-\/major order. The total number of elements (volume) must remain constant. This operation does not reorder or modify the data; it only changes how the flat data is interpreted dimensionally.


\begin{DoxyParams}{Parameters}
{\em new\+\_\+shape} & A vector of positive integers representing the desired dimensions. All dimensions must be greater than 0. The product of all dimensions must equal the current volume.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified shape and the same data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The new\+\_\+shape contains any non-\/positive dimensions (i.\+e., any dimension ? 0).
\item The volume implied by new\+\_\+shape does not match the current \doxylink{class_tensor}{Tensor}\textquotesingle{}s volume.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

Only the shape metadata changes; data is copied but not reordered. 
\end{DoxyNote}
\Hypertarget{class_tensor_a0f50736794c3594411fe96aeb337b7b5}\index{Tensor@{Tensor}!Round@{Round}}
\index{Round@{Round}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Round()}{Round()}}
{\footnotesize\ttfamily \label{class_tensor_a0f50736794c3594411fe96aeb337b7b5} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Round (\begin{DoxyParamCaption}\item[{int}]{decimal\+\_\+place}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Rounds each element to a specified number of decimal places. 

Returns a new tensor where each element is rounded to the nearest value with the specified number of decimal places. Uses standard rounding rules (round half to even / banker\textquotesingle{}s rounding).


\begin{DoxyParams}{Parameters}
{\em decimal\+\_\+place} & The number of decimal places to round to. Must be non-\/negative (≥ 0). Default is 0 (round to nearest integer).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing rounded values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if decimal\+\_\+place is negative (\texorpdfstring{$<$}{<} 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a85eaa3e12b1a044e82d5f5912460aee8}\index{Tensor@{Tensor}!Sec@{Sec}}
\index{Sec@{Sec}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Sec()}{Sec()}}
{\footnotesize\ttfamily \label{class_tensor_a85eaa3e12b1a044e82d5f5912460aee8} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Sec (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the secant (reciprocal of cosine) of each element (in radians). 

Returns a new tensor where each element is the secant (1/cos(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The secant function is undefined at odd multiples of π/2 (where cosine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing secant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately an odd multiple of π/2 (where secant is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by π/180. 
\end{DoxyNote}
\Hypertarget{class_tensor_a03d0593a8715bad32098cbda433451f1}\index{Tensor@{Tensor}!Sech@{Sech}}
\index{Sech@{Sech}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Sech()}{Sech()}}
{\footnotesize\ttfamily \label{class_tensor_a03d0593a8715bad32098cbda433451f1} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Sech (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element. 

Returns a new tensor where each element is the hyperbolic secant (1/cosh(x)) of the corresponding element in the original tensor.

The hyperbolic secant is always positive and has range (0, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic secant values in the range (0, 1\mbox{]}.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if numerical instability is detected (extremely rare).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_adb8cd0e538a8410157ca2a17a5055f02}\index{Tensor@{Tensor}!Shape@{Shape}}
\index{Shape@{Shape}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Shape()}{Shape()}}
{\footnotesize\ttfamily \label{class_tensor_adb8cd0e538a8410157ca2a17a5055f02} 
std\+::vector$<$ int $>$ Tensor\+::\+Shape (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Returns the shape of the tensor as a vector of dimension sizes. 

The shape describes the size of each dimension in the tensor. For example, shape \{2, 3, 4\} represents a 3D tensor with 2 slices, each containing a 3×4 matrix.

\begin{DoxyReturn}{Returns}
A vector of integers representing the size of each dimension.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
For a scalar tensor (rank 0), this returns an empty vector. 

The returned vector is a copy; modifying it does not affect the tensor. 
\end{DoxyNote}
\Hypertarget{class_tensor_af2642442d55d275a7a21fca2e3dfb4b5}\index{Tensor@{Tensor}!Sign@{Sign}}
\index{Sign@{Sign}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Sign()}{Sign()}}
{\footnotesize\ttfamily \label{class_tensor_af2642442d55d275a7a21fca2e3dfb4b5} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Sign (\begin{DoxyParamCaption}\item[{bool}]{heaviside}{ = {\ttfamily false}}\end{DoxyParamCaption}) const}



Computes the sign function element-\/wise. 

Returns a new tensor where each element is\+:
\begin{DoxyItemize}
\item 1.\+0 if the original element is positive
\item -\/1.\+0 if the original element is negative
\item 0.\+0 if the original element is approximately zero (\texorpdfstring{$\vert$}{|}x\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE)
\end{DoxyItemize}

If the Heaviside step function mode is enabled, zero values are mapped to 1.\+0 instead of 0.\+0.


\begin{DoxyParams}{Parameters}
{\em heaviside} & If true, uses Heaviside step function (maps 0 → 1). If false, uses standard sign function (maps 0 → 0). Default is false.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing sign values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a7183546c868b2cac8075f0434376dccb}\index{Tensor@{Tensor}!Sin@{Sin}}
\index{Sin@{Sin}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Sin()}{Sin()}}
{\footnotesize\ttfamily \label{class_tensor_a7183546c868b2cac8075f0434376dccb} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Sin (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the sine of each element (in radians). 

Returns a new tensor where each element is the sine of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The sine function maps any real number to the range \mbox{[}-\/1, 1\mbox{]} and is periodic with period 2π.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing sine values in the range \mbox{[}-\/1, 1\mbox{]}.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by π/180. 
\end{DoxyNote}
\Hypertarget{class_tensor_a2cbc29f90925cf18d54d62d9cc6ebbe3}\index{Tensor@{Tensor}!Sinh@{Sinh}}
\index{Sinh@{Sinh}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Sinh()}{Sinh()}}
{\footnotesize\ttfamily \label{class_tensor_a2cbc29f90925cf18d54d62d9cc6ebbe3} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Sinh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic sine of each element. 

Returns a new tensor where each element is the hyperbolic sine of the corresponding element in the original tensor. The hyperbolic sine is defined as\+: sinh(x) = (e\texorpdfstring{$^\wedge$}{\string^}x -\/ e\texorpdfstring{$^\wedge$}{\string^}(-\/x)) / 2

The hyperbolic sine function is defined for all real numbers and is an odd function.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic sine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_acdf40158e4bd7edd14f59bfc2c52ff92}\index{Tensor@{Tensor}!Slice@{Slice}}
\index{Slice@{Slice}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Slice()}{Slice()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_acdf40158e4bd7edd14f59bfc2c52ff92} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Slice (\begin{DoxyParamCaption}\item[{int}]{axis}{, }\item[{int}]{index}{}\end{DoxyParamCaption}) const}



Extracts a slice of the \doxylink{class_tensor}{Tensor} along a specified axis at a given index. 

This method returns a new \doxylink{class_tensor}{Tensor} representing a lower-\/rank slice of the current \doxylink{class_tensor}{Tensor}, taken along the specified axis at a particular index position. The operation performs a deep copy of the relevant data region, so the resulting \doxylink{class_tensor}{Tensor} is completely independent of the original.

The rank of the returned \doxylink{class_tensor}{Tensor} is {\ttfamily rank -\/ 1}, as the specified axis is removed. For example, slicing a (2, 3, 4) tensor along axis 1 at index 0 produces a (2, 4) tensor.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to slice. Must satisfy\+: {\ttfamily 0 ≤ axis \texorpdfstring{$<$}{<} rank}. \\
\hline
{\em index} & The index position along the given axis to extract. Must satisfy\+: {\ttfamily 0 ≤ index \texorpdfstring{$<$}{<} shape\mbox{[}axis\mbox{]}}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} slice with one fewer dimension (rank reduced by 1).
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The \doxylink{class_tensor}{Tensor} is empty (volume = 0).
\item The \doxylink{class_tensor}{Tensor} is a scalar (rank = 0).
\end{DoxyItemize}\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item The axis is negative or \texorpdfstring{$>$}{>}= rank.
\item The index is negative or \texorpdfstring{$>$}{>}= shape\mbox{[}axis\mbox{]}.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a copy-\/based operation. The returned \doxylink{class_tensor}{Tensor} has its own independent data buffer and does not share memory with the original.

This operation efficiently extracts non-\/contiguous data using stride information. 
\end{DoxyNote}
\Hypertarget{class_tensor_ad2a6207e2f4dcb9571e4530490fcd439}\index{Tensor@{Tensor}!Slice@{Slice}}
\index{Slice@{Slice}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Slice()}{Slice()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_ad2a6207e2f4dcb9571e4530490fcd439} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Slice (\begin{DoxyParamCaption}\item[{int}]{axis}{, }\item[{int}]{index\+\_\+from}{, }\item[{int}]{index\+\_\+upto}{}\end{DoxyParamCaption}) const}



Extracts a range of slices from the \doxylink{class_tensor}{Tensor} along a given axis. 

This method performs slicing between two indices ({\ttfamily index\+\_\+from} inclusive and {\ttfamily index\+\_\+upto} exclusive) along the specified axis. Each individual slice is extracted using the single-\/index {\ttfamily \doxylink{class_tensor_acdf40158e4bd7edd14f59bfc2c52ff92}{Slice()}} method, and the results are stacked together along the same axis to form a contiguous sub-\/tensor.

The rank of the returned \doxylink{class_tensor}{Tensor} remains the same as the original. The dimension along the specified axis is reduced to {\ttfamily index\+\_\+upto -\/ index\+\_\+from}.

Like single-\/index slicing, this is a {\bfseries{copy-\/based}} operation resulting in an independent \doxylink{class_tensor}{Tensor} with no shared data.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to slice. Must satisfy\+: {\ttfamily 0 ≤ axis \texorpdfstring{$<$}{<} rank}.\\
\hline
{\em index\+\_\+from} & The starting index (inclusive) along the axis. Must satisfy\+: {\ttfamily 0 ≤ index\+\_\+from \texorpdfstring{$<$}{<} index\+\_\+upto}.\\
\hline
{\em index\+\_\+upto} & The ending index (exclusive) along the axis. Must satisfy\+: {\ttfamily index\+\_\+from \texorpdfstring{$<$}{<} index\+\_\+upto ≤ shape\mbox{[}axis\mbox{]}}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} formed by stacking the specified slices along the same axis.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The \doxylink{class_tensor}{Tensor} is empty (volume = 0).
\item The \doxylink{class_tensor}{Tensor} is a scalar (rank = 0).
\end{DoxyItemize}\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item The axis is negative or \texorpdfstring{$>$}{>}= rank.
\item {\ttfamily index\+\_\+from} is negative or {\ttfamily index\+\_\+upto} is \texorpdfstring{$>$}{>} shape\mbox{[}axis\mbox{]}.
\end{DoxyItemize}\\
\hline
{\em std\+::invalid\+\_\+argument} & if {\ttfamily index\+\_\+from \texorpdfstring{$>$}{>}= index\+\_\+upto} (invalid range specification).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a copy-\/based operation. The returned \doxylink{class_tensor}{Tensor} has its own independent data buffer.

Internally, this method calls {\ttfamily Slice(axis, index)} for each index in the range and uses {\ttfamily \doxylink{class_tensor_a7d2ad35ec705991518a2ecbec8ffd318}{Stack()}} to combine them. 
\end{DoxyNote}
\Hypertarget{class_tensor_a4c7df16dc4a4fc10cbdf5bfa20e25ba7}\index{Tensor@{Tensor}!Sqrt@{Sqrt}}
\index{Sqrt@{Sqrt}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Sqrt()}{Sqrt()}}
{\footnotesize\ttfamily \label{class_tensor_a4c7df16dc4a4fc10cbdf5bfa20e25ba7} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Sqrt (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the square root of each element. 

Returns a new tensor where each element is the square root of the corresponding element in the original tensor. This is equivalent to raising each element to the power of 0.\+5.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing square root values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is negative (square root undefined for negative reals).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

For negative values, consider using \doxylink{class_tensor_aa9330e265d36beb2e217c75f6a03a41e}{Abs()} first if magnitude is desired. 
\end{DoxyNote}
\Hypertarget{class_tensor_a7d2ad35ec705991518a2ecbec8ffd318}\index{Tensor@{Tensor}!Stack@{Stack}}
\index{Stack@{Stack}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Stack()}{Stack()}}
{\footnotesize\ttfamily \label{class_tensor_a7d2ad35ec705991518a2ecbec8ffd318} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Stack (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ \mbox{\hyperlink{class_tensor}{Tensor}} $>$ \&}]{tensors}{, }\item[{int}]{axis}{ = {\ttfamily 0}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Stacks multiple Tensors along a new dimension. 

This static method combines a vector of Tensors by introducing a new axis at the specified position. Unlike concatenation (which joins along an existing axis), stacking creates a new dimension and increases the rank by 1.

All input tensors must have identical shapes. Each tensor is first expanded to include a new dimension of size 1 at the specified axis position using \doxylink{class_tensor_aa5215a8751f54d02e66b38c4982537f9}{Expand\+Rank()}, then all expanded tensors are concatenated along that new axis.

The resulting tensor has rank = {\ttfamily original\+\_\+rank + 1}, with the new dimension\textquotesingle{}s size equal to the number of tensors being stacked.


\begin{DoxyParams}{Parameters}
{\em tensors} & A vector of Tensors to stack. Must not be empty. All tensors must have identical shapes.\\
\hline
{\em axis} & The position where the new dimension will be inserted. Must satisfy\+: {\ttfamily 0 ≤ axis ≤ rank}. Default is 0 (stack along the outermost dimension).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with rank increased by 1, containing all stacked tensors.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The tensors vector is empty.
\item Tensors have different shapes (all shapes must match exactly).
\end{DoxyItemize}\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item The axis is negative.
\item The axis is greater than the tensors\textquotesingle{} rank.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a static method -\/ call it as {\ttfamily \doxylink{class_tensor_a7d2ad35ec705991518a2ecbec8ffd318}{Tensor\+::\+Stack}(\{t1, t2, t3\})}.

Internally, this method expands each tensor\textquotesingle{}s rank at the specified axis, then concatenates them using \doxylink{class_tensor_a4d525a3d5051c3a704db5a254b654706}{Concat()}. 
\end{DoxyNote}
\Hypertarget{class_tensor_adb9ce076a4629b3bbc897e17f39b7573}\index{Tensor@{Tensor}!Sum@{Sum}}
\index{Sum@{Sum}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Sum()}{Sum()}}
{\footnotesize\ttfamily \label{class_tensor_adb9ce076a4629b3bbc897e17f39b7573} 
double Tensor\+::\+Sum (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the sum of all elements in the tensor. 

Returns the sum of all elements as a scalar value. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The sum of all elements.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
\end{DoxyExceptions}
\Hypertarget{class_tensor_a8148f97acf80f5e6aa685544ecc22be2}\index{Tensor@{Tensor}!Tan@{Tan}}
\index{Tan@{Tan}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Tan()}{Tan()}}
{\footnotesize\ttfamily \label{class_tensor_a8148f97acf80f5e6aa685544ecc22be2} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Tan (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the tangent of each element (in radians). 

Returns a new tensor where each element is the tangent of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The tangent function is undefined at odd multiples of π/2 (where cosine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing tangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately an odd multiple of π/2 (where tangent is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by π/180. 
\end{DoxyNote}
\Hypertarget{class_tensor_aee8ad1fde49129b199ad87b4dd85c07f}\index{Tensor@{Tensor}!Tanh@{Tanh}}
\index{Tanh@{Tanh}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Tanh()}{Tanh()}}
{\footnotesize\ttfamily \label{class_tensor_aee8ad1fde49129b199ad87b4dd85c07f} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Tanh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic tangent of each element. 

Returns a new tensor where each element is the hyperbolic tangent of the corresponding element in the original tensor. The hyperbolic tangent is defined as\+: tanh(x) = sinh(x) / cosh(x) = (e\texorpdfstring{$^\wedge$}{\string^}x -\/ e\texorpdfstring{$^\wedge$}{\string^}(-\/x)) / (e\texorpdfstring{$^\wedge$}{\string^}x + e\texorpdfstring{$^\wedge$}{\string^}(-\/x))

The hyperbolic tangent function is defined for all real numbers, is an odd function, and has range (-\/1, 1).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic tangent values in the range (-\/1, 1).
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_abde6f09589147296a9035bce10cc8c49}\index{Tensor@{Tensor}!TensorDot@{TensorDot}}
\index{TensorDot@{TensorDot}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{TensorDot()}{TensorDot()}}
{\footnotesize\ttfamily \label{class_tensor_abde6f09589147296a9035bce10cc8c49} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Tensor\+Dot (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor\+\_\+1}{, }\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor\+\_\+2}{, }\item[{const std\+::vector$<$ int $>$ \&}]{contract\+\_\+axes\+\_\+1}{, }\item[{const std\+::vector$<$ int $>$ \&}]{contract\+\_\+axes\+\_\+2}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Performs generalized tensor contraction over specified axes. 

Tensor\+Dot computes a generalized dot product by contracting (summing over) specified axes of two tensors. The contracted axes must have matching dimensions and are paired in order\+: contract\+\_\+axes\+\_\+1\mbox{[}i\mbox{]} contracts with contract\+\_\+axes\+\_\+2\mbox{[}i\mbox{]}.

This is a generalization of matrix multiplication, where you can choose which axes to contract. The contracted axes disappear from the result, and the remaining axes from both tensors are concatenated\+: \mbox{[}remaining\+\_\+axes\+\_\+1, remaining\+\_\+axes\+\_\+2\mbox{]}.

Mathematical formulation\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{result[i,j,...,m,n,...]\ =\ Σ\ tensor\_1[i,j,...,k₁,k₂,...]\ ×\ tensor\_2[k₁,k₂,...,m,n,...]}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ k₁,k₂,...}

\end{DoxyCode}



\begin{DoxyParams}{Parameters}
{\em tensor\+\_\+1} & The first tensor. \\
\hline
{\em tensor\+\_\+2} & The second tensor. \\
\hline
{\em contract\+\_\+axes\+\_\+1} & Axes of tensor\+\_\+1 to contract. Must contain unique values in range \mbox{[}0, rank\+\_\+1). \\
\hline
{\em contract\+\_\+axes\+\_\+2} & Axes of tensor\+\_\+2 to contract. Must contain unique values in range \mbox{[}0, rank\+\_\+2).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with contracted axes removed and remaining axes concatenated.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & if any axis index is negative or \texorpdfstring{$>$}{>}= tensor rank. \\
\hline
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item Either contract\+\_\+axes vector contains duplicate values.
\item The number of axes to contract doesn\textquotesingle{}t match (contract\+\_\+axes\+\_\+1.\+size() != contract\+\_\+axes\+\_\+2.\+size()).
\item Paired axes have different dimensions (tensor\+\_\+1.\+shape\mbox{[}contract\+\_\+axes\+\_\+1\mbox{[}i\mbox{]}\mbox{]} != tensor\+\_\+2.\+shape\mbox{[}contract\+\_\+axes\+\_\+2\mbox{[}i\mbox{]}\mbox{]}).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
Axes are contracted pairwise in order\+: contract\+\_\+axes\+\_\+1\mbox{[}i\mbox{]} contracts with contract\+\_\+axes\+\_\+2\mbox{[}i\mbox{]}. 

Empty axes vectors are valid and result in an outer product (no contraction). 

This operation creates a new independent \doxylink{class_tensor}{Tensor}. Input tensors remain unchanged. 
\end{DoxyNote}
\Hypertarget{class_tensor_a52b3acaaf5f1d9bad285fd7ae88399ac}\index{Tensor@{Tensor}!Tile@{Tile}}
\index{Tile@{Tile}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Tile()}{Tile()}}
{\footnotesize\ttfamily \label{class_tensor_a52b3acaaf5f1d9bad285fd7ae88399ac} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Tile (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{repetitions}{}\end{DoxyParamCaption}) const}



Repeats the entire tensor structure along each axis a specified number of times. 

This method creates a new \doxylink{class_tensor}{Tensor} by replicating the current tensor along each dimension. The repetitions vector specifies how many times to tile along each axis. The resulting tensor has shape {\ttfamily new\+\_\+shape\mbox{[}i\mbox{]} = original\+\_\+shape\mbox{[}i\mbox{]} \texorpdfstring{$\ast$}{*} repetitions\mbox{[}i\mbox{]}} for each axis i.

Unlike element-\/wise repetition, tiling repeats the entire structure as a block. For example, tiling \mbox{[}1,2,3\mbox{]} twice results in \mbox{[}1,2,3,1,2,3\mbox{]}, not \mbox{[}1,1,2,2,3,3\mbox{]}.

The operation proceeds from the innermost dimension (last axis) to the outermost (first axis), using concatenation to build up the tiled result incrementally.


\begin{DoxyParams}{Parameters}
{\em repetitions} & A vector specifying the number of repetitions along each axis. Must have the same length as the tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the tiled structure.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The repetitions vector size does not match the tensor\textquotesingle{}s rank.
\item Any repetition value is non-\/positive (≤ 0).
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The product of repetitions exceeds INT\+\_\+\+MAX.
\item The resulting total volume exceeds INT\+\_\+\+MAX.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

The total volume of the result is {\ttfamily original\+\_\+volume × product(repetitions)}.

For large tensors and many repetitions, this operation can be memory-\/intensive. 
\end{DoxyNote}
\Hypertarget{class_tensor_abd4b0bfabe2a7c378318d6132ec84936}\index{Tensor@{Tensor}!ToMatrix@{ToMatrix}}
\index{ToMatrix@{ToMatrix}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ToMatrix()}{ToMatrix()}}
{\footnotesize\ttfamily \label{class_tensor_abd4b0bfabe2a7c378318d6132ec84936} 
std\+::vector$<$ std\+::vector$<$ double $>$ $>$ Tensor\+::\+To\+Matrix (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Converts a rank-\/2 tensor to a 2D vector (matrix). 

Extracts all elements from a rank-\/2 tensor and returns them as a nested std\+::vector$<$std\+::vector$<$double$>$$>$. This is useful for interfacing with standard C++ code that expects 2D arrays or matrices.

The outer vector represents rows, and each inner vector represents the columns of that row.

\begin{DoxyReturn}{Returns}
A 2D vector containing all tensor elements organized by rows and columns.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is not rank-\/2 (not a matrix).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This creates a copy of the data. The original tensor is unchanged. 

Works correctly with sliced tensors (uses start and stride information). 
\end{DoxyNote}
\Hypertarget{class_tensor_ad3b998f18ac3263bf5e02b88026a166f}\index{Tensor@{Tensor}!ToScalar@{ToScalar}}
\index{ToScalar@{ToScalar}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ToScalar()}{ToScalar()}}
{\footnotesize\ttfamily \label{class_tensor_ad3b998f18ac3263bf5e02b88026a166f} 
double Tensor\+::\+To\+Scalar (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Converts a scalar tensor to a double value. 

Extracts and returns the single value from a rank-\/0 (scalar) tensor. This method only works on tensors with rank 0 and volume 1.

\begin{DoxyReturn}{Returns}
The scalar value as a double.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is not a scalar (rank \texorpdfstring{$>$}{>} 0 or volume != 1).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a convenience method for extracting scalar values from scalar tensors. 
\end{DoxyNote}
\Hypertarget{class_tensor_a577b089b89971b6ab7a1bfab790e4edc}\index{Tensor@{Tensor}!ToVector@{ToVector}}
\index{ToVector@{ToVector}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{ToVector()}{ToVector()}}
{\footnotesize\ttfamily \label{class_tensor_a577b089b89971b6ab7a1bfab790e4edc} 
std\+::vector$<$ double $>$ Tensor\+::\+To\+Vector (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Converts a rank-\/1 tensor to a standard vector. 

Extracts all elements from a rank-\/1 tensor and returns them as a std\+::vector$<$double$>$. This is useful for interfacing with standard C++ code that expects vectors.

\begin{DoxyReturn}{Returns}
A std\+::vector$<$double$>$ containing all tensor elements in order.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is not rank-\/1 (not a vector).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This creates a copy of the data. The original tensor is unchanged. 

Works correctly with sliced tensors (uses start and end indices). 
\end{DoxyNote}
\Hypertarget{class_tensor_a699a4b1ec7d7d244e7c10643bf533f98}\index{Tensor@{Tensor}!Transpose@{Transpose}}
\index{Transpose@{Transpose}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Transpose()}{Transpose()}}
{\footnotesize\ttfamily \label{class_tensor_a699a4b1ec7d7d244e7c10643bf533f98} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+::\+Transpose (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{permutation}{}\end{DoxyParamCaption}) const}



Transposes (permutes) the tensor\textquotesingle{}s axes according to a specified permutation. 

This method rearranges the tensor\textquotesingle{}s dimensions by permuting its axes according to the provided permutation vector. Each element in the permutation specifies which original axis should be placed at that position in the result.

For example, permutation \{1, 0, 2\} swaps the first two axes while keeping the third axis unchanged. This is a generalization of matrix transpose to arbitrary dimensions.

The operation creates a new tensor with reordered dimensions and rearranged data to match the new axis order.


\begin{DoxyParams}{Parameters}
{\em permutation} & A vector specifying the new order of axes. Must have length equal to the tensor\textquotesingle{}s rank. Must be a valid permutation\+: contain each value from 0 to (rank-\/1) exactly once.
\begin{DoxyItemize}
\item permutation\mbox{[}i\mbox{]} = j means the j-\/th axis of the original tensor becomes the i-\/th axis of the result.
\end{DoxyItemize}\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with permuted axes and reordered data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The permutation size does not match the tensor\textquotesingle{}s rank.
\item The permutation contains negative values.
\item The permutation contains values \texorpdfstring{$>$}{>}= rank.
\item The permutation contains duplicate values (not a valid permutation).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The data is physically reordered to match the new axis layout, making subsequent access efficient. 
\end{DoxyNote}
\Hypertarget{class_tensor_ac9b2a793615586ac29b2e7215261b844}\index{Tensor@{Tensor}!UniqueData@{UniqueData}}
\index{UniqueData@{UniqueData}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{UniqueData()}{UniqueData()}}
{\footnotesize\ttfamily \label{class_tensor_ac9b2a793615586ac29b2e7215261b844} 
void Tensor\+::\+Unique\+Data (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption})}



Ensures this \doxylink{class_tensor}{Tensor} has unique ownership of its data buffer. 

If the underlying data buffer is shared with other \doxylink{class_tensor}{Tensor} objects (use\+\_\+count() \texorpdfstring{$>$}{>} 1), this method creates an independent copy of the data range \mbox{[}start, end) and detaches from the shared buffer. After this call, modifications to this \doxylink{class_tensor}{Tensor}\textquotesingle{}s data will not affect any other \doxylink{class_tensor}{Tensor}.

If the \doxylink{class_tensor}{Tensor} already has unique ownership (use\+\_\+count() == 1) or is empty, this method does nothing.

\begin{DoxyNote}{Note}
This method is called internally before in-\/place modifications to ensure safe data manipulation without affecting other tensors that may share the buffer.

After calling this method, start is reset to 0 and end is set to volume, ensuring the tensor represents the complete data range.
\end{DoxyNote}

\begin{DoxyExceptions}{Exceptions}
{\em None} & {\ucr} this method never throws exceptions.\\
\hline
\end{DoxyExceptions}
\begin{DoxySeeAlso}{See also}
Set\+Slice(), Set\+Slice\+Chain(), Append\+Inplace() 
\end{DoxySeeAlso}
\Hypertarget{class_tensor_aceb3777b0c462d3596781b6031a234b6}\index{Tensor@{Tensor}!Var@{Var}}
\index{Var@{Var}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Var()}{Var()}}
{\footnotesize\ttfamily \label{class_tensor_aceb3777b0c462d3596781b6031a234b6} 
double Tensor\+::\+Var (\begin{DoxyParamCaption}\item[{bool}]{inference}{ = {\ttfamily false}}\end{DoxyParamCaption}) const}



Computes the variance of all elements in the tensor. 

Returns the variance of all elements as a scalar value. Variance measures how spread out the values are from their mean. This is a global reduction operation across the entire tensor.


\begin{DoxyParams}{Parameters}
{\em inference} & If true, uses Bessel\textquotesingle{}s correction (divides by n-\/1 for sample variance). If false, divides by n (population variance). Default is false.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The variance of all elements.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
Formula\+: Var = sum((x -\/ mean)²) / n (or n-\/1 if inference=true) 
\end{DoxyNote}
\Hypertarget{class_tensor_ad7155b38d35344550fde1eeb7f0fbd61}\index{Tensor@{Tensor}!Volume@{Volume}}
\index{Volume@{Volume}!Tensor@{Tensor}}
\doxysubsubsection{\texorpdfstring{Volume()}{Volume()}}
{\footnotesize\ttfamily \label{class_tensor_ad7155b38d35344550fde1eeb7f0fbd61} 
int Tensor\+::\+Volume (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Returns the total number of elements (volume) in the tensor. 

The volume is the product of all dimensions in the tensor\textquotesingle{}s shape. It represents the total count of scalar values stored in the tensor.

\begin{DoxyReturn}{Returns}
The total number of elements as an integer.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
For an empty tensor and scalar tensor, this returns 0. 
\end{DoxyNote}


The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
Tensor.\+h\item 
Tensor.\+cpp\end{DoxyCompactItemize}
