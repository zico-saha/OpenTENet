\doxysection{Tensor\+Slice Class Reference}
\hypertarget{class_tensor_slice}{}\label{class_tensor_slice}\index{TensorSlice@{TensorSlice}}


Proxy class for tensor indexing that enables both copy and reference semantics.  




{\ttfamily \#include $<$Tensor\+Slice.\+h$>$}

\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_tensor_slice_ad6c7cb02037ef9c8be85e75f3d8295f5}{Tensor\+Slice}} (\mbox{\hyperlink{class_tensor}{Tensor}} \texorpdfstring{$\ast$}{*}p, int idx)
\begin{DoxyCompactList}\small\item\em Constructs a \doxylink{class_tensor_slice}{Tensor\+Slice} for a single index. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice_a55c5c65bc9c909bdad1c45e188c2e99b}{operator Tensor}} () const
\begin{DoxyCompactList}\small\item\em Implicit conversion to \doxylink{class_tensor}{Tensor} (creates an independent copy). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_a725be809a7e2f9903fe1aa7bbfc7d425}{operator=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&other)
\begin{DoxyCompactList}\small\item\em Assignment operator that modifies the root parent tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \mbox{\hyperlink{class_tensor_slice_a36b4453303b38372b6b48b83bead2e45}{operator\mbox{[}$\,$\mbox{]}}} (int idx)
\begin{DoxyCompactList}\small\item\em Non-\/const indexing for continued chaining with modification capability. \end{DoxyCompactList}\item 
\Hypertarget{class_tensor_slice_a9c53a0466348635b4b8a50f057a48d62}\label{class_tensor_slice_a9c53a0466348635b4b8a50f057a48d62} 
\mbox{\hyperlink{class_tensor}{Tensor}} {\bfseries operator\mbox{[}$\,$\mbox{]}} (int idx) const
\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a891cda49b0e34178a9abeab88481066f}{operator+}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise addition of a scalar value to all tensor elements. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a30c1e8fe8a68609fda529a1ad6602724}{operator-\/}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise subtraction of a scalar value from all tensor elements. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_af184ad77fc278974efbbcfce8be97e20}{operator\texorpdfstring{$\ast$}{*}}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise multiplication of all tensor elements by a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_add3ca72dfa58d4f0d443da639fdb576b}{operator/}} (double value) const
\begin{DoxyCompactList}\small\item\em Element-\/wise division of all tensor elements by a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a5cbf99706365813b2d14ddf63a9b9624}{operator+}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise addition of two tensors. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ab31a85076571882207207be11c70cd34}{operator-\/}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise subtraction of two tensors. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_abd2662558437bf0032085e5a483520d3}{operator\texorpdfstring{$\ast$}{*}}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise multiplication of two tensors (Hadamard product). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a67aee1af10009acf23649fdae6e3dc49}{operator/}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Element-\/wise division of two tensors. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_a0a6c7af8296371c02d00f53b6aa3400a}{operator+=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise addition of a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_a953cf784473905860747b49166078421}{operator-\/=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise subtraction of a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_a6fb8999e863da0cd422494ea8936e3bb}{operator\texorpdfstring{$\ast$}{*}=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise multiplication by a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_ac0cfe800f5166e780913c459085c5240}{operator/=}} (double value)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise division by a scalar value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_af81661b65d4ef9a66109c5e2354e0621}{operator+=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise addition with another tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_ad456ffc088943ad62eea57a8c80f05d7}{operator-\/=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise subtraction with another tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_a79372cfb766492f6d4a0beb236eca244}{operator\texorpdfstring{$\ast$}{*}=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise multiplication with another tensor (Hadamard product). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& \mbox{\hyperlink{class_tensor_slice_a1763727eccb717b5359293923576bf43}{operator/=}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor)
\begin{DoxyCompactList}\small\item\em In-\/place element-\/wise division by another tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a324cf2ea9cc02476c25de1d4069468b0}{Reshape}} (const std\+::vector$<$ int $>$ \&new\+\_\+shape) const
\begin{DoxyCompactList}\small\item\em Reshapes the \doxylink{class_tensor}{Tensor} to a new specified shape without changing data order. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_aecd6af41dcc4e4a825408736216982a9}{Expand\+Rank}} (int axis=0) const
\begin{DoxyCompactList}\small\item\em Expands the rank of the \doxylink{class_tensor}{Tensor} by inserting a dimension of size 1 at a specified axis. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a7037d4e167e55ad888dd1d9dac6b39eb}{Flatten}} (int axis\+\_\+from, int axis\+\_\+upto) const
\begin{DoxyCompactList}\small\item\em Flattens a range of consecutive axes into a single dimension. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_adebcfb3b75b9a42ddfac2766c6ea0acc}{Slice}} (int axis, int index) const
\begin{DoxyCompactList}\small\item\em Extracts a slice of the \doxylink{class_tensor}{Tensor} along a specified axis at a given index. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ab26b29a1be6c026364c9210307dcffde}{Slice}} (int axis, int index\+\_\+from, int index\+\_\+upto) const
\begin{DoxyCompactList}\small\item\em Extracts a range of slices from the \doxylink{class_tensor}{Tensor} along a given axis. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a44621cdd09df688b2c5cb4bd000d8f73}{Pad}} (int axis, int pad\+\_\+before, int pad\+\_\+after, double value=0.\+0) const
\begin{DoxyCompactList}\small\item\em Adds padding elements before and/or after the tensor along a specified axis. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ad0e4432eeecf83eb8f93d026cea106f3}{Tile}} (const std\+::vector$<$ int $>$ \&repetitions) const
\begin{DoxyCompactList}\small\item\em Repeats the entire tensor structure along each axis a specified number of times. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a26aebba00b9e12f161384198295678f0}{Broadcast}} (const std\+::vector$<$ int $>$ \&shape) const
\begin{DoxyCompactList}\small\item\em Broadcasts the tensor to a target shape following Num\+Py-\/style broadcasting rules. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ae1ce3b94498a11ea3f83a2c98d0f523f}{Transpose}} (const std\+::vector$<$ int $>$ \&permutation) const
\begin{DoxyCompactList}\small\item\em Transposes (permutes) the tensor\textquotesingle{}s axes according to a specified permutation. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a30214f0ea0c3c3163bd05ca52c7dc95c}{Mat\+Mul}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&tensor) const
\begin{DoxyCompactList}\small\item\em Performs matrix multiplication with another tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a8d2f2a27e468f2431a65cad597beec93}{Convolve}} (const \mbox{\hyperlink{class_tensor}{Tensor}} \&filter, const std\+::vector$<$ int $>$ \&strides, const std\+::vector$<$ int $>$ \&padding)
\begin{DoxyCompactList}\small\item\em Performs N-\/dimensional convolution between this tensor and a filter kernel. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a58d10d1fd229a260e8a9299a6b6208f3}{Max\+Pool}} (const std\+::vector$<$ int $>$ \&pool\+\_\+shape, const std\+::vector$<$ int $>$ \&strides=\{\})
\begin{DoxyCompactList}\small\item\em Performs max pooling operation by taking the maximum value within sliding windows. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ac7587c1151e35617411a27b786bb420c}{Min\+Pool}} (const std\+::vector$<$ int $>$ \&pool\+\_\+shape, const std\+::vector$<$ int $>$ \&strides=\{\})
\begin{DoxyCompactList}\small\item\em Performs min pooling operation by taking the minimum value within sliding windows. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a9d55201d57f76d5c94cf58eda3c35725}{Avg\+Pool}} (const std\+::vector$<$ int $>$ \&pool\+\_\+shape, const std\+::vector$<$ int $>$ \&strides=\{\})
\begin{DoxyCompactList}\small\item\em Performs average pooling operation by computing the mean value within sliding windows. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ada3970a1f99f8e389c6272d0e8f54944}{Sign}} (bool heaviside=false) const
\begin{DoxyCompactList}\small\item\em Computes the sign function element-\/wise. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_afe2ed01b32773724e684e9fe6090f531}{Reduce\+Sum}} (int axis) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the sum. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a0bc4030adf64e861696d2033f6fc08bb}{Reduce\+Mean}} (int axis) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the mean (average). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a0898917704e36edbd2b99779010f945e}{Reduce\+Var}} (int axis, bool inference=false) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the variance. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a581bc889132baeaafc6974c523c80189}{Reduce\+Max}} (int axis) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the maximum. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a0bd288decf47bfad24af8d46a70f2952}{Reduce\+Min}} (int axis) const
\begin{DoxyCompactList}\small\item\em Reduces the tensor along a specified axis by computing the minimum. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_slice_a5402ef990f310a0e47a776acc2020656}{Sum}} () const
\begin{DoxyCompactList}\small\item\em Computes the sum of all elements in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_slice_a1cc3aa9a38e6baba9ed12371986c45c2}{Mean}} () const
\begin{DoxyCompactList}\small\item\em Computes the mean (average) of all elements in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_slice_ade9abd7f940b3f1d50b16854f241abc3}{Var}} (bool inference=false) const
\begin{DoxyCompactList}\small\item\em Computes the variance of all elements in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_slice_a40baf8d6e10b1024e654af746e84a649}{Max}} () const
\begin{DoxyCompactList}\small\item\em Finds the maximum value in the tensor. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_slice_a0a7fb881f780412a2d39ca26089fb26e}{Min}} () const
\begin{DoxyCompactList}\small\item\em Finds the minimum value in the tensor. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a4eb8d65d3052ebac6c39c04326830b4b}{Abs}} () const
\begin{DoxyCompactList}\small\item\em Computes the absolute value of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a3fe9669c843cf233b390f01befe92280}{Floor}} () const
\begin{DoxyCompactList}\small\item\em Rounds each element down to the nearest integer (floor function). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a9636224ea3638818437a002240e36725}{Ceil}} () const
\begin{DoxyCompactList}\small\item\em Rounds each element up to the nearest integer (ceiling function). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ab07074813ba5a5f62a9246fe99d1430c}{Round}} (int decimal\+\_\+place=0) const
\begin{DoxyCompactList}\small\item\em Rounds each element to a specified number of decimal places. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_aef30c23712785dd04bd9e02ba41dc78b}{Clip}} (double min\+\_\+value, double max\+\_\+value) const
\begin{DoxyCompactList}\small\item\em Clips (clamps) each element to be within a specified range. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ab3b88de18822c6f21b4f846fc2a08651}{Power}} (double exponent) const
\begin{DoxyCompactList}\small\item\em Raises each element to a specified power (exponentiation).    \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a7709875a1c35f01cb88f26bd1ea3cfe1}{Sqrt}} () const
\begin{DoxyCompactList}\small\item\em Computes the square root of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a06db73fa0da2f9e770dcfe21cc14e828}{Log}} (double base=std\+::numbers\+::e) const
\begin{DoxyCompactList}\small\item\em Computes the logarithm of each element with a specified base. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ad2ec37ad613eebdab3c0bf8bba3e27ee}{Exp}} () const
\begin{DoxyCompactList}\small\item\em Computes e raised to the power of each element (exponential function). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a556db8ba686446c0412952d9405f42ba}{Mod}} (double mod\+\_\+value) const
\begin{DoxyCompactList}\small\item\em Computes the modulus (remainder) of each element divided by a value. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a13d0676062409a9e032ca58e0bf2d8ff}{Sin}} () const
\begin{DoxyCompactList}\small\item\em Computes the sine of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a50af8b385c36ce9ab4c707d96e131f30}{Cos}} () const
\begin{DoxyCompactList}\small\item\em Computes the cosine of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_af56814ea935d8ee7c8945f21d452025d}{Tan}} () const
\begin{DoxyCompactList}\small\item\em Computes the tangent of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ad69af858ebe61a0637ca0f8f4d05e4be}{Csc}} () const
\begin{DoxyCompactList}\small\item\em Computes the cosecant (reciprocal of sine) of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a0e1f2f379dd0ff1dcdffe924f7f1360c}{Sec}} () const
\begin{DoxyCompactList}\small\item\em Computes the secant (reciprocal of cosine) of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_af93c5440a098163158a3ef04a1286fe2}{Cot}} () const
\begin{DoxyCompactList}\small\item\em Computes the cotangent (reciprocal of tangent) of each element (in radians). \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a29a4acf502a0696d3e04c6d178f77a99}{Asin}} () const
\begin{DoxyCompactList}\small\item\em Computes the arcsine (inverse sine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a7a2ec909ae143cf9388ffe47cd331fcb}{Acos}} () const
\begin{DoxyCompactList}\small\item\em Computes the arccosine (inverse cosine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a519178f6b8e4ae40533c4d6030dee949}{Atan}} () const
\begin{DoxyCompactList}\small\item\em Computes the arctangent (inverse tangent) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_af3d3ab207245adb801b802f66b5fde73}{Acsc}} () const
\begin{DoxyCompactList}\small\item\em Computes the arccosecant (inverse cosecant) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a73b6144b9dd8e7e74951fe443bc4a849}{Asec}} () const
\begin{DoxyCompactList}\small\item\em Computes the arcsecant (inverse secant) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a95fc99ff4da0f51a8269cab2ae10086f}{Acot}} () const
\begin{DoxyCompactList}\small\item\em Computes the arccotangent (inverse cotangent) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_af9a20344356eae9d28baf7aab314b80b}{Sinh}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic sine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a8eb0360a00945e98f06285a16a4d66ee}{Cosh}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic cosine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a3298ee780337e0d515fe3b07e090a4bd}{Tanh}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic tangent of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a39e047e2b44d05b024fe15d884ac8df3}{Csch}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a44053a3ce4683ba4e4000b59555cf361}{Sech}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a47239a452da7a9bcac96b60d87882669}{Coth}} () const
\begin{DoxyCompactList}\small\item\em Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a3b512d0a8f019ec8d9f20e274525e799}{Asinh}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic sine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ae69b2212f5ed15bd6ae63cec84a57d8f}{Acosh}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic cosine of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ae6ea5e2eb62073e68c546b03a7561acb}{Atanh}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic tangent of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a85fe09e15d404b4a254eaec5fb1df4ca}{Acsch}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic cosecant of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_ade05697844f7212fa4aec69de25743c6}{Asech}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic secant of each element. \end{DoxyCompactList}\item 
\mbox{\hyperlink{class_tensor}{Tensor}} \mbox{\hyperlink{class_tensor_slice_a1acd6ad17fc6f224966a0804113f64a7}{Acoth}} () const
\begin{DoxyCompactList}\small\item\em Computes the inverse hyperbolic cotangent of each element. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{class_tensor_slice_a5d66ce8c7e459c2c6e9d2f2cc0c16ee3}{Rank}} () const
\begin{DoxyCompactList}\small\item\em Returns the rank (number of dimensions) of the tensor. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{class_tensor_slice_acfa02303d766c0d2399fe34a1943238d}{Volume}} () const
\begin{DoxyCompactList}\small\item\em Returns the total number of elements (volume) in the tensor. \end{DoxyCompactList}\item 
std\+::vector$<$ int $>$ \mbox{\hyperlink{class_tensor_slice_af773875332be2e70344d4a17429166ba}{Shape}} () const
\begin{DoxyCompactList}\small\item\em Returns the shape of the tensor as a vector of dimension sizes. \end{DoxyCompactList}\item 
bool \mbox{\hyperlink{class_tensor_slice_a847c00a1c549d33cebe3a4ef2f4d3b2f}{Is\+Empty}} () const
\begin{DoxyCompactList}\small\item\em Checks whether the tensor contains no elements. \end{DoxyCompactList}\item 
bool \mbox{\hyperlink{class_tensor_slice_a25b03c23ebc8f53112bd2b5083d981b7}{Is\+Scalar}} () const
\begin{DoxyCompactList}\small\item\em Checks whether the tensor represents a scalar (single) value. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_tensor_slice_ac4fca8605058c8dd92bc8bbb1eba2969}{Print}} (int depth=0) const
\begin{DoxyCompactList}\small\item\em Prints the tensor contents to standard output in a readable, nested format. \end{DoxyCompactList}\item 
double \mbox{\hyperlink{class_tensor_slice_aacca4d01deff58b2cb00aa0e0de4d3f8}{To\+Scalar}} () const
\begin{DoxyCompactList}\small\item\em Converts a scalar tensor to a double value. \end{DoxyCompactList}\item 
std\+::vector$<$ double $>$ \mbox{\hyperlink{class_tensor_slice_a6072465ba590c092c398bded85469fd4}{To\+Vector}} () const
\begin{DoxyCompactList}\small\item\em Converts a rank-\/1 tensor to a standard vector. \end{DoxyCompactList}\item 
std\+::vector$<$ std\+::vector$<$ double $>$ $>$ \mbox{\hyperlink{class_tensor_slice_ac0b56c26e6b0638e8be8512df974f2b9}{To\+Matrix}} () const
\begin{DoxyCompactList}\small\item\em Converts a rank-\/2 tensor to a 2D vector (matrix). \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Proxy class for tensor indexing that enables both copy and reference semantics. 

\doxylink{class_tensor_slice}{Tensor\+Slice} is returned by \doxylink{class_tensor}{Tensor}\textquotesingle{}s non-\/const operator\mbox{[}\mbox{]} and supports chained indexing. It allows modifications to propagate to the original tensor while also enabling independent copies when needed.

Key behaviors\+:
\begin{DoxyItemize}
\item Implicit conversion to \doxylink{class_tensor}{Tensor} creates an independent copy
\item Assignment modifies the original tensor through the index chain
\item Chaining indexing builds up a chain of indices
\item Pass-\/through methods delegate to the underlying \doxylink{class_tensor}{Tensor}
\end{DoxyItemize}

\begin{DoxyNote}{Note}
Users should use explicit {\ttfamily \doxylink{class_tensor}{Tensor}} type declarations to get independent copies, not {\ttfamily auto}, which would deduce \doxylink{class_tensor_slice}{Tensor\+Slice}. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}


\label{doc-constructors}
\Hypertarget{class_tensor_slice_doc-constructors}
\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{class_tensor_slice_ad6c7cb02037ef9c8be85e75f3d8295f5}\index{TensorSlice@{TensorSlice}!TensorSlice@{TensorSlice}}
\index{TensorSlice@{TensorSlice}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{TensorSlice()}{TensorSlice()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ad6c7cb02037ef9c8be85e75f3d8295f5} 
Tensor\+Slice\+::\+Tensor\+Slice (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{class_tensor}{Tensor}} \texorpdfstring{$\ast$}{*}}]{p}{, }\item[{int}]{idx}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Constructs a \doxylink{class_tensor_slice}{Tensor\+Slice} for a single index. 


\begin{DoxyParams}{Parameters}
{\em p} & Pointer to the parent \doxylink{class_tensor}{Tensor}. \\
\hline
{\em idx} & The index along the first dimension. \\
\hline
\end{DoxyParams}


\label{doc-func-members}
\Hypertarget{class_tensor_slice_doc-func-members}
\doxysubsection{Member Function Documentation}
\Hypertarget{class_tensor_slice_a4eb8d65d3052ebac6c39c04326830b4b}\index{TensorSlice@{TensorSlice}!Abs@{Abs}}
\index{Abs@{Abs}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Abs()}{Abs()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a4eb8d65d3052ebac6c39c04326830b4b} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Abs (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the absolute value of each element. 

Returns a new tensor where each element is the absolute value (magnitude) of the corresponding element in the original tensor. For any value x, the result is \texorpdfstring{$\vert$}{|}x\texorpdfstring{$\vert$}{|}, which is always non-\/negative.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing absolute values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a7a2ec909ae143cf9388ffe47cd331fcb}\index{TensorSlice@{TensorSlice}!Acos@{Acos}}
\index{Acos@{Acos}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Acos()}{Acos()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a7a2ec909ae143cf9388ffe47cd331fcb} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Acos (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arccosine (inverse cosine) of each element. 

Returns a new tensor where each element is the arccosine of the corresponding element in the original tensor. The result is in radians in the range \mbox{[}0, ?\mbox{]}.

The arccosine function is only defined for input values in the range \mbox{[}-\/1, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arccosine values in radians, ranging from 0 to ?.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is outside the range \mbox{[}-\/1, 1\mbox{]}.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/?. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ae69b2212f5ed15bd6ae63cec84a57d8f}\index{TensorSlice@{TensorSlice}!Acosh@{Acosh}}
\index{Acosh@{Acosh}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Acosh()}{Acosh()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ae69b2212f5ed15bd6ae63cec84a57d8f} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Acosh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic cosine of each element. 

Returns a new tensor where each element is the inverse hyperbolic cosine (also called area hyperbolic cosine) of the corresponding element in the original tensor. It is defined as\+: acosh(x) = ln(x + sqrt(x² -\/ 1))

The inverse hyperbolic cosine is only defined for values ? 1.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic cosine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is less than 1 (where acosh is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a95fc99ff4da0f51a8269cab2ae10086f}\index{TensorSlice@{TensorSlice}!Acot@{Acot}}
\index{Acot@{Acot}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Acot()}{Acot()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a95fc99ff4da0f51a8269cab2ae10086f} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Acot (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arccotangent (inverse cotangent) of each element. 

Returns a new tensor where each element is the arccotangent of the corresponding element in the original tensor. The result is in radians in the range (0, ?).

The arccotangent function is defined for all real numbers. For zero, it returns ?/2. For negative values, the result is adjusted to maintain the range \mbox{[}0, ?\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arccotangent values in radians, ranging from 0 to ?.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/?. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a1acd6ad17fc6f224966a0804113f64a7}\index{TensorSlice@{TensorSlice}!Acoth@{Acoth}}
\index{Acoth@{Acoth}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Acoth()}{Acoth()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a1acd6ad17fc6f224966a0804113f64a7} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Acoth (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic cotangent of each element. 

Returns a new tensor where each element is the inverse hyperbolic cotangent of the corresponding element in the original tensor. It is computed as\+: acoth(x) = atanh(1/x)

The inverse hyperbolic cotangent is only defined for values in (-\/?, -\/1) ? (1, ?). Values in the range \mbox{[}-\/1, 1\mbox{]} are undefined.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic cotangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is in the range \mbox{[}-\/1, 1\mbox{]} (where acoth is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_af3d3ab207245adb801b802f66b5fde73}\index{TensorSlice@{TensorSlice}!Acsc@{Acsc}}
\index{Acsc@{Acsc}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Acsc()}{Acsc()}}
{\footnotesize\ttfamily \label{class_tensor_slice_af3d3ab207245adb801b802f66b5fde73} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Acsc (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arccosecant (inverse cosecant) of each element. 

Returns a new tensor where each element is the arccosecant of the corresponding element in the original tensor. The result is in radians.

The arccosecant function is only defined for values in (-\/?, -\/1\mbox{]} ? \mbox{[}1, ?). It is computed as asin(1/x).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arccosecant values in radians.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is in the range (-\/1, 1), where arccosecant is undefined.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/?. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a85fe09e15d404b4a254eaec5fb1df4ca}\index{TensorSlice@{TensorSlice}!Acsch@{Acsch}}
\index{Acsch@{Acsch}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Acsch()}{Acsch()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a85fe09e15d404b4a254eaec5fb1df4ca} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Acsch (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic cosecant of each element. 

Returns a new tensor where each element is the inverse hyperbolic cosecant of the corresponding element in the original tensor. It is computed as\+: acsch(x) = asinh(1/x)

The inverse hyperbolic cosecant is undefined at zero.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic cosecant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately zero (where acsch is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a73b6144b9dd8e7e74951fe443bc4a849}\index{TensorSlice@{TensorSlice}!Asec@{Asec}}
\index{Asec@{Asec}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Asec()}{Asec()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a73b6144b9dd8e7e74951fe443bc4a849} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Asec (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arcsecant (inverse secant) of each element. 

Returns a new tensor where each element is the arcsecant of the corresponding element in the original tensor. The result is in radians.

The arcsecant function is only defined for values in (-\/?, -\/1\mbox{]} ? \mbox{[}1, ?). It is computed as acos(1/x).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arcsecant values in radians.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is in the range (-\/1, 1), where arcsecant is undefined.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/?. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ade05697844f7212fa4aec69de25743c6}\index{TensorSlice@{TensorSlice}!Asech@{Asech}}
\index{Asech@{Asech}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Asech()}{Asech()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ade05697844f7212fa4aec69de25743c6} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Asech (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic secant of each element. 

Returns a new tensor where each element is the inverse hyperbolic secant of the corresponding element in the original tensor. It is computed as\+: asech(x) = acosh(1/x)

The inverse hyperbolic secant is only defined for values in the range (0, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic secant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is ? 0 or \texorpdfstring{$>$}{>} 1 (where asech is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a29a4acf502a0696d3e04c6d178f77a99}\index{TensorSlice@{TensorSlice}!Asin@{Asin}}
\index{Asin@{Asin}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Asin()}{Asin()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a29a4acf502a0696d3e04c6d178f77a99} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Asin (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arcsine (inverse sine) of each element. 

Returns a new tensor where each element is the arcsine of the corresponding element in the original tensor. The result is in radians in the range \mbox{[}-\/?/2, ?/2\mbox{]}.

The arcsine function is only defined for input values in the range \mbox{[}-\/1, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arcsine values in radians, ranging from -\/?/2 to ?/2.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is outside the range \mbox{[}-\/1, 1\mbox{]}.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/?. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a3b512d0a8f019ec8d9f20e274525e799}\index{TensorSlice@{TensorSlice}!Asinh@{Asinh}}
\index{Asinh@{Asinh}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Asinh()}{Asinh()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a3b512d0a8f019ec8d9f20e274525e799} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Asinh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic sine of each element. 

Returns a new tensor where each element is the inverse hyperbolic sine (also called area hyperbolic sine) of the corresponding element in the original tensor. It is defined as\+: asinh(x) = ln(x + sqrt(x² + 1))

The inverse hyperbolic sine is defined for all real numbers.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic sine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a519178f6b8e4ae40533c4d6030dee949}\index{TensorSlice@{TensorSlice}!Atan@{Atan}}
\index{Atan@{Atan}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Atan()}{Atan()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a519178f6b8e4ae40533c4d6030dee949} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Atan (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the arctangent (inverse tangent) of each element. 

Returns a new tensor where each element is the arctangent of the corresponding element in the original tensor. The result is in radians in the range (-\/?/2, ?/2).

The arctangent function is defined for all real numbers.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing arctangent values in radians, ranging from -\/?/2 to ?/2.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The output is in radians. To convert to degrees, multiply by 180/?. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ae6ea5e2eb62073e68c546b03a7561acb}\index{TensorSlice@{TensorSlice}!Atanh@{Atanh}}
\index{Atanh@{Atanh}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Atanh()}{Atanh()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ae6ea5e2eb62073e68c546b03a7561acb} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Atanh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the inverse hyperbolic tangent of each element. 

Returns a new tensor where each element is the inverse hyperbolic tangent (also called area hyperbolic tangent) of the corresponding element in the original tensor. It is defined as\+: atanh(x) = 0.\+5 × ln((1 + x) / (1 -\/ x))

The inverse hyperbolic tangent is only defined for values in the open interval (-\/1, 1).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing inverse hyperbolic tangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is ? -\/1 or ? 1 (where atanh is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a9d55201d57f76d5c94cf58eda3c35725}\index{TensorSlice@{TensorSlice}!AvgPool@{AvgPool}}
\index{AvgPool@{AvgPool}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{AvgPool()}{AvgPool()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a9d55201d57f76d5c94cf58eda3c35725} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Avg\+Pool (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{pool\+\_\+shape}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{ = {\ttfamily \{\}}}\end{DoxyParamCaption})}



Performs average pooling operation by computing the mean value within sliding windows. 

Average pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the arithmetic mean (average) of all values in each region. It provides smoother downsampling compared to max pooling and is commonly used in convolutional neural networks for dimensionality reduction while preserving more global information.

The operation slides a window (defined by pool\+\_\+shape) across the input tensor according to the specified strides, and at each position, computes the average of all values within that window to form the output.

The pool\+\_\+shape can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the pool\+\_\+shape rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

If strides is empty, it defaults to the broadcasted pool\+\_\+shape, resulting in non-\/overlapping pooling windows (most common usage). Otherwise, strides must match the tensor\textquotesingle{}s rank.

Mathematical formulation for each output element\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{output[i,j,...]\ =\ (1/N)\ ×\ ?\ input[window\ elements]}
\DoxyCodeLine{where\ N\ =\ number\ of\ elements\ in\ the\ pooling\ window}

\end{DoxyCode}



\begin{DoxyParams}{Parameters}
{\em pool\+\_\+shape} & A vector specifying the size of the pooling window for each dimension. Must have rank ? this tensor\textquotesingle{}s rank. Each dimension of the pool must be ? the corresponding dimension of the input. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool\+\_\+shape (non-\/overlapping windows). If provided, must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the average-\/pooled result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} -\/ pool\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The pool\+\_\+shape is not compatible with the tensor (pool dimensions exceed input dimensions).
\item The strides vector is non-\/empty and its size does not match the tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (? 0).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Average pooling provides smoother gradients during backpropagation compared to max pooling, as all values in the window contribute to the output.

The output represents the average intensity or activation level within each pooling region. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a26aebba00b9e12f161384198295678f0}\index{TensorSlice@{TensorSlice}!Broadcast@{Broadcast}}
\index{Broadcast@{Broadcast}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Broadcast()}{Broadcast()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a26aebba00b9e12f161384198295678f0} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Broadcast (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{shape}{}\end{DoxyParamCaption}) const}



Broadcasts the tensor to a target shape following Num\+Py-\/style broadcasting rules. 

This method expands the tensor\textquotesingle{}s dimensions to match a target shape by replicating data along singleton dimensions (dimensions of size 1) and adding new leading dimensions as needed. Broadcasting allows operations between tensors of different but compatible shapes.

Broadcasting rules\+:
\begin{DoxyItemize}
\item Dimensions are aligned from the rightmost (trailing) dimension.
\item Two dimensions are compatible if they are equal or one of them is 1.
\item Missing leading dimensions are treated as size 1.
\end{DoxyItemize}

For scalar tensors (rank 0), broadcasting simply fills the target shape with the scalar value.


\begin{DoxyParams}{Parameters}
{\em shape} & The target shape to broadcast to. Must contain only positive integers. The shape must be broadcast-\/compatible with the current tensor\textquotesingle{}s shape.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the broadcasted shape and expanded data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The target shape is empty or contains non-\/positive values.
\item The tensor is empty (volume = 0).
\item The shapes are not broadcast-\/compatible.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor} with its own data buffer. The original tensor remains unchanged.

For large target shapes, broadcasting can be memory-\/intensive as data is replicated. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a9636224ea3638818437a002240e36725}\index{TensorSlice@{TensorSlice}!Ceil@{Ceil}}
\index{Ceil@{Ceil}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Ceil()}{Ceil()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a9636224ea3638818437a002240e36725} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Ceil (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Rounds each element up to the nearest integer (ceiling function). 

Returns a new tensor where each element is rounded up to the smallest integer greater than or equal to the original value. For example, 2.\+3 becomes 3, and -\/2.\+7 becomes -\/2.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing ceiled values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_aef30c23712785dd04bd9e02ba41dc78b}\index{TensorSlice@{TensorSlice}!Clip@{Clip}}
\index{Clip@{Clip}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Clip()}{Clip()}}
{\footnotesize\ttfamily \label{class_tensor_slice_aef30c23712785dd04bd9e02ba41dc78b} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Clip (\begin{DoxyParamCaption}\item[{double}]{min\+\_\+value}{, }\item[{double}]{max\+\_\+value}{}\end{DoxyParamCaption}) const}



Clips (clamps) each element to be within a specified range. 

Returns a new tensor where each element is constrained to lie within the range \mbox{[}min\+\_\+value, max\+\_\+value\mbox{]}. Values less than min\+\_\+value are set to min\+\_\+value, values greater than max\+\_\+value are set to max\+\_\+value, and values within the range remain unchanged.

This operation is useful for gradient clipping in neural networks, enforcing value bounds, and numerical stability.


\begin{DoxyParams}{Parameters}
{\em min\+\_\+value} & The minimum allowed value. Must be finite and ? max\+\_\+value. \\
\hline
{\em max\+\_\+value} & The maximum allowed value. Must be finite and ? min\+\_\+value.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing clipped values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item min\+\_\+value is not finite (NaN or infinity).
\item max\+\_\+value is not finite (NaN or infinity).
\item min\+\_\+value \texorpdfstring{$>$}{>} max\+\_\+value (invalid range).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

If min\+\_\+value equals max\+\_\+value, all output elements will be set to that value. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a8d2f2a27e468f2431a65cad597beec93}\index{TensorSlice@{TensorSlice}!Convolve@{Convolve}}
\index{Convolve@{Convolve}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Convolve()}{Convolve()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a8d2f2a27e468f2431a65cad597beec93} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Convolve (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{filter}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{, }\item[{const std\+::vector$<$ int $>$ \&}]{padding}{}\end{DoxyParamCaption})}



Performs N-\/dimensional convolution between this tensor and a filter kernel. 

This method computes the discrete convolution of the current tensor with a given filter kernel, supporting arbitrary dimensions, custom strides, and padding.

The operation applies the filter kernel across the input tensor using a sliding window approach. At each position, element-\/wise multiplication is performed between the kernel and the corresponding input region, followed by summation to produce a single output value.

The filter kernel can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the filter rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

Mathematical formulation for each output element\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{output[i,j,...]\ =\ ?\ input[i*stride\ +\ m,\ j*stride\ +\ n,\ ...]\ ×\ kernel[m,\ n,\ ...]}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ m,n,...}

\end{DoxyCode}



\begin{DoxyParams}{Parameters}
{\em filter} & The convolution kernel/filter tensor. Must have rank ? this tensor\textquotesingle{}s rank. Each dimension of the filter must be ? the corresponding padded dimension of the input tensor (aligned from the rightmost dimension).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. Must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0). Larger strides reduce output size and computational cost. Example\+: \{1, 1\} for dense convolution, \{2, 2\} for downsampling.\\
\hline
{\em padding} & A vector specifying the number of zero-\/padding elements to add before and after each dimension. Must have length equal to this tensor\textquotesingle{}s rank. All values must be non-\/negative (? 0). Padding controls output spatial dimensions and edge behavior. Example\+: \{1, 1\} adds one zero on each side of each dimension.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the convolution result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} + 2\texorpdfstring{$\ast$}{*}padding\mbox{[}i\mbox{]} -\/ filter\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The strides vector size does not match this tensor\textquotesingle{}s rank.
\item The padding vector size does not match this tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (? 0).
\item Any padding value is negative (\texorpdfstring{$<$}{<} 0).
\item The filter shape is not compatible with the padded input shape (filter dimensions exceed corresponding padded input dimensions).
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if the padded tensor shape would cause integer overflow (total volume exceeds INT\+\_\+\+MAX).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The convolution is computed in the spatial domain (direct method), not using FFT. For large kernels or tensors, this may be computationally expensive.

This implements "{}valid"{} convolution semantics after padding is applied. For "{}same"{} convolution (output size = input size), set padding appropriately\+: {\ttfamily padding\mbox{[}i\mbox{]} = (filter\+\_\+shape\mbox{[}i\mbox{]} -\/ 1) / 2} for odd-\/sized filters with stride=1.

The filter kernel is applied as-\/is without rotation. This is technically cross-\/correlation rather than true mathematical convolution, which is the standard convention in deep learning frameworks. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a50af8b385c36ce9ab4c707d96e131f30}\index{TensorSlice@{TensorSlice}!Cos@{Cos}}
\index{Cos@{Cos}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Cos()}{Cos()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a50af8b385c36ce9ab4c707d96e131f30} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Cos (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the cosine of each element (in radians). 

Returns a new tensor where each element is the cosine of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The cosine function maps any real number to the range \mbox{[}-\/1, 1\mbox{]} and is periodic with period 2?.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing cosine values in the range \mbox{[}-\/1, 1\mbox{]}.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a8eb0360a00945e98f06285a16a4d66ee}\index{TensorSlice@{TensorSlice}!Cosh@{Cosh}}
\index{Cosh@{Cosh}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Cosh()}{Cosh()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a8eb0360a00945e98f06285a16a4d66ee} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Cosh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic cosine of each element. 

Returns a new tensor where each element is the hyperbolic cosine of the corresponding element in the original tensor. The hyperbolic cosine is defined as\+: cosh(x) = (e\texorpdfstring{$^\wedge$}{\string^}x + e\texorpdfstring{$^\wedge$}{\string^}(-\/x)) / 2

The hyperbolic cosine function is defined for all real numbers and is an even function.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic cosine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_af93c5440a098163158a3ef04a1286fe2}\index{TensorSlice@{TensorSlice}!Cot@{Cot}}
\index{Cot@{Cot}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Cot()}{Cot()}}
{\footnotesize\ttfamily \label{class_tensor_slice_af93c5440a098163158a3ef04a1286fe2} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Cot (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the cotangent (reciprocal of tangent) of each element (in radians). 

Returns a new tensor where each element is the cotangent (1/tan(x) or cos(x)/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The cotangent function is undefined at multiples of ? (where sine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing cotangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately a multiple of ? (where cotangent is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a47239a452da7a9bcac96b60d87882669}\index{TensorSlice@{TensorSlice}!Coth@{Coth}}
\index{Coth@{Coth}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Coth()}{Coth()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a47239a452da7a9bcac96b60d87882669} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Coth (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element. 

Returns a new tensor where each element is the hyperbolic cotangent (1/tanh(x) or cosh(x)/sinh(x)) of the corresponding element in the original tensor.

The hyperbolic cotangent is undefined at zero (where sinh equals zero).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic cotangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately zero (where hyperbolic cotangent is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ad69af858ebe61a0637ca0f8f4d05e4be}\index{TensorSlice@{TensorSlice}!Csc@{Csc}}
\index{Csc@{Csc}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Csc()}{Csc()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ad69af858ebe61a0637ca0f8f4d05e4be} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Csc (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the cosecant (reciprocal of sine) of each element (in radians). 

Returns a new tensor where each element is the cosecant (1/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The cosecant function is undefined at multiples of ? (where sine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing cosecant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately a multiple of ? (where cosecant is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a39e047e2b44d05b024fe15d884ac8df3}\index{TensorSlice@{TensorSlice}!Csch@{Csch}}
\index{Csch@{Csch}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Csch()}{Csch()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a39e047e2b44d05b024fe15d884ac8df3} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Csch (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element. 

Returns a new tensor where each element is the hyperbolic cosecant (1/sinh(x)) of the corresponding element in the original tensor.

The hyperbolic cosecant is undefined at zero (where sinh equals zero).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic cosecant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately zero (where hyperbolic cosecant is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ad2ec37ad613eebdab3c0bf8bba3e27ee}\index{TensorSlice@{TensorSlice}!Exp@{Exp}}
\index{Exp@{Exp}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Exp()}{Exp()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ad2ec37ad613eebdab3c0bf8bba3e27ee} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Exp (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes e raised to the power of each element (exponential function). 

Returns a new tensor where each element is e\texorpdfstring{$^\wedge$}{\string^}x, where e ? 2.\+71828 (Euler\textquotesingle{}s number) and x is the corresponding element in the original tensor. This is the inverse operation of the natural logarithm.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing exponential values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The exponential function grows very rapidly. Large input values may result in overflow (infinity).

Special values\+:
\begin{DoxyItemize}
\item exp(0) = 1
\item exp(1) = e ? 2.\+71828
\item exp(ln(x)) = x 
\end{DoxyItemize}
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_aecd6af41dcc4e4a825408736216982a9}\index{TensorSlice@{TensorSlice}!ExpandRank@{ExpandRank}}
\index{ExpandRank@{ExpandRank}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ExpandRank()}{ExpandRank()}}
{\footnotesize\ttfamily \label{class_tensor_slice_aecd6af41dcc4e4a825408736216982a9} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Expand\+Rank (\begin{DoxyParamCaption}\item[{int}]{axis}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Expands the rank of the \doxylink{class_tensor}{Tensor} by inserting a dimension of size 1 at a specified axis. 

This operation increases the \doxylink{class_tensor}{Tensor}\textquotesingle{}s rank by 1 by inserting a new axis with dimension 1 at the specified position. The data remains unchanged; only the shape metadata is modified. This is analogous to Num\+Py\textquotesingle{}s {\ttfamily np.\+expand\+\_\+dims()} function.

The new dimension allows for operations such as broadcasting or stacking without modifying the underlying data. The axis parameter determines where the new dimension is inserted in the shape vector.


\begin{DoxyParams}{Parameters}
{\em axis} & The position where the new dimension (of size 1) will be inserted. Must satisfy\+: {\ttfamily 0 ? axis ? rank}.
\begin{DoxyItemize}
\item {\ttfamily axis = 0}\+: Insert at the beginning (becomes the new outermost dimension).
\item {\ttfamily axis = rank}\+: Append at the end (becomes the new innermost dimension). Default value is 0.
\end{DoxyItemize}\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with rank increased by 1 and a dimension of size 1 at the specified axis.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or greater than the current rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor} via reshaping. The original \doxylink{class_tensor}{Tensor} is unchanged.

The total volume (number of elements) remains the same. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a7037d4e167e55ad888dd1d9dac6b39eb}\index{TensorSlice@{TensorSlice}!Flatten@{Flatten}}
\index{Flatten@{Flatten}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Flatten()}{Flatten()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a7037d4e167e55ad888dd1d9dac6b39eb} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Flatten (\begin{DoxyParamCaption}\item[{int}]{axis\+\_\+from}{, }\item[{int}]{axis\+\_\+upto}{}\end{DoxyParamCaption}) const}



Flattens a range of consecutive axes into a single dimension. 

This operation collapses multiple consecutive dimensions between {\ttfamily axis\+\_\+from} (inclusive) and {\ttfamily axis\+\_\+upto} (exclusive) into a single flattened dimension. The axes before {\ttfamily axis\+\_\+from} and after {\ttfamily axis\+\_\+upto} remain unchanged. The resulting \doxylink{class_tensor}{Tensor} has a reduced rank.

The flattened dimension\textquotesingle{}s size is the product of all collapsed dimensions. The data order (row-\/major) remains unchanged; only the shape metadata is modified.


\begin{DoxyParams}{Parameters}
{\em axis\+\_\+from} & The starting axis index (inclusive) for flattening. Must satisfy\+: {\ttfamily 0 ? axis\+\_\+from \texorpdfstring{$<$}{<} axis\+\_\+upto}.\\
\hline
{\em axis\+\_\+upto} & The ending axis index (exclusive) for flattening. Must satisfy\+: {\ttfamily axis\+\_\+from \texorpdfstring{$<$}{<} axis\+\_\+upto ? rank}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with reduced rank where the specified axes are flattened.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the \doxylink{class_tensor}{Tensor} is rank-\/0 (scalar) or rank-\/1 (already flat, cannot flatten further).\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item {\ttfamily axis\+\_\+from} is negative.
\item {\ttfamily axis\+\_\+upto} is greater than the current rank.
\end{DoxyItemize}\\
\hline
{\em std\+::invalid\+\_\+argument} & if {\ttfamily axis\+\_\+from \texorpdfstring{$>$}{>}= axis\+\_\+upto} (invalid range specification).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

The total volume (number of elements) remains constant. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a3fe9669c843cf233b390f01befe92280}\index{TensorSlice@{TensorSlice}!Floor@{Floor}}
\index{Floor@{Floor}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Floor()}{Floor()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a3fe9669c843cf233b390f01befe92280} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Floor (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Rounds each element down to the nearest integer (floor function). 

Returns a new tensor where each element is rounded down to the largest integer less than or equal to the original value. For example, 2.\+7 becomes 2, and -\/2.\+3 becomes -\/3.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing floored values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a847c00a1c549d33cebe3a4ef2f4d3b2f}\index{TensorSlice@{TensorSlice}!IsEmpty@{IsEmpty}}
\index{IsEmpty@{IsEmpty}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{IsEmpty()}{IsEmpty()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a847c00a1c549d33cebe3a4ef2f4d3b2f} 
bool Tensor\+Slice\+::\+Is\+Empty (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Checks whether the tensor contains no elements. 

A tensor is considered empty if its volume (total number of elements) is zero. This can occur when any dimension in the shape is zero.

\begin{DoxyReturn}{Returns}
true if the tensor has zero elements (volume = 0), false otherwise.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
An empty tensor is different from a scalar tensor.
\begin{DoxyItemize}
\item Empty\+: volume = 0, no data stored
\item Scalar\+: volume = 1, single value stored 
\end{DoxyItemize}
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a25b03c23ebc8f53112bd2b5083d981b7}\index{TensorSlice@{TensorSlice}!IsScalar@{IsScalar}}
\index{IsScalar@{IsScalar}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{IsScalar()}{IsScalar()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a25b03c23ebc8f53112bd2b5083d981b7} 
bool Tensor\+Slice\+::\+Is\+Scalar (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Checks whether the tensor represents a scalar (single) value. 

A tensor is considered scalar if it has rank 0 (empty shape) and contains exactly one element. Scalar tensors represent single numerical values.

\begin{DoxyReturn}{Returns}
true if the tensor is a scalar (rank 0 and volume 1), false otherwise.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
A scalar tensor has\+:
\begin{DoxyItemize}
\item Empty shape\+: shape = \{\}
\item Volume of 1\+: exactly one element
\item Rank of 0\+: zero dimensions 
\end{DoxyItemize}
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a06db73fa0da2f9e770dcfe21cc14e828}\index{TensorSlice@{TensorSlice}!Log@{Log}}
\index{Log@{Log}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Log()}{Log()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a06db73fa0da2f9e770dcfe21cc14e828} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Log (\begin{DoxyParamCaption}\item[{double}]{base}{ = {\ttfamily std\+:\+:numbers\+:\+:e}}\end{DoxyParamCaption}) const}



Computes the logarithm of each element with a specified base. 

Returns a new tensor where each element is the logarithm (base-\/b) of the corresponding element in the original tensor. The operation computes log\+\_\+b(x) for each element x.

Uses the change of base formula\+: log\+\_\+b(x) = ln(x) / ln(b)


\begin{DoxyParams}{Parameters}
{\em base} & The logarithm base. Must be positive (\texorpdfstring{$>$}{>} 0) and not equal to 1. Common values\+: e ? 2.\+71828 (natural log), 10 (common log), 2 (binary log). Default is e (natural logarithm).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing logarithm values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The base is zero, negative, or approximately zero.
\item The base is 1 (logarithm base 1 is undefined).
\item Any element is zero, negative, or approximately zero (log undefined for non-\/positive values).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Special values\+:
\begin{DoxyItemize}
\item log\+\_\+b(1) = 0 for any valid base b
\item log\+\_\+b(b) = 1
\item log\+\_\+b(b\texorpdfstring{$^\wedge$}{\string^}n) = n 
\end{DoxyItemize}
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a30214f0ea0c3c3163bd05ca52c7dc95c}\index{TensorSlice@{TensorSlice}!MatMul@{MatMul}}
\index{MatMul@{MatMul}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{MatMul()}{MatMul()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a30214f0ea0c3c3163bd05ca52c7dc95c} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Mat\+Mul (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Performs matrix multiplication with another tensor. 

Convenience method that calls the static Mat\+Mul function. Equivalent to\+: Tensor\+::\+Mat\+Mul(\texorpdfstring{$\ast$}{*}this, other)


\begin{DoxyParams}{Parameters}
{\em other} & The right operand tensor. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the matrix multiplication result.
\end{DoxyReturn}
\begin{DoxySeeAlso}{See also}
Mat\+Mul(const Tensor\&, const Tensor\&) 
\end{DoxySeeAlso}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a40baf8d6e10b1024e654af746e84a649}\index{TensorSlice@{TensorSlice}!Max@{Max}}
\index{Max@{Max}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Max()}{Max()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a40baf8d6e10b1024e654af746e84a649} 
double Tensor\+Slice\+::\+Max (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Finds the maximum value in the tensor. 

Returns the largest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The maximum element value.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
\end{DoxyExceptions}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a58d10d1fd229a260e8a9299a6b6208f3}\index{TensorSlice@{TensorSlice}!MaxPool@{MaxPool}}
\index{MaxPool@{MaxPool}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{MaxPool()}{MaxPool()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a58d10d1fd229a260e8a9299a6b6208f3} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Max\+Pool (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{pool\+\_\+shape}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{ = {\ttfamily \{\}}}\end{DoxyParamCaption})}



Performs max pooling operation by taking the maximum value within sliding windows. 

Max pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the maximum value in each region. It is commonly used in convolutional neural networks for spatial dimensionality reduction, feature extraction, and translation invariance.

The operation slides a window (defined by pool\+\_\+shape) across the input tensor according to the specified strides, and at each position, selects the maximum value within that window to form the output.

The pool\+\_\+shape can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the pool\+\_\+shape rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

If strides is empty, it defaults to the broadcasted pool\+\_\+shape, resulting in non-\/overlapping pooling windows (most common usage). Otherwise, strides must match the tensor\textquotesingle{}s rank.


\begin{DoxyParams}{Parameters}
{\em pool\+\_\+shape} & A vector specifying the size of the pooling window for each dimension. Must have rank ? this tensor\textquotesingle{}s rank. Each dimension of the pool must be ? the corresponding dimension of the input. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool\+\_\+shape (non-\/overlapping windows). If provided, must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the max-\/pooled result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} -\/ pool\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The pool\+\_\+shape is not compatible with the tensor (pool dimensions exceed input dimensions).
\item The strides vector is non-\/empty and its size does not match the tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (? 0).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Max pooling provides translation invariance and is robust to small spatial shifts in the input features, making it popular in computer vision tasks.

The output captures the most prominent features within each pooling region. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a1cc3aa9a38e6baba9ed12371986c45c2}\index{TensorSlice@{TensorSlice}!Mean@{Mean}}
\index{Mean@{Mean}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Mean()}{Mean()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a1cc3aa9a38e6baba9ed12371986c45c2} 
double Tensor\+Slice\+::\+Mean (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the mean (average) of all elements in the tensor. 

Returns the arithmetic mean of all elements as a scalar value. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The mean of all elements.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
Formula\+: Mean = Sum / Volume 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a0a7fb881f780412a2d39ca26089fb26e}\index{TensorSlice@{TensorSlice}!Min@{Min}}
\index{Min@{Min}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Min()}{Min()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a0a7fb881f780412a2d39ca26089fb26e} 
double Tensor\+Slice\+::\+Min (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Finds the minimum value in the tensor. 

Returns the smallest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The minimum element value.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
\end{DoxyExceptions}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ac7587c1151e35617411a27b786bb420c}\index{TensorSlice@{TensorSlice}!MinPool@{MinPool}}
\index{MinPool@{MinPool}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{MinPool()}{MinPool()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ac7587c1151e35617411a27b786bb420c} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Min\+Pool (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{pool\+\_\+shape}{, }\item[{const std\+::vector$<$ int $>$ \&}]{strides}{ = {\ttfamily \{\}}}\end{DoxyParamCaption})}



Performs min pooling operation by taking the minimum value within sliding windows. 

Min pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the minimum value in each region. While less common than max pooling, it can be useful in specific applications where detecting the lowest activation or darkest features is important, such as certain image processing tasks or anomaly detection.

The operation slides a window (defined by pool\+\_\+shape) across the input tensor according to the specified strides, and at each position, selects the minimum value within that window to form the output.

The pool\+\_\+shape can have a rank lower than or equal to the input tensor\textquotesingle{}s rank. When the pool\+\_\+shape rank is lower, it is automatically broadcast to match the input tensor\textquotesingle{}s rank by prepending dimensions of size 1.

If strides is empty, it defaults to the broadcasted pool\+\_\+shape, resulting in non-\/overlapping pooling windows (most common usage). Otherwise, strides must match the tensor\textquotesingle{}s rank.


\begin{DoxyParams}{Parameters}
{\em pool\+\_\+shape} & A vector specifying the size of the pooling window for each dimension. Must have rank ? this tensor\textquotesingle{}s rank. Each dimension of the pool must be ? the corresponding dimension of the input. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
{\em strides} & A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool\+\_\+shape (non-\/overlapping windows). If provided, must have length equal to this tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing the min-\/pooled result with shape computed as\+: {\ttfamily output\+\_\+shape\mbox{[}i\mbox{]} = ((input\+\_\+shape\mbox{[}i\mbox{]} -\/ pool\+\_\+shape\mbox{[}i\mbox{]}) / strides\mbox{[}i\mbox{]}) + 1} for each dimension i.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The pool\+\_\+shape is not compatible with the tensor (pool dimensions exceed input dimensions).
\item The strides vector is non-\/empty and its size does not match the tensor\textquotesingle{}s rank.
\item Any stride value is non-\/positive (? 0).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Min pooling is sensitive to the smallest values in each region, making it useful for detecting low-\/intensity features or for applications requiring conservative feature selection.

The output captures the least prominent (minimum) features within each pooling region. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a556db8ba686446c0412952d9405f42ba}\index{TensorSlice@{TensorSlice}!Mod@{Mod}}
\index{Mod@{Mod}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Mod()}{Mod()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a556db8ba686446c0412952d9405f42ba} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Mod (\begin{DoxyParamCaption}\item[{double}]{mod\+\_\+value}{}\end{DoxyParamCaption}) const}



Computes the modulus (remainder) of each element divided by a value. 

Returns a new tensor where each element is the remainder of dividing the corresponding element by the specified modulus value. Uses the fmod function which computes the floating-\/point remainder of the division.

The result has the same sign as the dividend (the tensor element).


\begin{DoxyParams}{Parameters}
{\em mod\+\_\+value} & The divisor for the modulus operation. Must be non-\/zero.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing modulus values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if mod\+\_\+value is approximately zero (division by zero).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The result sign follows the dividend\+: fmod(-\/5, 3) = -\/2, fmod(5, -\/3) = 2 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a55c5c65bc9c909bdad1c45e188c2e99b}\index{TensorSlice@{TensorSlice}!operator Tensor@{operator Tensor}}
\index{operator Tensor@{operator Tensor}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator Tensor()}{operator Tensor()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a55c5c65bc9c909bdad1c45e188c2e99b} 
Tensor\+Slice\+::operator \mbox{\hyperlink{class_tensor}{Tensor}} (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Implicit conversion to \doxylink{class_tensor}{Tensor} (creates an independent copy). 

This conversion operator is called when a \doxylink{class_tensor_slice}{Tensor\+Slice} is assigned to a \doxylink{class_tensor}{Tensor} variable or passed to a function expecting a \doxylink{class_tensor}{Tensor}. It creates a deep copy of the sliced data.

\begin{DoxyReturn}{Returns}
A new independent \doxylink{class_tensor}{Tensor} containing the sliced data. 
\end{DoxyReturn}
\Hypertarget{class_tensor_slice_abd2662558437bf0032085e5a483520d3}\index{TensorSlice@{TensorSlice}!operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}}
\index{operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}()}{operator*()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_abd2662558437bf0032085e5a483520d3} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator\texorpdfstring{$\ast$}{*} (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise multiplication of two tensors (Hadamard product). 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the product of corresponding elements from both tensors. If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.

This is element-\/wise multiplication (Hadamard product), NOT matrix multiplication.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to multiply with. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise products with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 

This is NOT matrix multiplication. For matrix multiplication, use a separate Mat\+Mul method. 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_af184ad77fc278974efbbcfce8be97e20}\index{TensorSlice@{TensorSlice}!operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}}
\index{operator\texorpdfstring{$\ast$}{*}@{operator\texorpdfstring{$\ast$}{*}}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}()}{operator*()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_af184ad77fc278974efbbcfce8be97e20} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator\texorpdfstring{$\ast$}{*} (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise multiplication of all tensor elements by a scalar value. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the product of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise products.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a79372cfb766492f6d4a0beb236eca244}\index{TensorSlice@{TensorSlice}!operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}}
\index{operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}=()}{operator*=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a79372cfb766492f6d4a0beb236eca244} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator\texorpdfstring{$\ast$}{*}= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise multiplication with another tensor (Hadamard product). 

Multiplies this tensor with the given tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

This is element-\/wise multiplication (Hadamard product), NOT matrix multiplication.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to multiply with. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

This is NOT matrix multiplication. For matrix multiplication, use a separate Mat\+Mul method. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A \texorpdfstring{$\ast$}{*} B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_a6fb8999e863da0cd422494ea8936e3bb}\index{TensorSlice@{TensorSlice}!operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}}
\index{operator\texorpdfstring{$\ast$}{*}=@{operator\texorpdfstring{$\ast$}{*}=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator\texorpdfstring{$\ast$}{*}=()}{operator*=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a6fb8999e863da0cd422494ea8936e3bb} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator\texorpdfstring{$\ast$}{*}= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise multiplication by a scalar value. 

Multiplies all elements of this tensor by the scalar value in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A \texorpdfstring{$\ast$}{*} value;} 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a5cbf99706365813b2d14ddf63a9b9624}\index{TensorSlice@{TensorSlice}!operator+@{operator+}}
\index{operator+@{operator+}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator+()}{operator+()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a5cbf99706365813b2d14ddf63a9b9624} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator+ (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise addition of two tensors. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the sum of corresponding elements from both tensors. If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.

Broadcasting allows operations between tensors of different but compatible shapes by automatically expanding dimensions where needed.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to add. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise sums with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_a891cda49b0e34178a9abeab88481066f}\index{TensorSlice@{TensorSlice}!operator+@{operator+}}
\index{operator+@{operator+}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator+()}{operator+()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a891cda49b0e34178a9abeab88481066f} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator+ (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise addition of a scalar value to all tensor elements. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the sum of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to add to each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise sums.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_af81661b65d4ef9a66109c5e2354e0621}\index{TensorSlice@{TensorSlice}!operator+=@{operator+=}}
\index{operator+=@{operator+=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator+=()}{operator+=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_af81661b65d4ef9a66109c5e2354e0621} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator+= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise addition with another tensor. 

Adds the given tensor to this tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to add. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A + B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_a0a6c7af8296371c02d00f53b6aa3400a}\index{TensorSlice@{TensorSlice}!operator+=@{operator+=}}
\index{operator+=@{operator+=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator+=()}{operator+=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a0a6c7af8296371c02d00f53b6aa3400a} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator+= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise addition of a scalar value. 

Adds the scalar value to all elements of this tensor in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to add to each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A + value;} 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ab31a85076571882207207be11c70cd34}\index{TensorSlice@{TensorSlice}!operator-\/@{operator-\/}}
\index{operator-\/@{operator-\/}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator-\/()}{operator-()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_ab31a85076571882207207be11c70cd34} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator-\/ (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise subtraction of two tensors. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the difference between corresponding elements from both tensors (this -\/ tensor). If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to subtract. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise differences with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 

Order matters\+: A -\/ B ? B -\/ A 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_a30c1e8fe8a68609fda529a1ad6602724}\index{TensorSlice@{TensorSlice}!operator-\/@{operator-\/}}
\index{operator-\/@{operator-\/}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator-\/()}{operator-()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a30c1e8fe8a68609fda529a1ad6602724} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator-\/ (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise subtraction of a scalar value from all tensor elements. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the difference between the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise differences.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ad456ffc088943ad62eea57a8c80f05d7}\index{TensorSlice@{TensorSlice}!operator-\/=@{operator-\/=}}
\index{operator-\/=@{operator-\/=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator-\/=()}{operator-=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_ad456ffc088943ad62eea57a8c80f05d7} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator-\/= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise subtraction with another tensor. 

Subtracts the given tensor from this tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The tensor to subtract. Must be non-\/empty and broadcast-\/compatible.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A -\/ B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_a953cf784473905860747b49166078421}\index{TensorSlice@{TensorSlice}!operator-\/=@{operator-\/=}}
\index{operator-\/=@{operator-\/=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator-\/=()}{operator-=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a953cf784473905860747b49166078421} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator-\/= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise subtraction of a scalar value. 

Subtracts the scalar value from all elements of this tensor in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A -\/ value;} 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a67aee1af10009acf23649fdae6e3dc49}\index{TensorSlice@{TensorSlice}!operator/@{operator/}}
\index{operator/@{operator/}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator/()}{operator/()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a67aee1af10009acf23649fdae6e3dc49} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator/ (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption}) const}



Element-\/wise division of two tensors. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the quotient of corresponding elements from both tensors (this / tensor). If the shapes don\textquotesingle{}t match, automatic broadcasting is applied following Num\+Py-\/style broadcasting rules.

Division by elements close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon \texorpdfstring{$\ast$}{*} EPSILON\+\_\+\+SCALE) is detected and throws an exception to prevent numerical instability.


\begin{DoxyParams}{Parameters}
{\em tensor} & The divisor tensor. Must be non-\/empty, broadcast-\/compatible, and contain no near-\/zero values.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} containing element-\/wise quotients with the broadcasted shape.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method). \\
\hline
{\em std\+::domain\+\_\+error} & if any element in the divisor tensor is close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon \texorpdfstring{$\ast$}{*} EPSILON\+\_\+\+SCALE).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. Both input tensors remain unchanged. 

Automatic broadcasting may create temporary copies for shape alignment. 

Order matters\+: A / B ? B / A 

Division-\/by-\/zero check is performed for each element individually during iteration. 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_add3ca72dfa58d4f0d443da639fdb576b}\index{TensorSlice@{TensorSlice}!operator/@{operator/}}
\index{operator/@{operator/}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator/()}{operator/()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_add3ca72dfa58d4f0d443da639fdb576b} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::operator/ (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption}) const}



Element-\/wise division of all tensor elements by a scalar value. 

Creates a new \doxylink{class_tensor}{Tensor} where each element is the quotient of the corresponding element in this tensor divided by the scalar value. The operation is broadcast across all elements.

Division by values very close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} 1e-\/9) is treated as division by zero to prevent numerical instability.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape, containing element-\/wise quotients.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity. \\
\hline
{\em std\+::domain\+\_\+error} & if the absolute value of the divisor is less than epsilon × EPSILON\+\_\+\+SCALE (division by \texorpdfstring{$\sim$}{\string~}zero).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The threshold 1e-\/9 is used to detect near-\/zero values and prevent numerical errors. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a1763727eccb717b5359293923576bf43}\index{TensorSlice@{TensorSlice}!operator/=@{operator/=}}
\index{operator/=@{operator/=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator/=()}{operator/=()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_a1763727eccb717b5359293923576bf43} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator/= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{tensor}{}\end{DoxyParamCaption})}



In-\/place element-\/wise division by another tensor. 

Divides this tensor by the given tensor element-\/wise, modifying this tensor in-\/place. If the shapes don\textquotesingle{}t match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.

Division by elements close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE) is detected and throws an exception to prevent numerical instability.

The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.


\begin{DoxyParams}{Parameters}
{\em tensor} & The divisor tensor. Must be non-\/empty, broadcast-\/compatible, and contain no near-\/zero values.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if either tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the shapes are not broadcast-\/compatible (thrown by Broadcast method). \\
\hline
{\em std\+::domain\+\_\+error} & if any element in the divisor tensor is close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that may change the tensor\textquotesingle{}s shape via broadcasting. 

If shapes differ, this tensor is reassigned to the broadcast result. 

Division-\/by-\/zero check is performed for each element individually during iteration. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} C = A / B;} 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_ac0cfe800f5166e780913c459085c5240}\index{TensorSlice@{TensorSlice}!operator/=@{operator/=}}
\index{operator/=@{operator/=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator/=()}{operator/=()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_ac0cfe800f5166e780913c459085c5240} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator/= (\begin{DoxyParamCaption}\item[{double}]{value}{}\end{DoxyParamCaption})}



In-\/place element-\/wise division by a scalar value. 

Divides all elements of this tensor by the scalar value in-\/place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared\+\_\+ptr), all tensors sharing the same data will see the changes.

Division by values very close to zero (\texorpdfstring{$\vert$}{|}value\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE) is treated as division by zero to prevent numerical instability.


\begin{DoxyParams}{Parameters}
{\em value} & The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.\\
\hline
\end{DoxyParams}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if the value is NaN or infinity. \\
\hline
{\em std\+::domain\+\_\+error} & if the absolute value of the divisor is less than epsilon × EPSILON\+\_\+\+SCALE (division by \texorpdfstring{$\sim$}{\string~}zero).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is an in-\/place operation that modifies the underlying data directly. 

If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-\/modifying operator\+: {\ttfamily \doxylink{class_tensor}{Tensor} B = A / value;} 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a725be809a7e2f9903fe1aa7bbfc7d425}\index{TensorSlice@{TensorSlice}!operator=@{operator=}}
\index{operator=@{operator=}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator=()}{operator=()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a725be809a7e2f9903fe1aa7bbfc7d425} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} \& Tensor\+Slice\+::operator= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{class_tensor}{Tensor}} \&}]{other}{}\end{DoxyParamCaption})}



Assignment operator that modifies the root parent tensor. 

Assigns the given tensor\textquotesingle{}s data to the slice location in the original tensor. This modifies the root tensor through the index chain.


\begin{DoxyParams}{Parameters}
{\em other} & The \doxylink{class_tensor}{Tensor} whose data will be copied into the slice. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Reference to this \doxylink{class_tensor_slice}{Tensor\+Slice} for chaining. 
\end{DoxyReturn}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a36b4453303b38372b6b48b83bead2e45}\index{TensorSlice@{TensorSlice}!operator\mbox{[}\mbox{]}@{operator[]}}
\index{operator\mbox{[}\mbox{]}@{operator[]}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{operator[]()}{operator[]()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a36b4453303b38372b6b48b83bead2e45} 
\mbox{\hyperlink{class_tensor_slice}{Tensor\+Slice}} Tensor\+Slice\+::operator\mbox{[}$\,$\mbox{]} (\begin{DoxyParamCaption}\item[{int}]{idx}{}\end{DoxyParamCaption})}



Non-\/const indexing for continued chaining with modification capability. 

Extends the index chain by one level, allowing nested indexing operations. Used when the slice may be modified.


\begin{DoxyParams}{Parameters}
{\em idx} & The next index in the chain. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor_slice}{Tensor\+Slice} with the extended index chain. 
\end{DoxyReturn}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a44621cdd09df688b2c5cb4bd000d8f73}\index{TensorSlice@{TensorSlice}!Pad@{Pad}}
\index{Pad@{Pad}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Pad()}{Pad()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a44621cdd09df688b2c5cb4bd000d8f73} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Pad (\begin{DoxyParamCaption}\item[{int}]{axis}{, }\item[{int}]{pad\+\_\+before}{, }\item[{int}]{pad\+\_\+after}{, }\item[{double}]{value}{ = {\ttfamily 0.0}}\end{DoxyParamCaption}) const}



Adds padding elements before and/or after the tensor along a specified axis. 

This method creates a new \doxylink{class_tensor}{Tensor} with additional elements (padding) inserted before and after the original data along the specified axis. The padding elements are filled with a constant value (default is 0.\+0).

The resulting tensor has the same rank but an increased dimension along the padded axis\+: {\ttfamily new\+\_\+shape\mbox{[}axis\mbox{]} = original\+\_\+shape\mbox{[}axis\mbox{]} + pad\+\_\+before\+\_\+size + pad\+\_\+after\+\_\+size}.

This operation is commonly used in convolutional neural networks, signal processing, and boundary handling in various algorithms.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to add padding. Must satisfy\+: {\ttfamily 0 ? axis \texorpdfstring{$<$}{<} rank}.\\
\hline
{\em pad\+\_\+before\+\_\+size} & The number of padding elements to add before the data along the axis. Must be non-\/negative (? 0).\\
\hline
{\em pad\+\_\+after\+\_\+size} & The number of padding elements to add after the data along the axis. Must be non-\/negative (? 0).\\
\hline
{\em value} & The constant value to fill the padding elements with. Default is 0.\+0. Must be a finite number (not NaN or infinity).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with padding added along the specified axis.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
{\em std\+::invalid\+\_\+argument} & if pad\+\_\+before\+\_\+size or pad\+\_\+after\+\_\+size is negative.\\
\hline
{\em std\+::overflow\+\_\+error} & if the resulting shape volume exceeds INT\+\_\+\+MAX.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

If both pad\+\_\+before\+\_\+size and pad\+\_\+after\+\_\+size are 0, the returned tensor is a copy of the original.

Internally, this method uses Concat to join padding tensors with the original data. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ab3b88de18822c6f21b4f846fc2a08651}\index{TensorSlice@{TensorSlice}!Power@{Power}}
\index{Power@{Power}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Power()}{Power()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ab3b88de18822c6f21b4f846fc2a08651} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Power (\begin{DoxyParamCaption}\item[{double}]{exponent}{}\end{DoxyParamCaption}) const}



Raises each element to a specified power (exponentiation).    

Returns a new tensor where each element is raised to the given exponent. The operation computes x\texorpdfstring{$^\wedge$}{\string^}exponent for each element x.

For negative bases with non-\/integer exponents, the result would be a complex number, so an exception is thrown to maintain real number semantics.


\begin{DoxyParams}{Parameters}
{\em exponent} & The power to raise each element to. Can be any real number.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing the results of exponentiation.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is negative and the exponent is non-\/integer (would result in a complex number).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

Special cases\+:
\begin{DoxyItemize}
\item x\texorpdfstring{$^\wedge$}{\string^}0 = 1 for any x (including 0)
\item x\texorpdfstring{$^\wedge$}{\string^}1 = x
\item 0\texorpdfstring{$^\wedge$}{\string^}n = 0 for positive n    
\end{DoxyItemize}
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ac4fca8605058c8dd92bc8bbb1eba2969}\index{TensorSlice@{TensorSlice}!Print@{Print}}
\index{Print@{Print}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Print()}{Print()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ac4fca8605058c8dd92bc8bbb1eba2969} 
void Tensor\+Slice\+::\+Print (\begin{DoxyParamCaption}\item[{int}]{depth}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Prints the tensor contents to standard output in a readable, nested format. 

This method displays the tensor\textquotesingle{}s structure and values in a Num\+Py-\/like format with appropriate indentation for multi-\/dimensional tensors. It recursively prints nested structures, making it easy to visualize the tensor\textquotesingle{}s shape and data.

Special cases\+:
\begin{DoxyItemize}
\item Empty tensors are printed as {\ttfamily \mbox{[}\mbox{]}}
\item Scalar tensors print the single value directly
\item Multi-\/dimensional tensors use nested brackets with indentation
\end{DoxyItemize}


\begin{DoxyParams}{Parameters}
{\em depth} & Internal indentation level used during recursive printing. This parameter is automatically managed and should not be modified by users. Default is 0 (no indentation).\\
\hline
\end{DoxyParams}
\begin{DoxyNote}{Note}
This method is primarily intended for debugging and inspection. For programmatic string representation, consider implementing a To\+String() method.

The output format includes\+:
\begin{DoxyItemize}
\item Newlines and indentation for readability in multi-\/dimensional tensors
\item Commas between elements
\item Nested brackets representing each dimension
\end{DoxyItemize}

This method uses the const indexing operator {\ttfamily \mbox{[}\mbox{]}} internally, which triggers the conversion from \doxylink{class_tensor_slice}{Tensor\+Slice} to \doxylink{class_tensor}{Tensor}, creating temporary copies during recursion. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a5d66ce8c7e459c2c6e9d2f2cc0c16ee3}\index{TensorSlice@{TensorSlice}!Rank@{Rank}}
\index{Rank@{Rank}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Rank()}{Rank()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a5d66ce8c7e459c2c6e9d2f2cc0c16ee3} 
int Tensor\+Slice\+::\+Rank (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Returns the rank (number of dimensions) of the tensor. 

The rank represents the number of axes or dimensions in the tensor. For example, a scalar has rank 0, a vector has rank 1, a matrix has rank 2, etc.

\begin{DoxyReturn}{Returns}
The rank of the tensor as an integer.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
A scalar tensor (single value) has rank 0. 

An empty tensor also reports its rank correctly based on its shape. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a581bc889132baeaafc6974c523c80189}\index{TensorSlice@{TensorSlice}!ReduceMax@{ReduceMax}}
\index{ReduceMax@{ReduceMax}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ReduceMax()}{ReduceMax()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a581bc889132baeaafc6974c523c80189} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Reduce\+Max (\begin{DoxyParamCaption}\item[{int}]{axis}{}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the maximum. 

Finds the maximum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to find the maximum. Must satisfy\+: 0 ? axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing maximum values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a0bc4030adf64e861696d2033f6fc08bb}\index{TensorSlice@{TensorSlice}!ReduceMean@{ReduceMean}}
\index{ReduceMean@{ReduceMean}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ReduceMean()}{ReduceMean()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a0bc4030adf64e861696d2033f6fc08bb} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Reduce\+Mean (\begin{DoxyParamCaption}\item[{int}]{axis}{}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the mean (average). 

Computes the arithmetic mean of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to compute the mean. Must satisfy\+: 0 ? axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing means.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 

Implemented as Reduce\+Sum(axis) / size. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a0bd288decf47bfad24af8d46a70f2952}\index{TensorSlice@{TensorSlice}!ReduceMin@{ReduceMin}}
\index{ReduceMin@{ReduceMin}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ReduceMin()}{ReduceMin()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a0bd288decf47bfad24af8d46a70f2952} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Reduce\+Min (\begin{DoxyParamCaption}\item[{int}]{axis}{}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the minimum. 

Finds the minimum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to find the minimum. Must satisfy\+: 0 ? axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing minimum values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_afe2ed01b32773724e684e9fe6090f531}\index{TensorSlice@{TensorSlice}!ReduceSum@{ReduceSum}}
\index{ReduceSum@{ReduceSum}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ReduceSum()}{ReduceSum()}}
{\footnotesize\ttfamily \label{class_tensor_slice_afe2ed01b32773724e684e9fe6090f531} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Reduce\+Sum (\begin{DoxyParamCaption}\item[{int}]{axis}{}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the sum. 

Computes the sum of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to compute the sum. Must satisfy\+: 0 ? axis \texorpdfstring{$<$}{<} rank. Default is 0.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing sums.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a0898917704e36edbd2b99779010f945e}\index{TensorSlice@{TensorSlice}!ReduceVar@{ReduceVar}}
\index{ReduceVar@{ReduceVar}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ReduceVar()}{ReduceVar()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a0898917704e36edbd2b99779010f945e} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Reduce\+Var (\begin{DoxyParamCaption}\item[{int}]{axis}{, }\item[{bool}]{inference}{ = {\ttfamily false}}\end{DoxyParamCaption}) const}



Reduces the tensor along a specified axis by computing the variance. 

Computes the variance of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.

Variance measures how spread out the values are from their mean.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to compute the variance. Must satisfy\+: 0 ? axis \texorpdfstring{$<$}{<} rank. Default is 0. \\
\hline
{\em inference} & If true, uses Bessel\textquotesingle{}s correction (divides by n-\/1 for sample variance). If false, divides by n (population variance). Default is false.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified axis removed, containing variances.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is rank-\/0 (scalar) or empty. \\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if the axis is negative or \texorpdfstring{$>$}{>}= rank.\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. 

Formula\+: Var = sum((x -\/ mean)²) / n (or n-\/1 if inference=true) 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a324cf2ea9cc02476c25de1d4069468b0}\index{TensorSlice@{TensorSlice}!Reshape@{Reshape}}
\index{Reshape@{Reshape}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Reshape()}{Reshape()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a324cf2ea9cc02476c25de1d4069468b0} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Reshape (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{new\+\_\+shape}{}\end{DoxyParamCaption}) const}



Reshapes the \doxylink{class_tensor}{Tensor} to a new specified shape without changing data order. 

Creates a new \doxylink{class_tensor}{Tensor} with the given shape, containing the same data elements in the same row-\/major order. The total number of elements (volume) must remain constant. This operation does not reorder or modify the data; it only changes how the flat data is interpreted dimensionally.


\begin{DoxyParams}{Parameters}
{\em new\+\_\+shape} & A vector of positive integers representing the desired dimensions. All dimensions must be greater than 0. The product of all dimensions must equal the current volume.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the specified shape and the same data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The new\+\_\+shape contains any non-\/positive dimensions (i.\+e., any dimension ? 0).
\item The volume implied by new\+\_\+shape does not match the current \doxylink{class_tensor}{Tensor}\textquotesingle{}s volume.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

Only the shape metadata changes; data is copied but not reordered. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ab07074813ba5a5f62a9246fe99d1430c}\index{TensorSlice@{TensorSlice}!Round@{Round}}
\index{Round@{Round}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Round()}{Round()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ab07074813ba5a5f62a9246fe99d1430c} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Round (\begin{DoxyParamCaption}\item[{int}]{decimal\+\_\+place}{ = {\ttfamily 0}}\end{DoxyParamCaption}) const}



Rounds each element to a specified number of decimal places. 

Returns a new tensor where each element is rounded to the nearest value with the specified number of decimal places. Uses standard rounding rules (round half to even / banker\textquotesingle{}s rounding).


\begin{DoxyParams}{Parameters}
{\em decimal\+\_\+place} & The number of decimal places to round to. Must be non-\/negative (? 0). Default is 0 (round to nearest integer).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing rounded values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::invalid\+\_\+argument} & if decimal\+\_\+place is negative (\texorpdfstring{$<$}{<} 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a0e1f2f379dd0ff1dcdffe924f7f1360c}\index{TensorSlice@{TensorSlice}!Sec@{Sec}}
\index{Sec@{Sec}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Sec()}{Sec()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a0e1f2f379dd0ff1dcdffe924f7f1360c} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Sec (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the secant (reciprocal of cosine) of each element (in radians). 

Returns a new tensor where each element is the secant (1/cos(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The secant function is undefined at odd multiples of ?/2 (where cosine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing secant values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately an odd multiple of ?/2 (where secant is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a44053a3ce4683ba4e4000b59555cf361}\index{TensorSlice@{TensorSlice}!Sech@{Sech}}
\index{Sech@{Sech}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Sech()}{Sech()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a44053a3ce4683ba4e4000b59555cf361} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Sech (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element. 

Returns a new tensor where each element is the hyperbolic secant (1/cosh(x)) of the corresponding element in the original tensor.

The hyperbolic secant is always positive and has range (0, 1\mbox{]}.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic secant values in the range (0, 1\mbox{]}.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if numerical instability is detected (extremely rare).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_af773875332be2e70344d4a17429166ba}\index{TensorSlice@{TensorSlice}!Shape@{Shape}}
\index{Shape@{Shape}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Shape()}{Shape()}}
{\footnotesize\ttfamily \label{class_tensor_slice_af773875332be2e70344d4a17429166ba} 
std\+::vector$<$ int $>$ Tensor\+Slice\+::\+Shape (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Returns the shape of the tensor as a vector of dimension sizes. 

The shape describes the size of each dimension in the tensor. For example, shape \{2, 3, 4\} represents a 3D tensor with 2 slices, each containing a 3×4 matrix.

\begin{DoxyReturn}{Returns}
A vector of integers representing the size of each dimension.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
For a scalar tensor (rank 0), this returns an empty vector. 

The returned vector is a copy; modifying it does not affect the tensor. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ada3970a1f99f8e389c6272d0e8f54944}\index{TensorSlice@{TensorSlice}!Sign@{Sign}}
\index{Sign@{Sign}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Sign()}{Sign()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ada3970a1f99f8e389c6272d0e8f54944} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Sign (\begin{DoxyParamCaption}\item[{bool}]{heaviside}{ = {\ttfamily false}}\end{DoxyParamCaption}) const}



Computes the sign function element-\/wise. 

Returns a new tensor where each element is\+:
\begin{DoxyItemize}
\item 1.\+0 if the original element is positive
\item -\/1.\+0 if the original element is negative
\item 0.\+0 if the original element is approximately zero (\texorpdfstring{$\vert$}{|}x\texorpdfstring{$\vert$}{|} \texorpdfstring{$<$}{<} epsilon × EPSILON\+\_\+\+SCALE)
\end{DoxyItemize}

If the Heaviside step function mode is enabled, zero values are mapped to 1.\+0 instead of 0.\+0.


\begin{DoxyParams}{Parameters}
{\em heaviside} & If true, uses Heaviside step function (maps 0 ? 1). If false, uses standard sign function (maps 0 ? 0). Default is false.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing sign values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a13d0676062409a9e032ca58e0bf2d8ff}\index{TensorSlice@{TensorSlice}!Sin@{Sin}}
\index{Sin@{Sin}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Sin()}{Sin()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a13d0676062409a9e032ca58e0bf2d8ff} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Sin (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the sine of each element (in radians). 

Returns a new tensor where each element is the sine of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The sine function maps any real number to the range \mbox{[}-\/1, 1\mbox{]} and is periodic with period 2?.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing sine values in the range \mbox{[}-\/1, 1\mbox{]}.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_af9a20344356eae9d28baf7aab314b80b}\index{TensorSlice@{TensorSlice}!Sinh@{Sinh}}
\index{Sinh@{Sinh}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Sinh()}{Sinh()}}
{\footnotesize\ttfamily \label{class_tensor_slice_af9a20344356eae9d28baf7aab314b80b} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Sinh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic sine of each element. 

Returns a new tensor where each element is the hyperbolic sine of the corresponding element in the original tensor. The hyperbolic sine is defined as\+: sinh(x) = (e\texorpdfstring{$^\wedge$}{\string^}x -\/ e\texorpdfstring{$^\wedge$}{\string^}(-\/x)) / 2

The hyperbolic sine function is defined for all real numbers and is an odd function.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic sine values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_adebcfb3b75b9a42ddfac2766c6ea0acc}\index{TensorSlice@{TensorSlice}!Slice@{Slice}}
\index{Slice@{Slice}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Slice()}{Slice()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_adebcfb3b75b9a42ddfac2766c6ea0acc} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Slice (\begin{DoxyParamCaption}\item[{int}]{axis}{, }\item[{int}]{index}{}\end{DoxyParamCaption}) const}



Extracts a slice of the \doxylink{class_tensor}{Tensor} along a specified axis at a given index. 

This method returns a new \doxylink{class_tensor}{Tensor} representing a lower-\/rank slice of the current \doxylink{class_tensor}{Tensor}, taken along the specified axis at a particular index position. The operation performs a deep copy of the relevant data region, so the resulting \doxylink{class_tensor}{Tensor} is completely independent of the original.

The rank of the returned \doxylink{class_tensor}{Tensor} is {\ttfamily rank -\/ 1}, as the specified axis is removed. For example, slicing a (2, 3, 4) tensor along axis 1 at index 0 produces a (2, 4) tensor.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to slice. Must satisfy\+: {\ttfamily 0 ? axis \texorpdfstring{$<$}{<} rank}. \\
\hline
{\em index} & The index position along the given axis to extract. Must satisfy\+: {\ttfamily 0 ? index \texorpdfstring{$<$}{<} shape\mbox{[}axis\mbox{]}}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} slice with one fewer dimension (rank reduced by 1).
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The \doxylink{class_tensor}{Tensor} is empty (volume = 0).
\item The \doxylink{class_tensor}{Tensor} is a scalar (rank = 0).
\end{DoxyItemize}\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item The axis is negative or \texorpdfstring{$>$}{>}= rank.
\item The index is negative or \texorpdfstring{$>$}{>}= shape\mbox{[}axis\mbox{]}.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a copy-\/based operation. The returned \doxylink{class_tensor}{Tensor} has its own independent data buffer and does not share memory with the original.

This operation efficiently extracts non-\/contiguous data using stride information. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ab26b29a1be6c026364c9210307dcffde}\index{TensorSlice@{TensorSlice}!Slice@{Slice}}
\index{Slice@{Slice}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Slice()}{Slice()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{class_tensor_slice_ab26b29a1be6c026364c9210307dcffde} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Slice (\begin{DoxyParamCaption}\item[{int}]{axis}{, }\item[{int}]{index\+\_\+from}{, }\item[{int}]{index\+\_\+upto}{}\end{DoxyParamCaption}) const}



Extracts a range of slices from the \doxylink{class_tensor}{Tensor} along a given axis. 

This method performs slicing between two indices ({\ttfamily index\+\_\+from} inclusive and {\ttfamily index\+\_\+upto} exclusive) along the specified axis. Each individual slice is extracted using the single-\/index {\ttfamily \doxylink{class_tensor_slice_adebcfb3b75b9a42ddfac2766c6ea0acc}{Slice()}} method, and the results are stacked together along the same axis to form a contiguous sub-\/tensor.

The rank of the returned \doxylink{class_tensor}{Tensor} remains the same as the original. The dimension along the specified axis is reduced to {\ttfamily index\+\_\+upto -\/ index\+\_\+from}.

Like single-\/index slicing, this is a {\bfseries{copy-\/based}} operation resulting in an independent \doxylink{class_tensor}{Tensor} with no shared data.


\begin{DoxyParams}{Parameters}
{\em axis} & The axis along which to slice. Must satisfy\+: {\ttfamily 0 ? axis \texorpdfstring{$<$}{<} rank}.\\
\hline
{\em index\+\_\+from} & The starting index (inclusive) along the axis. Must satisfy\+: {\ttfamily 0 ? index\+\_\+from \texorpdfstring{$<$}{<} index\+\_\+upto}.\\
\hline
{\em index\+\_\+upto} & The ending index (exclusive) along the axis. Must satisfy\+: {\ttfamily index\+\_\+from \texorpdfstring{$<$}{<} index\+\_\+upto ? shape\mbox{[}axis\mbox{]}}.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} formed by stacking the specified slices along the same axis.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The \doxylink{class_tensor}{Tensor} is empty (volume = 0).
\item The \doxylink{class_tensor}{Tensor} is a scalar (rank = 0).
\end{DoxyItemize}\\
\hline
{\em std\+::out\+\_\+of\+\_\+range} & if\+:
\begin{DoxyItemize}
\item The axis is negative or \texorpdfstring{$>$}{>}= rank.
\item {\ttfamily index\+\_\+from} is negative or {\ttfamily index\+\_\+upto} is \texorpdfstring{$>$}{>} shape\mbox{[}axis\mbox{]}.
\end{DoxyItemize}\\
\hline
{\em std\+::invalid\+\_\+argument} & if {\ttfamily index\+\_\+from \texorpdfstring{$>$}{>}= index\+\_\+upto} (invalid range specification).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a copy-\/based operation. The returned \doxylink{class_tensor}{Tensor} has its own independent data buffer.

Internally, this method calls {\ttfamily Slice(axis, index)} for each index in the range and uses {\ttfamily Stack()} to combine them. 
\end{DoxyNote}
\Hypertarget{class_tensor_slice_a7709875a1c35f01cb88f26bd1ea3cfe1}\index{TensorSlice@{TensorSlice}!Sqrt@{Sqrt}}
\index{Sqrt@{Sqrt}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Sqrt()}{Sqrt()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a7709875a1c35f01cb88f26bd1ea3cfe1} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Sqrt (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the square root of each element. 

Returns a new tensor where each element is the square root of the corresponding element in the original tensor. This is equivalent to raising each element to the power of 0.\+5.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing square root values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is negative (square root undefined for negative reals).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

For negative values, consider using \doxylink{class_tensor_slice_a4eb8d65d3052ebac6c39c04326830b4b}{Abs()} first if magnitude is desired. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a5402ef990f310a0e47a776acc2020656}\index{TensorSlice@{TensorSlice}!Sum@{Sum}}
\index{Sum@{Sum}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Sum()}{Sum()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a5402ef990f310a0e47a776acc2020656} 
double Tensor\+Slice\+::\+Sum (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the sum of all elements in the tensor. 

Returns the sum of all elements as a scalar value. This is a global reduction operation across the entire tensor.

\begin{DoxyReturn}{Returns}
The sum of all elements.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
\end{DoxyExceptions}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_af56814ea935d8ee7c8945f21d452025d}\index{TensorSlice@{TensorSlice}!Tan@{Tan}}
\index{Tan@{Tan}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Tan()}{Tan()}}
{\footnotesize\ttfamily \label{class_tensor_slice_af56814ea935d8ee7c8945f21d452025d} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Tan (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the tangent of each element (in radians). 

Returns a new tensor where each element is the tangent of the corresponding element in the original tensor. The input is interpreted as angles in radians.

The tangent function is undefined at odd multiples of ?/2 (where cosine equals zero) and has vertical asymptotes at these points.

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing tangent values.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0). \\
\hline
{\em std\+::domain\+\_\+error} & if any element is approximately an odd multiple of ?/2 (where tangent is undefined).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a3298ee780337e0d515fe3b07e090a4bd}\index{TensorSlice@{TensorSlice}!Tanh@{Tanh}}
\index{Tanh@{Tanh}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Tanh()}{Tanh()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a3298ee780337e0d515fe3b07e090a4bd} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Tanh (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Computes the hyperbolic tangent of each element. 

Returns a new tensor where each element is the hyperbolic tangent of the corresponding element in the original tensor. The hyperbolic tangent is defined as\+: tanh(x) = sinh(x) / cosh(x) = (e\texorpdfstring{$^\wedge$}{\string^}x -\/ e\texorpdfstring{$^\wedge$}{\string^}(-\/x)) / (e\texorpdfstring{$^\wedge$}{\string^}x + e\texorpdfstring{$^\wedge$}{\string^}(-\/x))

The hyperbolic tangent function is defined for all real numbers, is an odd function, and has range (-\/1, 1).

\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the same shape containing hyperbolic tangent values in the range (-\/1, 1).
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ad0e4432eeecf83eb8f93d026cea106f3}\index{TensorSlice@{TensorSlice}!Tile@{Tile}}
\index{Tile@{Tile}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Tile()}{Tile()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ad0e4432eeecf83eb8f93d026cea106f3} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Tile (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{repetitions}{}\end{DoxyParamCaption}) const}



Repeats the entire tensor structure along each axis a specified number of times. 

This method creates a new \doxylink{class_tensor}{Tensor} by replicating the current tensor along each dimension. The repetitions vector specifies how many times to tile along each axis. The resulting tensor has shape {\ttfamily new\+\_\+shape\mbox{[}i\mbox{]} = original\+\_\+shape\mbox{[}i\mbox{]} \texorpdfstring{$\ast$}{*} repetitions\mbox{[}i\mbox{]}} for each axis i.

Unlike element-\/wise repetition, tiling repeats the entire structure as a block. For example, tiling \mbox{[}1,2,3\mbox{]} twice results in \mbox{[}1,2,3,1,2,3\mbox{]}, not \mbox{[}1,1,2,2,3,3\mbox{]}.

The operation proceeds from the innermost dimension (last axis) to the outermost (first axis), using concatenation to build up the tiled result incrementally.


\begin{DoxyParams}{Parameters}
{\em repetitions} & A vector specifying the number of repetitions along each axis. Must have the same length as the tensor\textquotesingle{}s rank. All values must be positive (\texorpdfstring{$>$}{>} 0).\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with the tiled structure.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The repetitions vector size does not match the tensor\textquotesingle{}s rank.
\item Any repetition value is non-\/positive (? 0).
\end{DoxyItemize}\\
\hline
{\em std\+::overflow\+\_\+error} & if\+:
\begin{DoxyItemize}
\item The product of repetitions exceeds INT\+\_\+\+MAX.
\item The resulting total volume exceeds INT\+\_\+\+MAX.
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original \doxylink{class_tensor}{Tensor} is unchanged.

The total volume of the result is {\ttfamily original\+\_\+volume × product(repetitions)}.

For large tensors and many repetitions, this operation can be memory-\/intensive. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ac0b56c26e6b0638e8be8512df974f2b9}\index{TensorSlice@{TensorSlice}!ToMatrix@{ToMatrix}}
\index{ToMatrix@{ToMatrix}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ToMatrix()}{ToMatrix()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ac0b56c26e6b0638e8be8512df974f2b9} 
std\+::vector$<$ std\+::vector$<$ double $>$ $>$ Tensor\+Slice\+::\+To\+Matrix (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Converts a rank-\/2 tensor to a 2D vector (matrix). 

Extracts all elements from a rank-\/2 tensor and returns them as a nested std\+::vector$<$std\+::vector$<$double$>$$>$. This is useful for interfacing with standard C++ code that expects 2D arrays or matrices.

The outer vector represents rows, and each inner vector represents the columns of that row.

\begin{DoxyReturn}{Returns}
A 2D vector containing all tensor elements organized by rows and columns.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is not rank-\/2 (not a matrix).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This creates a copy of the data. The original tensor is unchanged. 

Works correctly with sliced tensors (uses start and stride information). 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_aacca4d01deff58b2cb00aa0e0de4d3f8}\index{TensorSlice@{TensorSlice}!ToScalar@{ToScalar}}
\index{ToScalar@{ToScalar}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ToScalar()}{ToScalar()}}
{\footnotesize\ttfamily \label{class_tensor_slice_aacca4d01deff58b2cb00aa0e0de4d3f8} 
double Tensor\+Slice\+::\+To\+Scalar (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Converts a scalar tensor to a double value. 

Extracts and returns the single value from a rank-\/0 (scalar) tensor. This method only works on tensors with rank 0 and volume 1.

\begin{DoxyReturn}{Returns}
The scalar value as a double.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is not a scalar (rank \texorpdfstring{$>$}{>} 0 or volume != 1).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This is a convenience method for extracting scalar values from scalar tensors. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_a6072465ba590c092c398bded85469fd4}\index{TensorSlice@{TensorSlice}!ToVector@{ToVector}}
\index{ToVector@{ToVector}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{ToVector()}{ToVector()}}
{\footnotesize\ttfamily \label{class_tensor_slice_a6072465ba590c092c398bded85469fd4} 
std\+::vector$<$ double $>$ Tensor\+Slice\+::\+To\+Vector (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Converts a rank-\/1 tensor to a standard vector. 

Extracts all elements from a rank-\/1 tensor and returns them as a std\+::vector$<$double$>$. This is useful for interfacing with standard C++ code that expects vectors.

\begin{DoxyReturn}{Returns}
A std\+::vector$<$double$>$ containing all tensor elements in order.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is not rank-\/1 (not a vector).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This creates a copy of the data. The original tensor is unchanged. 

Works correctly with sliced tensors (uses start and end indices). 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ae1ce3b94498a11ea3f83a2c98d0f523f}\index{TensorSlice@{TensorSlice}!Transpose@{Transpose}}
\index{Transpose@{Transpose}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Transpose()}{Transpose()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ae1ce3b94498a11ea3f83a2c98d0f523f} 
\mbox{\hyperlink{class_tensor}{Tensor}} Tensor\+Slice\+::\+Transpose (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ int $>$ \&}]{permutation}{}\end{DoxyParamCaption}) const}



Transposes (permutes) the tensor\textquotesingle{}s axes according to a specified permutation. 

This method rearranges the tensor\textquotesingle{}s dimensions by permuting its axes according to the provided permutation vector. Each element in the permutation specifies which original axis should be placed at that position in the result.

For example, permutation \{1, 0, 2\} swaps the first two axes while keeping the third axis unchanged. This is a generalization of matrix transpose to arbitrary dimensions.

The operation creates a new tensor with reordered dimensions and rearranged data to match the new axis order.


\begin{DoxyParams}{Parameters}
{\em permutation} & A vector specifying the new order of axes. Must have length equal to the tensor\textquotesingle{}s rank. Must be a valid permutation\+: contain each value from 0 to (rank-\/1) exactly once.
\begin{DoxyItemize}
\item permutation\mbox{[}i\mbox{]} = j means the j-\/th axis of the original tensor becomes the i-\/th axis of the result.
\end{DoxyItemize}\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A new \doxylink{class_tensor}{Tensor} with permuted axes and reordered data.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::invalid\+\_\+argument} & if\+:
\begin{DoxyItemize}
\item The permutation size does not match the tensor\textquotesingle{}s rank.
\item The permutation contains negative values.
\item The permutation contains values \texorpdfstring{$>$}{>}= rank.
\item The permutation contains duplicate values (not a valid permutation).
\end{DoxyItemize}\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
This operation creates a new independent \doxylink{class_tensor}{Tensor}. The original tensor is unchanged.

The data is physically reordered to match the new axis layout, making subsequent access efficient. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_ade9abd7f940b3f1d50b16854f241abc3}\index{TensorSlice@{TensorSlice}!Var@{Var}}
\index{Var@{Var}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Var()}{Var()}}
{\footnotesize\ttfamily \label{class_tensor_slice_ade9abd7f940b3f1d50b16854f241abc3} 
double Tensor\+Slice\+::\+Var (\begin{DoxyParamCaption}\item[{bool}]{inference}{ = {\ttfamily false}}\end{DoxyParamCaption}) const}



Computes the variance of all elements in the tensor. 

Returns the variance of all elements as a scalar value. Variance measures how spread out the values are from their mean. This is a global reduction operation across the entire tensor.


\begin{DoxyParams}{Parameters}
{\em inference} & If true, uses Bessel\textquotesingle{}s correction (divides by n-\/1 for sample variance). If false, divides by n (population variance). Default is false.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The variance of all elements.
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::runtime\+\_\+error} & if the tensor is empty (volume = 0).\\
\hline
\end{DoxyExceptions}
\begin{DoxyNote}{Note}
Formula\+: Var = sum((x -\/ mean)²) / n (or n-\/1 if inference=true) 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}
\Hypertarget{class_tensor_slice_acfa02303d766c0d2399fe34a1943238d}\index{TensorSlice@{TensorSlice}!Volume@{Volume}}
\index{Volume@{Volume}!TensorSlice@{TensorSlice}}
\doxysubsubsection{\texorpdfstring{Volume()}{Volume()}}
{\footnotesize\ttfamily \label{class_tensor_slice_acfa02303d766c0d2399fe34a1943238d} 
int Tensor\+Slice\+::\+Volume (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const}



Returns the total number of elements (volume) in the tensor. 

The volume is the product of all dimensions in the tensor\textquotesingle{}s shape. It represents the total count of scalar values stored in the tensor.

\begin{DoxyReturn}{Returns}
The total number of elements as an integer.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
For an empty tensor and scalar tensor, this returns 0. 
\end{DoxyNote}
\begin{Desc}
\item[Examples]\par
\mbox{\hyperlink{_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example}{C\+:/\+Users/saha0/source/repos/\+Tensor/\+Tensor/\+Tensor\+Slice.\+h}}.\end{Desc}


The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
Tensor\+Slice.\+h\item 
Tensor\+Slice.\+cpp\end{DoxyCompactItemize}
