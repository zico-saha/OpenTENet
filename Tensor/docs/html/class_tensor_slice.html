<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: TensorSlice Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('class_tensor_slice.html','','class_tensor_slice-members'); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">TensorSlice Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Proxy class for tensor indexing that enables both copy and reference semantics.  
 <a href="#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_tensor_slice_8h_source.html">TensorSlice.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-pub-methods" class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ad6c7cb02037ef9c8be85e75f3d8295f5" id="r_ad6c7cb02037ef9c8be85e75f3d8295f5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad6c7cb02037ef9c8be85e75f3d8295f5">TensorSlice</a> (<a class="el" href="class_tensor.html">Tensor</a> *p, int idx)</td></tr>
<tr class="memdesc:ad6c7cb02037ef9c8be85e75f3d8295f5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> for a single index.  <br /></td></tr>
<tr class="memitem:a55c5c65bc9c909bdad1c45e188c2e99b" id="r_a55c5c65bc9c909bdad1c45e188c2e99b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a55c5c65bc9c909bdad1c45e188c2e99b">operator Tensor</a> () const</td></tr>
<tr class="memdesc:a55c5c65bc9c909bdad1c45e188c2e99b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implicit conversion to <a class="el" href="class_tensor.html">Tensor</a> (creates an independent copy).  <br /></td></tr>
<tr class="memitem:a725be809a7e2f9903fe1aa7bbfc7d425" id="r_a725be809a7e2f9903fe1aa7bbfc7d425"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a725be809a7e2f9903fe1aa7bbfc7d425">operator=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;other)</td></tr>
<tr class="memdesc:a725be809a7e2f9903fe1aa7bbfc7d425"><td class="mdescLeft">&#160;</td><td class="mdescRight">Assignment operator that modifies the root parent tensor.  <br /></td></tr>
<tr class="memitem:a36b4453303b38372b6b48b83bead2e45" id="r_a36b4453303b38372b6b48b83bead2e45"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a36b4453303b38372b6b48b83bead2e45">operator[]</a> (int idx)</td></tr>
<tr class="memdesc:a36b4453303b38372b6b48b83bead2e45"><td class="mdescLeft">&#160;</td><td class="mdescRight">Non-const indexing for continued chaining with modification capability.  <br /></td></tr>
<tr class="memitem:a9c53a0466348635b4b8a50f057a48d62" id="r_a9c53a0466348635b4b8a50f057a48d62"><td class="memItemLeft" align="right" valign="top"><a id="a9c53a0466348635b4b8a50f057a48d62" name="a9c53a0466348635b4b8a50f057a48d62"></a>
<a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>operator[]</b> (int idx) const</td></tr>
<tr class="memitem:a891cda49b0e34178a9abeab88481066f" id="r_a891cda49b0e34178a9abeab88481066f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a891cda49b0e34178a9abeab88481066f">operator+</a> (double value) const</td></tr>
<tr class="memdesc:a891cda49b0e34178a9abeab88481066f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise addition of a scalar value to all tensor elements.  <br /></td></tr>
<tr class="memitem:a30c1e8fe8a68609fda529a1ad6602724" id="r_a30c1e8fe8a68609fda529a1ad6602724"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a30c1e8fe8a68609fda529a1ad6602724">operator-</a> (double value) const</td></tr>
<tr class="memdesc:a30c1e8fe8a68609fda529a1ad6602724"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise subtraction of a scalar value from all tensor elements.  <br /></td></tr>
<tr class="memitem:af184ad77fc278974efbbcfce8be97e20" id="r_af184ad77fc278974efbbcfce8be97e20"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af184ad77fc278974efbbcfce8be97e20">operator*</a> (double value) const</td></tr>
<tr class="memdesc:af184ad77fc278974efbbcfce8be97e20"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise multiplication of all tensor elements by a scalar value.  <br /></td></tr>
<tr class="memitem:add3ca72dfa58d4f0d443da639fdb576b" id="r_add3ca72dfa58d4f0d443da639fdb576b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#add3ca72dfa58d4f0d443da639fdb576b">operator/</a> (double value) const</td></tr>
<tr class="memdesc:add3ca72dfa58d4f0d443da639fdb576b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise division of all tensor elements by a scalar value.  <br /></td></tr>
<tr class="memitem:a5cbf99706365813b2d14ddf63a9b9624" id="r_a5cbf99706365813b2d14ddf63a9b9624"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5cbf99706365813b2d14ddf63a9b9624">operator+</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:a5cbf99706365813b2d14ddf63a9b9624"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise addition of two tensors.  <br /></td></tr>
<tr class="memitem:ab31a85076571882207207be11c70cd34" id="r_ab31a85076571882207207be11c70cd34"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab31a85076571882207207be11c70cd34">operator-</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:ab31a85076571882207207be11c70cd34"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise subtraction of two tensors.  <br /></td></tr>
<tr class="memitem:abd2662558437bf0032085e5a483520d3" id="r_abd2662558437bf0032085e5a483520d3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abd2662558437bf0032085e5a483520d3">operator*</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:abd2662558437bf0032085e5a483520d3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise multiplication of two tensors (Hadamard product).  <br /></td></tr>
<tr class="memitem:a67aee1af10009acf23649fdae6e3dc49" id="r_a67aee1af10009acf23649fdae6e3dc49"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a67aee1af10009acf23649fdae6e3dc49">operator/</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:a67aee1af10009acf23649fdae6e3dc49"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise division of two tensors.  <br /></td></tr>
<tr class="memitem:a0a6c7af8296371c02d00f53b6aa3400a" id="r_a0a6c7af8296371c02d00f53b6aa3400a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0a6c7af8296371c02d00f53b6aa3400a">operator+=</a> (double value)</td></tr>
<tr class="memdesc:a0a6c7af8296371c02d00f53b6aa3400a"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise addition of a scalar value.  <br /></td></tr>
<tr class="memitem:a953cf784473905860747b49166078421" id="r_a953cf784473905860747b49166078421"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a953cf784473905860747b49166078421">operator-=</a> (double value)</td></tr>
<tr class="memdesc:a953cf784473905860747b49166078421"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise subtraction of a scalar value.  <br /></td></tr>
<tr class="memitem:a6fb8999e863da0cd422494ea8936e3bb" id="r_a6fb8999e863da0cd422494ea8936e3bb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6fb8999e863da0cd422494ea8936e3bb">operator*=</a> (double value)</td></tr>
<tr class="memdesc:a6fb8999e863da0cd422494ea8936e3bb"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise multiplication by a scalar value.  <br /></td></tr>
<tr class="memitem:ac0cfe800f5166e780913c459085c5240" id="r_ac0cfe800f5166e780913c459085c5240"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac0cfe800f5166e780913c459085c5240">operator/=</a> (double value)</td></tr>
<tr class="memdesc:ac0cfe800f5166e780913c459085c5240"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise division by a scalar value.  <br /></td></tr>
<tr class="memitem:af81661b65d4ef9a66109c5e2354e0621" id="r_af81661b65d4ef9a66109c5e2354e0621"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af81661b65d4ef9a66109c5e2354e0621">operator+=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:af81661b65d4ef9a66109c5e2354e0621"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise addition with another tensor.  <br /></td></tr>
<tr class="memitem:ad456ffc088943ad62eea57a8c80f05d7" id="r_ad456ffc088943ad62eea57a8c80f05d7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad456ffc088943ad62eea57a8c80f05d7">operator-=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:ad456ffc088943ad62eea57a8c80f05d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise subtraction with another tensor.  <br /></td></tr>
<tr class="memitem:a79372cfb766492f6d4a0beb236eca244" id="r_a79372cfb766492f6d4a0beb236eca244"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a79372cfb766492f6d4a0beb236eca244">operator*=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a79372cfb766492f6d4a0beb236eca244"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise multiplication with another tensor (Hadamard product).  <br /></td></tr>
<tr class="memitem:a1763727eccb717b5359293923576bf43" id="r_a1763727eccb717b5359293923576bf43"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1763727eccb717b5359293923576bf43">operator/=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a1763727eccb717b5359293923576bf43"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise division by another tensor.  <br /></td></tr>
<tr class="memitem:a324cf2ea9cc02476c25de1d4069468b0" id="r_a324cf2ea9cc02476c25de1d4069468b0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a324cf2ea9cc02476c25de1d4069468b0">Reshape</a> (const std::vector&lt; int &gt; &amp;new_shape) const</td></tr>
<tr class="memdesc:a324cf2ea9cc02476c25de1d4069468b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reshapes the <a class="el" href="class_tensor.html">Tensor</a> to a new specified shape without changing data order.  <br /></td></tr>
<tr class="memitem:aecd6af41dcc4e4a825408736216982a9" id="r_aecd6af41dcc4e4a825408736216982a9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aecd6af41dcc4e4a825408736216982a9">ExpandRank</a> (int axis=0) const</td></tr>
<tr class="memdesc:aecd6af41dcc4e4a825408736216982a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Expands the rank of the <a class="el" href="class_tensor.html">Tensor</a> by inserting a dimension of size 1 at a specified axis.  <br /></td></tr>
<tr class="memitem:a7037d4e167e55ad888dd1d9dac6b39eb" id="r_a7037d4e167e55ad888dd1d9dac6b39eb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7037d4e167e55ad888dd1d9dac6b39eb">Flatten</a> (int axis_from, int axis_upto) const</td></tr>
<tr class="memdesc:a7037d4e167e55ad888dd1d9dac6b39eb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flattens a range of consecutive axes into a single dimension.  <br /></td></tr>
<tr class="memitem:adebcfb3b75b9a42ddfac2766c6ea0acc" id="r_adebcfb3b75b9a42ddfac2766c6ea0acc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#adebcfb3b75b9a42ddfac2766c6ea0acc">Slice</a> (int axis, int index) const</td></tr>
<tr class="memdesc:adebcfb3b75b9a42ddfac2766c6ea0acc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extracts a slice of the <a class="el" href="class_tensor.html">Tensor</a> along a specified axis at a given index.  <br /></td></tr>
<tr class="memitem:ab26b29a1be6c026364c9210307dcffde" id="r_ab26b29a1be6c026364c9210307dcffde"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab26b29a1be6c026364c9210307dcffde">Slice</a> (int axis, int index_from, int index_upto) const</td></tr>
<tr class="memdesc:ab26b29a1be6c026364c9210307dcffde"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extracts a range of slices from the <a class="el" href="class_tensor.html">Tensor</a> along a given axis.  <br /></td></tr>
<tr class="memitem:a44621cdd09df688b2c5cb4bd000d8f73" id="r_a44621cdd09df688b2c5cb4bd000d8f73"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a44621cdd09df688b2c5cb4bd000d8f73">Pad</a> (int axis, int pad_before, int pad_after, double value=0.0) const</td></tr>
<tr class="memdesc:a44621cdd09df688b2c5cb4bd000d8f73"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds padding elements before and/or after the tensor along a specified axis.  <br /></td></tr>
<tr class="memitem:ad0e4432eeecf83eb8f93d026cea106f3" id="r_ad0e4432eeecf83eb8f93d026cea106f3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad0e4432eeecf83eb8f93d026cea106f3">Tile</a> (const std::vector&lt; int &gt; &amp;repetitions) const</td></tr>
<tr class="memdesc:ad0e4432eeecf83eb8f93d026cea106f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Repeats the entire tensor structure along each axis a specified number of times.  <br /></td></tr>
<tr class="memitem:a26aebba00b9e12f161384198295678f0" id="r_a26aebba00b9e12f161384198295678f0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a26aebba00b9e12f161384198295678f0">Broadcast</a> (const std::vector&lt; int &gt; &amp;shape) const</td></tr>
<tr class="memdesc:a26aebba00b9e12f161384198295678f0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Broadcasts the tensor to a target shape following NumPy-style broadcasting rules.  <br /></td></tr>
<tr class="memitem:ae1ce3b94498a11ea3f83a2c98d0f523f" id="r_ae1ce3b94498a11ea3f83a2c98d0f523f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae1ce3b94498a11ea3f83a2c98d0f523f">Transpose</a> (const std::vector&lt; int &gt; &amp;permutation) const</td></tr>
<tr class="memdesc:ae1ce3b94498a11ea3f83a2c98d0f523f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Transposes (permutes) the tensor's axes according to a specified permutation.  <br /></td></tr>
<tr class="memitem:a30214f0ea0c3c3163bd05ca52c7dc95c" id="r_a30214f0ea0c3c3163bd05ca52c7dc95c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a30214f0ea0c3c3163bd05ca52c7dc95c">MatMul</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:a30214f0ea0c3c3163bd05ca52c7dc95c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication with another tensor.  <br /></td></tr>
<tr class="memitem:a8d2f2a27e468f2431a65cad597beec93" id="r_a8d2f2a27e468f2431a65cad597beec93"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8d2f2a27e468f2431a65cad597beec93">Convolve</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;filter, const std::vector&lt; int &gt; &amp;strides, const std::vector&lt; int &gt; &amp;padding)</td></tr>
<tr class="memdesc:a8d2f2a27e468f2431a65cad597beec93"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs N-dimensional convolution between this tensor and a filter kernel.  <br /></td></tr>
<tr class="memitem:a58d10d1fd229a260e8a9299a6b6208f3" id="r_a58d10d1fd229a260e8a9299a6b6208f3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a58d10d1fd229a260e8a9299a6b6208f3">MaxPool</a> (const std::vector&lt; int &gt; &amp;pool_shape, const std::vector&lt; int &gt; &amp;strides={})</td></tr>
<tr class="memdesc:a58d10d1fd229a260e8a9299a6b6208f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs max pooling operation by taking the maximum value within sliding windows.  <br /></td></tr>
<tr class="memitem:ac7587c1151e35617411a27b786bb420c" id="r_ac7587c1151e35617411a27b786bb420c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac7587c1151e35617411a27b786bb420c">MinPool</a> (const std::vector&lt; int &gt; &amp;pool_shape, const std::vector&lt; int &gt; &amp;strides={})</td></tr>
<tr class="memdesc:ac7587c1151e35617411a27b786bb420c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs min pooling operation by taking the minimum value within sliding windows.  <br /></td></tr>
<tr class="memitem:a9d55201d57f76d5c94cf58eda3c35725" id="r_a9d55201d57f76d5c94cf58eda3c35725"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9d55201d57f76d5c94cf58eda3c35725">AvgPool</a> (const std::vector&lt; int &gt; &amp;pool_shape, const std::vector&lt; int &gt; &amp;strides={})</td></tr>
<tr class="memdesc:a9d55201d57f76d5c94cf58eda3c35725"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs average pooling operation by computing the mean value within sliding windows.  <br /></td></tr>
<tr class="memitem:ada3970a1f99f8e389c6272d0e8f54944" id="r_ada3970a1f99f8e389c6272d0e8f54944"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ada3970a1f99f8e389c6272d0e8f54944">Sign</a> (bool heaviside=false) const</td></tr>
<tr class="memdesc:ada3970a1f99f8e389c6272d0e8f54944"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the sign function element-wise.  <br /></td></tr>
<tr class="memitem:afe2ed01b32773724e684e9fe6090f531" id="r_afe2ed01b32773724e684e9fe6090f531"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#afe2ed01b32773724e684e9fe6090f531">ReduceSum</a> (int axis) const</td></tr>
<tr class="memdesc:afe2ed01b32773724e684e9fe6090f531"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the sum.  <br /></td></tr>
<tr class="memitem:a0bc4030adf64e861696d2033f6fc08bb" id="r_a0bc4030adf64e861696d2033f6fc08bb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0bc4030adf64e861696d2033f6fc08bb">ReduceMean</a> (int axis) const</td></tr>
<tr class="memdesc:a0bc4030adf64e861696d2033f6fc08bb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the mean (average).  <br /></td></tr>
<tr class="memitem:a0898917704e36edbd2b99779010f945e" id="r_a0898917704e36edbd2b99779010f945e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0898917704e36edbd2b99779010f945e">ReduceVar</a> (int axis, bool inference=false) const</td></tr>
<tr class="memdesc:a0898917704e36edbd2b99779010f945e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the variance.  <br /></td></tr>
<tr class="memitem:a581bc889132baeaafc6974c523c80189" id="r_a581bc889132baeaafc6974c523c80189"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a581bc889132baeaafc6974c523c80189">ReduceMax</a> (int axis) const</td></tr>
<tr class="memdesc:a581bc889132baeaafc6974c523c80189"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the maximum.  <br /></td></tr>
<tr class="memitem:a0bd288decf47bfad24af8d46a70f2952" id="r_a0bd288decf47bfad24af8d46a70f2952"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0bd288decf47bfad24af8d46a70f2952">ReduceMin</a> (int axis) const</td></tr>
<tr class="memdesc:a0bd288decf47bfad24af8d46a70f2952"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the minimum.  <br /></td></tr>
<tr class="memitem:a5402ef990f310a0e47a776acc2020656" id="r_a5402ef990f310a0e47a776acc2020656"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5402ef990f310a0e47a776acc2020656">Sum</a> () const</td></tr>
<tr class="memdesc:a5402ef990f310a0e47a776acc2020656"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the sum of all elements in the tensor.  <br /></td></tr>
<tr class="memitem:a1cc3aa9a38e6baba9ed12371986c45c2" id="r_a1cc3aa9a38e6baba9ed12371986c45c2"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1cc3aa9a38e6baba9ed12371986c45c2">Mean</a> () const</td></tr>
<tr class="memdesc:a1cc3aa9a38e6baba9ed12371986c45c2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the mean (average) of all elements in the tensor.  <br /></td></tr>
<tr class="memitem:ade9abd7f940b3f1d50b16854f241abc3" id="r_ade9abd7f940b3f1d50b16854f241abc3"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ade9abd7f940b3f1d50b16854f241abc3">Var</a> (bool inference=false) const</td></tr>
<tr class="memdesc:ade9abd7f940b3f1d50b16854f241abc3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the variance of all elements in the tensor.  <br /></td></tr>
<tr class="memitem:a40baf8d6e10b1024e654af746e84a649" id="r_a40baf8d6e10b1024e654af746e84a649"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a40baf8d6e10b1024e654af746e84a649">Max</a> () const</td></tr>
<tr class="memdesc:a40baf8d6e10b1024e654af746e84a649"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finds the maximum value in the tensor.  <br /></td></tr>
<tr class="memitem:a0a7fb881f780412a2d39ca26089fb26e" id="r_a0a7fb881f780412a2d39ca26089fb26e"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0a7fb881f780412a2d39ca26089fb26e">Min</a> () const</td></tr>
<tr class="memdesc:a0a7fb881f780412a2d39ca26089fb26e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finds the minimum value in the tensor.  <br /></td></tr>
<tr class="memitem:a4eb8d65d3052ebac6c39c04326830b4b" id="r_a4eb8d65d3052ebac6c39c04326830b4b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4eb8d65d3052ebac6c39c04326830b4b">Abs</a> () const</td></tr>
<tr class="memdesc:a4eb8d65d3052ebac6c39c04326830b4b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the absolute value of each element.  <br /></td></tr>
<tr class="memitem:a3fe9669c843cf233b390f01befe92280" id="r_a3fe9669c843cf233b390f01befe92280"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3fe9669c843cf233b390f01befe92280">Floor</a> () const</td></tr>
<tr class="memdesc:a3fe9669c843cf233b390f01befe92280"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rounds each element down to the nearest integer (floor function).  <br /></td></tr>
<tr class="memitem:a9636224ea3638818437a002240e36725" id="r_a9636224ea3638818437a002240e36725"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9636224ea3638818437a002240e36725">Ceil</a> () const</td></tr>
<tr class="memdesc:a9636224ea3638818437a002240e36725"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rounds each element up to the nearest integer (ceiling function).  <br /></td></tr>
<tr class="memitem:ab07074813ba5a5f62a9246fe99d1430c" id="r_ab07074813ba5a5f62a9246fe99d1430c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab07074813ba5a5f62a9246fe99d1430c">Round</a> (int decimal_place=0) const</td></tr>
<tr class="memdesc:ab07074813ba5a5f62a9246fe99d1430c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rounds each element to a specified number of decimal places.  <br /></td></tr>
<tr class="memitem:aef30c23712785dd04bd9e02ba41dc78b" id="r_aef30c23712785dd04bd9e02ba41dc78b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aef30c23712785dd04bd9e02ba41dc78b">Clip</a> (double min_value, double max_value) const</td></tr>
<tr class="memdesc:aef30c23712785dd04bd9e02ba41dc78b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clips (clamps) each element to be within a specified range.  <br /></td></tr>
<tr class="memitem:ab3b88de18822c6f21b4f846fc2a08651" id="r_ab3b88de18822c6f21b4f846fc2a08651"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab3b88de18822c6f21b4f846fc2a08651">Power</a> (double exponent) const</td></tr>
<tr class="memdesc:ab3b88de18822c6f21b4f846fc2a08651"><td class="mdescLeft">&#160;</td><td class="mdescRight">Raises each element to a specified power (exponentiation).     <br /></td></tr>
<tr class="memitem:a7709875a1c35f01cb88f26bd1ea3cfe1" id="r_a7709875a1c35f01cb88f26bd1ea3cfe1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7709875a1c35f01cb88f26bd1ea3cfe1">Sqrt</a> () const</td></tr>
<tr class="memdesc:a7709875a1c35f01cb88f26bd1ea3cfe1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the square root of each element.  <br /></td></tr>
<tr class="memitem:a06db73fa0da2f9e770dcfe21cc14e828" id="r_a06db73fa0da2f9e770dcfe21cc14e828"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a06db73fa0da2f9e770dcfe21cc14e828">Log</a> (double base=std::numbers::e) const</td></tr>
<tr class="memdesc:a06db73fa0da2f9e770dcfe21cc14e828"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the logarithm of each element with a specified base.  <br /></td></tr>
<tr class="memitem:ad2ec37ad613eebdab3c0bf8bba3e27ee" id="r_ad2ec37ad613eebdab3c0bf8bba3e27ee"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad2ec37ad613eebdab3c0bf8bba3e27ee">Exp</a> () const</td></tr>
<tr class="memdesc:ad2ec37ad613eebdab3c0bf8bba3e27ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes e raised to the power of each element (exponential function).  <br /></td></tr>
<tr class="memitem:a556db8ba686446c0412952d9405f42ba" id="r_a556db8ba686446c0412952d9405f42ba"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a556db8ba686446c0412952d9405f42ba">Mod</a> (double mod_value) const</td></tr>
<tr class="memdesc:a556db8ba686446c0412952d9405f42ba"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the modulus (remainder) of each element divided by a value.  <br /></td></tr>
<tr class="memitem:a13d0676062409a9e032ca58e0bf2d8ff" id="r_a13d0676062409a9e032ca58e0bf2d8ff"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a13d0676062409a9e032ca58e0bf2d8ff">Sin</a> () const</td></tr>
<tr class="memdesc:a13d0676062409a9e032ca58e0bf2d8ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the sine of each element (in radians).  <br /></td></tr>
<tr class="memitem:a50af8b385c36ce9ab4c707d96e131f30" id="r_a50af8b385c36ce9ab4c707d96e131f30"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a50af8b385c36ce9ab4c707d96e131f30">Cos</a> () const</td></tr>
<tr class="memdesc:a50af8b385c36ce9ab4c707d96e131f30"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the cosine of each element (in radians).  <br /></td></tr>
<tr class="memitem:af56814ea935d8ee7c8945f21d452025d" id="r_af56814ea935d8ee7c8945f21d452025d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af56814ea935d8ee7c8945f21d452025d">Tan</a> () const</td></tr>
<tr class="memdesc:af56814ea935d8ee7c8945f21d452025d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the tangent of each element (in radians).  <br /></td></tr>
<tr class="memitem:ad69af858ebe61a0637ca0f8f4d05e4be" id="r_ad69af858ebe61a0637ca0f8f4d05e4be"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad69af858ebe61a0637ca0f8f4d05e4be">Csc</a> () const</td></tr>
<tr class="memdesc:ad69af858ebe61a0637ca0f8f4d05e4be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the cosecant (reciprocal of sine) of each element (in radians).  <br /></td></tr>
<tr class="memitem:a0e1f2f379dd0ff1dcdffe924f7f1360c" id="r_a0e1f2f379dd0ff1dcdffe924f7f1360c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0e1f2f379dd0ff1dcdffe924f7f1360c">Sec</a> () const</td></tr>
<tr class="memdesc:a0e1f2f379dd0ff1dcdffe924f7f1360c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the secant (reciprocal of cosine) of each element (in radians).  <br /></td></tr>
<tr class="memitem:af93c5440a098163158a3ef04a1286fe2" id="r_af93c5440a098163158a3ef04a1286fe2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af93c5440a098163158a3ef04a1286fe2">Cot</a> () const</td></tr>
<tr class="memdesc:af93c5440a098163158a3ef04a1286fe2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the cotangent (reciprocal of tangent) of each element (in radians).  <br /></td></tr>
<tr class="memitem:a29a4acf502a0696d3e04c6d178f77a99" id="r_a29a4acf502a0696d3e04c6d178f77a99"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a29a4acf502a0696d3e04c6d178f77a99">Asin</a> () const</td></tr>
<tr class="memdesc:a29a4acf502a0696d3e04c6d178f77a99"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arcsine (inverse sine) of each element.  <br /></td></tr>
<tr class="memitem:a7a2ec909ae143cf9388ffe47cd331fcb" id="r_a7a2ec909ae143cf9388ffe47cd331fcb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7a2ec909ae143cf9388ffe47cd331fcb">Acos</a> () const</td></tr>
<tr class="memdesc:a7a2ec909ae143cf9388ffe47cd331fcb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arccosine (inverse cosine) of each element.  <br /></td></tr>
<tr class="memitem:a519178f6b8e4ae40533c4d6030dee949" id="r_a519178f6b8e4ae40533c4d6030dee949"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a519178f6b8e4ae40533c4d6030dee949">Atan</a> () const</td></tr>
<tr class="memdesc:a519178f6b8e4ae40533c4d6030dee949"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arctangent (inverse tangent) of each element.  <br /></td></tr>
<tr class="memitem:af3d3ab207245adb801b802f66b5fde73" id="r_af3d3ab207245adb801b802f66b5fde73"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af3d3ab207245adb801b802f66b5fde73">Acsc</a> () const</td></tr>
<tr class="memdesc:af3d3ab207245adb801b802f66b5fde73"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arccosecant (inverse cosecant) of each element.  <br /></td></tr>
<tr class="memitem:a73b6144b9dd8e7e74951fe443bc4a849" id="r_a73b6144b9dd8e7e74951fe443bc4a849"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a73b6144b9dd8e7e74951fe443bc4a849">Asec</a> () const</td></tr>
<tr class="memdesc:a73b6144b9dd8e7e74951fe443bc4a849"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arcsecant (inverse secant) of each element.  <br /></td></tr>
<tr class="memitem:a95fc99ff4da0f51a8269cab2ae10086f" id="r_a95fc99ff4da0f51a8269cab2ae10086f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a95fc99ff4da0f51a8269cab2ae10086f">Acot</a> () const</td></tr>
<tr class="memdesc:a95fc99ff4da0f51a8269cab2ae10086f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arccotangent (inverse cotangent) of each element.  <br /></td></tr>
<tr class="memitem:af9a20344356eae9d28baf7aab314b80b" id="r_af9a20344356eae9d28baf7aab314b80b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af9a20344356eae9d28baf7aab314b80b">Sinh</a> () const</td></tr>
<tr class="memdesc:af9a20344356eae9d28baf7aab314b80b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic sine of each element.  <br /></td></tr>
<tr class="memitem:a8eb0360a00945e98f06285a16a4d66ee" id="r_a8eb0360a00945e98f06285a16a4d66ee"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8eb0360a00945e98f06285a16a4d66ee">Cosh</a> () const</td></tr>
<tr class="memdesc:a8eb0360a00945e98f06285a16a4d66ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic cosine of each element.  <br /></td></tr>
<tr class="memitem:a3298ee780337e0d515fe3b07e090a4bd" id="r_a3298ee780337e0d515fe3b07e090a4bd"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3298ee780337e0d515fe3b07e090a4bd">Tanh</a> () const</td></tr>
<tr class="memdesc:a3298ee780337e0d515fe3b07e090a4bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic tangent of each element.  <br /></td></tr>
<tr class="memitem:a39e047e2b44d05b024fe15d884ac8df3" id="r_a39e047e2b44d05b024fe15d884ac8df3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a39e047e2b44d05b024fe15d884ac8df3">Csch</a> () const</td></tr>
<tr class="memdesc:a39e047e2b44d05b024fe15d884ac8df3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element.  <br /></td></tr>
<tr class="memitem:a44053a3ce4683ba4e4000b59555cf361" id="r_a44053a3ce4683ba4e4000b59555cf361"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a44053a3ce4683ba4e4000b59555cf361">Sech</a> () const</td></tr>
<tr class="memdesc:a44053a3ce4683ba4e4000b59555cf361"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element.  <br /></td></tr>
<tr class="memitem:a47239a452da7a9bcac96b60d87882669" id="r_a47239a452da7a9bcac96b60d87882669"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a47239a452da7a9bcac96b60d87882669">Coth</a> () const</td></tr>
<tr class="memdesc:a47239a452da7a9bcac96b60d87882669"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element.  <br /></td></tr>
<tr class="memitem:a3b512d0a8f019ec8d9f20e274525e799" id="r_a3b512d0a8f019ec8d9f20e274525e799"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3b512d0a8f019ec8d9f20e274525e799">Asinh</a> () const</td></tr>
<tr class="memdesc:a3b512d0a8f019ec8d9f20e274525e799"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic sine of each element.  <br /></td></tr>
<tr class="memitem:ae69b2212f5ed15bd6ae63cec84a57d8f" id="r_ae69b2212f5ed15bd6ae63cec84a57d8f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae69b2212f5ed15bd6ae63cec84a57d8f">Acosh</a> () const</td></tr>
<tr class="memdesc:ae69b2212f5ed15bd6ae63cec84a57d8f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic cosine of each element.  <br /></td></tr>
<tr class="memitem:ae6ea5e2eb62073e68c546b03a7561acb" id="r_ae6ea5e2eb62073e68c546b03a7561acb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae6ea5e2eb62073e68c546b03a7561acb">Atanh</a> () const</td></tr>
<tr class="memdesc:ae6ea5e2eb62073e68c546b03a7561acb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic tangent of each element.  <br /></td></tr>
<tr class="memitem:a85fe09e15d404b4a254eaec5fb1df4ca" id="r_a85fe09e15d404b4a254eaec5fb1df4ca"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a85fe09e15d404b4a254eaec5fb1df4ca">Acsch</a> () const</td></tr>
<tr class="memdesc:a85fe09e15d404b4a254eaec5fb1df4ca"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic cosecant of each element.  <br /></td></tr>
<tr class="memitem:ade05697844f7212fa4aec69de25743c6" id="r_ade05697844f7212fa4aec69de25743c6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ade05697844f7212fa4aec69de25743c6">Asech</a> () const</td></tr>
<tr class="memdesc:ade05697844f7212fa4aec69de25743c6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic secant of each element.  <br /></td></tr>
<tr class="memitem:a1acd6ad17fc6f224966a0804113f64a7" id="r_a1acd6ad17fc6f224966a0804113f64a7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1acd6ad17fc6f224966a0804113f64a7">Acoth</a> () const</td></tr>
<tr class="memdesc:a1acd6ad17fc6f224966a0804113f64a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic cotangent of each element.  <br /></td></tr>
<tr class="memitem:a5d66ce8c7e459c2c6e9d2f2cc0c16ee3" id="r_a5d66ce8c7e459c2c6e9d2f2cc0c16ee3"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5d66ce8c7e459c2c6e9d2f2cc0c16ee3">Rank</a> () const</td></tr>
<tr class="memdesc:a5d66ce8c7e459c2c6e9d2f2cc0c16ee3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the rank (number of dimensions) of the tensor.  <br /></td></tr>
<tr class="memitem:acfa02303d766c0d2399fe34a1943238d" id="r_acfa02303d766c0d2399fe34a1943238d"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acfa02303d766c0d2399fe34a1943238d">Volume</a> () const</td></tr>
<tr class="memdesc:acfa02303d766c0d2399fe34a1943238d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the total number of elements (volume) in the tensor.  <br /></td></tr>
<tr class="memitem:af773875332be2e70344d4a17429166ba" id="r_af773875332be2e70344d4a17429166ba"><td class="memItemLeft" align="right" valign="top">std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af773875332be2e70344d4a17429166ba">Shape</a> () const</td></tr>
<tr class="memdesc:af773875332be2e70344d4a17429166ba"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the shape of the tensor as a vector of dimension sizes.  <br /></td></tr>
<tr class="memitem:a847c00a1c549d33cebe3a4ef2f4d3b2f" id="r_a847c00a1c549d33cebe3a4ef2f4d3b2f"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a847c00a1c549d33cebe3a4ef2f4d3b2f">IsEmpty</a> () const</td></tr>
<tr class="memdesc:a847c00a1c549d33cebe3a4ef2f4d3b2f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks whether the tensor contains no elements.  <br /></td></tr>
<tr class="memitem:a25b03c23ebc8f53112bd2b5083d981b7" id="r_a25b03c23ebc8f53112bd2b5083d981b7"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a25b03c23ebc8f53112bd2b5083d981b7">IsScalar</a> () const</td></tr>
<tr class="memdesc:a25b03c23ebc8f53112bd2b5083d981b7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks whether the tensor represents a scalar (single) value.  <br /></td></tr>
<tr class="memitem:ac4fca8605058c8dd92bc8bbb1eba2969" id="r_ac4fca8605058c8dd92bc8bbb1eba2969"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac4fca8605058c8dd92bc8bbb1eba2969">Print</a> (int depth=0) const</td></tr>
<tr class="memdesc:ac4fca8605058c8dd92bc8bbb1eba2969"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prints the tensor contents to standard output in a readable, nested format.  <br /></td></tr>
<tr class="memitem:aacca4d01deff58b2cb00aa0e0de4d3f8" id="r_aacca4d01deff58b2cb00aa0e0de4d3f8"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aacca4d01deff58b2cb00aa0e0de4d3f8">ToScalar</a> () const</td></tr>
<tr class="memdesc:aacca4d01deff58b2cb00aa0e0de4d3f8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a scalar tensor to a double value.  <br /></td></tr>
<tr class="memitem:a6072465ba590c092c398bded85469fd4" id="r_a6072465ba590c092c398bded85469fd4"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6072465ba590c092c398bded85469fd4">ToVector</a> () const</td></tr>
<tr class="memdesc:a6072465ba590c092c398bded85469fd4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a rank-1 tensor to a standard vector.  <br /></td></tr>
<tr class="memitem:ac0b56c26e6b0638e8be8512df974f2b9" id="r_ac0b56c26e6b0638e8be8512df974f2b9"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; double &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac0b56c26e6b0638e8be8512df974f2b9">ToMatrix</a> () const</td></tr>
<tr class="memdesc:ac0b56c26e6b0638e8be8512df974f2b9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a rank-2 tensor to a 2D vector (matrix).  <br /></td></tr>
</table>
<a name="details" id="details"></a><h2 id="header-details" class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Proxy class for tensor indexing that enables both copy and reference semantics. </p>
<p><a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> is returned by <a class="el" href="class_tensor.html">Tensor</a>'s non-const operator[] and supports chained indexing. It allows modifications to propagate to the original tensor while also enabling independent copies when needed.</p>
<p>Key behaviors:</p><ul>
<li>Implicit conversion to <a class="el" href="class_tensor.html">Tensor</a> creates an independent copy</li>
<li>Assignment modifies the original tensor through the index chain</li>
<li>Chaining indexing builds up a chain of indices</li>
<li>Pass-through methods delegate to the underlying <a class="el" href="class_tensor.html">Tensor</a></li>
</ul>
<dl class="section note"><dt>Note</dt><dd>Users should use explicit <span class="tt"><a class="el" href="class_tensor.html">Tensor</a></span> type declarations to get independent copies, not <span class="tt">auto</span>, which would deduce <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a>. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#_a1">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>
</div><a name="doc-constructors" id="doc-constructors"></a><h2 id="header-doc-constructors" class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ad6c7cb02037ef9c8be85e75f3d8295f5" name="ad6c7cb02037ef9c8be85e75f3d8295f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6c7cb02037ef9c8be85e75f3d8295f5">&#9670;&#160;</a></span>TensorSlice()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">TensorSlice::TensorSlice </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_tensor.html">Tensor</a> *</td>          <td class="paramname"><span class="paramname"><em>p</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>idx</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> for a single index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">p</td><td>Pointer to the parent <a class="el" href="class_tensor.html">Tensor</a>. </td></tr>
    <tr><td class="paramname">idx</td><td>The index along the first dimension. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a name="doc-func-members" id="doc-func-members"></a><h2 id="header-doc-func-members" class="groupheader">Member Function Documentation</h2>
<a id="a4eb8d65d3052ebac6c39c04326830b4b" name="a4eb8d65d3052ebac6c39c04326830b4b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4eb8d65d3052ebac6c39c04326830b4b">&#9670;&#160;</a></span>Abs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Abs </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the absolute value of each element. </p>
<p>Returns a new tensor where each element is the absolute value (magnitude) of the corresponding element in the original tensor. For any value x, the result is |x|, which is always non-negative.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing absolute values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a36">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a7a2ec909ae143cf9388ffe47cd331fcb" name="a7a2ec909ae143cf9388ffe47cd331fcb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a2ec909ae143cf9388ffe47cd331fcb">&#9670;&#160;</a></span>Acos()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Acos </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arccosine (inverse cosine) of each element. </p>
<p>Returns a new tensor where each element is the arccosine of the corresponding element in the original tensor. The result is in radians in the range [0, ?].</p>
<p>The arccosine function is only defined for input values in the range [-1, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arccosine values in radians, ranging from 0 to ?.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is outside the range [-1, 1].</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/?. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a53">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ae69b2212f5ed15bd6ae63cec84a57d8f" name="ae69b2212f5ed15bd6ae63cec84a57d8f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae69b2212f5ed15bd6ae63cec84a57d8f">&#9670;&#160;</a></span>Acosh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Acosh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic cosine of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic cosine (also called area hyperbolic cosine) of the corresponding element in the original tensor. It is defined as: acosh(x) = ln(x + sqrt(x - 1))</p>
<p>The inverse hyperbolic cosine is only defined for values ? 1.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic cosine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is less than 1 (where acosh is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a65">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a95fc99ff4da0f51a8269cab2ae10086f" name="a95fc99ff4da0f51a8269cab2ae10086f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a95fc99ff4da0f51a8269cab2ae10086f">&#9670;&#160;</a></span>Acot()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Acot </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arccotangent (inverse cotangent) of each element. </p>
<p>Returns a new tensor where each element is the arccotangent of the corresponding element in the original tensor. The result is in radians in the range (0, ?).</p>
<p>The arccotangent function is defined for all real numbers. For zero, it returns ?/2. For negative values, the result is adjusted to maintain the range [0, ?].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arccotangent values in radians, ranging from 0 to ?.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/?. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a57">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a1acd6ad17fc6f224966a0804113f64a7" name="a1acd6ad17fc6f224966a0804113f64a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1acd6ad17fc6f224966a0804113f64a7">&#9670;&#160;</a></span>Acoth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Acoth </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic cotangent of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic cotangent of the corresponding element in the original tensor. It is computed as: acoth(x) = atanh(1/x)</p>
<p>The inverse hyperbolic cotangent is only defined for values in (-?, -1) ? (1, ?). Values in the range [-1, 1] are undefined.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic cotangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is in the range [-1, 1] (where acoth is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a69">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="af3d3ab207245adb801b802f66b5fde73" name="af3d3ab207245adb801b802f66b5fde73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3d3ab207245adb801b802f66b5fde73">&#9670;&#160;</a></span>Acsc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Acsc </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arccosecant (inverse cosecant) of each element. </p>
<p>Returns a new tensor where each element is the arccosecant of the corresponding element in the original tensor. The result is in radians.</p>
<p>The arccosecant function is only defined for values in (-?, -1] ? [1, ?). It is computed as asin(1/x).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arccosecant values in radians.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is in the range (-1, 1), where arccosecant is undefined.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/?. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a55">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a85fe09e15d404b4a254eaec5fb1df4ca" name="a85fe09e15d404b4a254eaec5fb1df4ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85fe09e15d404b4a254eaec5fb1df4ca">&#9670;&#160;</a></span>Acsch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Acsch </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic cosecant of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic cosecant of the corresponding element in the original tensor. It is computed as: acsch(x) = asinh(1/x)</p>
<p>The inverse hyperbolic cosecant is undefined at zero.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic cosecant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately zero (where acsch is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a67">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a73b6144b9dd8e7e74951fe443bc4a849" name="a73b6144b9dd8e7e74951fe443bc4a849"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a73b6144b9dd8e7e74951fe443bc4a849">&#9670;&#160;</a></span>Asec()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Asec </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arcsecant (inverse secant) of each element. </p>
<p>Returns a new tensor where each element is the arcsecant of the corresponding element in the original tensor. The result is in radians.</p>
<p>The arcsecant function is only defined for values in (-?, -1] ? [1, ?). It is computed as acos(1/x).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arcsecant values in radians.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is in the range (-1, 1), where arcsecant is undefined.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/?. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a56">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ade05697844f7212fa4aec69de25743c6" name="ade05697844f7212fa4aec69de25743c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade05697844f7212fa4aec69de25743c6">&#9670;&#160;</a></span>Asech()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Asech </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic secant of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic secant of the corresponding element in the original tensor. It is computed as: asech(x) = acosh(1/x)</p>
<p>The inverse hyperbolic secant is only defined for values in the range (0, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic secant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is ? 0 or &gt; 1 (where asech is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a68">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a29a4acf502a0696d3e04c6d178f77a99" name="a29a4acf502a0696d3e04c6d178f77a99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a29a4acf502a0696d3e04c6d178f77a99">&#9670;&#160;</a></span>Asin()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Asin </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arcsine (inverse sine) of each element. </p>
<p>Returns a new tensor where each element is the arcsine of the corresponding element in the original tensor. The result is in radians in the range [-?/2, ?/2].</p>
<p>The arcsine function is only defined for input values in the range [-1, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arcsine values in radians, ranging from -?/2 to ?/2.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is outside the range [-1, 1].</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/?. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a52">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a3b512d0a8f019ec8d9f20e274525e799" name="a3b512d0a8f019ec8d9f20e274525e799"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3b512d0a8f019ec8d9f20e274525e799">&#9670;&#160;</a></span>Asinh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Asinh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic sine of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic sine (also called area hyperbolic sine) of the corresponding element in the original tensor. It is defined as: asinh(x) = ln(x + sqrt(x + 1))</p>
<p>The inverse hyperbolic sine is defined for all real numbers.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic sine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a64">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a519178f6b8e4ae40533c4d6030dee949" name="a519178f6b8e4ae40533c4d6030dee949"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a519178f6b8e4ae40533c4d6030dee949">&#9670;&#160;</a></span>Atan()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Atan </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arctangent (inverse tangent) of each element. </p>
<p>Returns a new tensor where each element is the arctangent of the corresponding element in the original tensor. The result is in radians in the range (-?/2, ?/2).</p>
<p>The arctangent function is defined for all real numbers.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arctangent values in radians, ranging from -?/2 to ?/2.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/?. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a54">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ae6ea5e2eb62073e68c546b03a7561acb" name="ae6ea5e2eb62073e68c546b03a7561acb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6ea5e2eb62073e68c546b03a7561acb">&#9670;&#160;</a></span>Atanh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Atanh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic tangent of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic tangent (also called area hyperbolic tangent) of the corresponding element in the original tensor. It is defined as: atanh(x) = 0.5  ln((1 + x) / (1 - x))</p>
<p>The inverse hyperbolic tangent is only defined for values in the open interval (-1, 1).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic tangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is ? -1 or ? 1 (where atanh is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a66">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a9d55201d57f76d5c94cf58eda3c35725" name="a9d55201d57f76d5c94cf58eda3c35725"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d55201d57f76d5c94cf58eda3c35725">&#9670;&#160;</a></span>AvgPool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::AvgPool </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>pool_shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span><span class="paramdefsep"> = </span><span class="paramdefval">{}</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs average pooling operation by computing the mean value within sliding windows. </p>
<p>Average pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the arithmetic mean (average) of all values in each region. It provides smoother downsampling compared to max pooling and is commonly used in convolutional neural networks for dimensionality reduction while preserving more global information.</p>
<p>The operation slides a window (defined by pool_shape) across the input tensor according to the specified strides, and at each position, computes the average of all values within that window to form the output.</p>
<p>The pool_shape can have a rank lower than or equal to the input tensor's rank. When the pool_shape rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>If strides is empty, it defaults to the broadcasted pool_shape, resulting in non-overlapping pooling windows (most common usage). Otherwise, strides must match the tensor's rank.</p>
<p>Mathematical formulation for each output element: </p><div class="fragment"><div class="line">output[i,j,...] = (1/N)  ? input[window elements]</div>
<div class="line">where N = number of elements in the pooling window</div>
</div><!-- fragment --><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pool_shape</td><td>A vector specifying the size of the pooling window for each dimension. Must have rank ? this tensor's rank. Each dimension of the pool must be ? the corresponding dimension of the input. All values must be positive (&gt; 0).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool_shape (non-overlapping windows). If provided, must have length equal to this tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the average-pooled result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] - pool_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The pool_shape is not compatible with the tensor (pool dimensions exceed input dimensions).</li>
<li>The strides vector is non-empty and its size does not match the tensor's rank.</li>
<li>Any stride value is non-positive (? 0).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Average pooling provides smoother gradients during backpropagation compared to max pooling, as all values in the window contribute to the output.</dd>
<dd>
The output represents the average intensity or activation level within each pooling region. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a24">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a26aebba00b9e12f161384198295678f0" name="a26aebba00b9e12f161384198295678f0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a26aebba00b9e12f161384198295678f0">&#9670;&#160;</a></span>Broadcast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Broadcast </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Broadcasts the tensor to a target shape following NumPy-style broadcasting rules. </p>
<p>This method expands the tensor's dimensions to match a target shape by replicating data along singleton dimensions (dimensions of size 1) and adding new leading dimensions as needed. Broadcasting allows operations between tensors of different but compatible shapes.</p>
<p>Broadcasting rules:</p><ul>
<li>Dimensions are aligned from the rightmost (trailing) dimension.</li>
<li>Two dimensions are compatible if they are equal or one of them is 1.</li>
<li>Missing leading dimensions are treated as size 1.</li>
</ul>
<p>For scalar tensors (rank 0), broadcasting simply fills the target shape with the scalar value.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>The target shape to broadcast to. Must contain only positive integers. The shape must be broadcast-compatible with the current tensor's shape.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the broadcasted shape and expanded data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The target shape is empty or contains non-positive values.</li>
<li>The tensor is empty (volume = 0).</li>
<li>The shapes are not broadcast-compatible.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a> with its own data buffer. The original tensor remains unchanged.</dd>
<dd>
For large target shapes, broadcasting can be memory-intensive as data is replicated. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a18">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a9636224ea3638818437a002240e36725" name="a9636224ea3638818437a002240e36725"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9636224ea3638818437a002240e36725">&#9670;&#160;</a></span>Ceil()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Ceil </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Rounds each element up to the nearest integer (ceiling function). </p>
<p>Returns a new tensor where each element is rounded up to the smallest integer greater than or equal to the original value. For example, 2.3 becomes 3, and -2.7 becomes -2.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing ceiled values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a38">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="aef30c23712785dd04bd9e02ba41dc78b" name="aef30c23712785dd04bd9e02ba41dc78b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef30c23712785dd04bd9e02ba41dc78b">&#9670;&#160;</a></span>Clip()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Clip </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>min_value</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>max_value</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clips (clamps) each element to be within a specified range. </p>
<p>Returns a new tensor where each element is constrained to lie within the range [min_value, max_value]. Values less than min_value are set to min_value, values greater than max_value are set to max_value, and values within the range remain unchanged.</p>
<p>This operation is useful for gradient clipping in neural networks, enforcing value bounds, and numerical stability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">min_value</td><td>The minimum allowed value. Must be finite and ? max_value. </td></tr>
    <tr><td class="paramname">max_value</td><td>The maximum allowed value. Must be finite and ? min_value.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing clipped values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>min_value is not finite (NaN or infinity).</li>
<li>max_value is not finite (NaN or infinity).</li>
<li>min_value &gt; max_value (invalid range).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
If min_value equals max_value, all output elements will be set to that value. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a40">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a8d2f2a27e468f2431a65cad597beec93" name="a8d2f2a27e468f2431a65cad597beec93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d2f2a27e468f2431a65cad597beec93">&#9670;&#160;</a></span>Convolve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Convolve </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>filter</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>padding</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs N-dimensional convolution between this tensor and a filter kernel. </p>
<p>This method computes the discrete convolution of the current tensor with a given filter kernel, supporting arbitrary dimensions, custom strides, and padding.</p>
<p>The operation applies the filter kernel across the input tensor using a sliding window approach. At each position, element-wise multiplication is performed between the kernel and the corresponding input region, followed by summation to produce a single output value.</p>
<p>The filter kernel can have a rank lower than or equal to the input tensor's rank. When the filter rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>Mathematical formulation for each output element: </p><div class="fragment"><div class="line">output[i,j,...] = ? input[i*stride + m, j*stride + n, ...]  kernel[m, n, ...]</div>
<div class="line">                  m,n,...</div>
</div><!-- fragment --><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">filter</td><td>The convolution kernel/filter tensor. Must have rank ? this tensor's rank. Each dimension of the filter must be ? the corresponding padded dimension of the input tensor (aligned from the rightmost dimension).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. Must have length equal to this tensor's rank. All values must be positive (&gt; 0). Larger strides reduce output size and computational cost. Example: {1, 1} for dense convolution, {2, 2} for downsampling.</td></tr>
    <tr><td class="paramname">padding</td><td>A vector specifying the number of zero-padding elements to add before and after each dimension. Must have length equal to this tensor's rank. All values must be non-negative (? 0). Padding controls output spatial dimensions and edge behavior. Example: {1, 1} adds one zero on each side of each dimension.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the convolution result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] + 2*padding[i] - filter_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The strides vector size does not match this tensor's rank.</li>
<li>The padding vector size does not match this tensor's rank.</li>
<li>Any stride value is non-positive (? 0).</li>
<li>Any padding value is negative (&lt; 0).</li>
<li>The filter shape is not compatible with the padded input shape (filter dimensions exceed corresponding padded input dimensions).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the padded tensor shape would cause integer overflow (total volume exceeds INT_MAX).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The convolution is computed in the spatial domain (direct method), not using FFT. For large kernels or tensors, this may be computationally expensive.</dd>
<dd>
This implements "valid" convolution semantics after padding is applied. For "same" convolution (output size = input size), set padding appropriately: <span class="tt">padding[i] = (filter_shape[i] - 1) / 2</span> for odd-sized filters with stride=1.</dd>
<dd>
The filter kernel is applied as-is without rotation. This is technically cross-correlation rather than true mathematical convolution, which is the standard convention in deep learning frameworks. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a21">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a50af8b385c36ce9ab4c707d96e131f30" name="a50af8b385c36ce9ab4c707d96e131f30"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50af8b385c36ce9ab4c707d96e131f30">&#9670;&#160;</a></span>Cos()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Cos </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the cosine of each element (in radians). </p>
<p>Returns a new tensor where each element is the cosine of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The cosine function maps any real number to the range [-1, 1] and is periodic with period 2?.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing cosine values in the range [-1, 1].</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a47">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a8eb0360a00945e98f06285a16a4d66ee" name="a8eb0360a00945e98f06285a16a4d66ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8eb0360a00945e98f06285a16a4d66ee">&#9670;&#160;</a></span>Cosh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Cosh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic cosine of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic cosine of the corresponding element in the original tensor. The hyperbolic cosine is defined as: cosh(x) = (e^x + e^(-x)) / 2</p>
<p>The hyperbolic cosine function is defined for all real numbers and is an even function.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic cosine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a59">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="af93c5440a098163158a3ef04a1286fe2" name="af93c5440a098163158a3ef04a1286fe2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af93c5440a098163158a3ef04a1286fe2">&#9670;&#160;</a></span>Cot()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Cot </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the cotangent (reciprocal of tangent) of each element (in radians). </p>
<p>Returns a new tensor where each element is the cotangent (1/tan(x) or cos(x)/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The cotangent function is undefined at multiples of ? (where sine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing cotangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately a multiple of ? (where cotangent is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a51">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a47239a452da7a9bcac96b60d87882669" name="a47239a452da7a9bcac96b60d87882669"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47239a452da7a9bcac96b60d87882669">&#9670;&#160;</a></span>Coth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Coth </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic cotangent (1/tanh(x) or cosh(x)/sinh(x)) of the corresponding element in the original tensor.</p>
<p>The hyperbolic cotangent is undefined at zero (where sinh equals zero).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic cotangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately zero (where hyperbolic cotangent is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a63">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ad69af858ebe61a0637ca0f8f4d05e4be" name="ad69af858ebe61a0637ca0f8f4d05e4be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad69af858ebe61a0637ca0f8f4d05e4be">&#9670;&#160;</a></span>Csc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Csc </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the cosecant (reciprocal of sine) of each element (in radians). </p>
<p>Returns a new tensor where each element is the cosecant (1/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The cosecant function is undefined at multiples of ? (where sine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing cosecant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately a multiple of ? (where cosecant is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a49">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a39e047e2b44d05b024fe15d884ac8df3" name="a39e047e2b44d05b024fe15d884ac8df3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a39e047e2b44d05b024fe15d884ac8df3">&#9670;&#160;</a></span>Csch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Csch </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic cosecant (1/sinh(x)) of the corresponding element in the original tensor.</p>
<p>The hyperbolic cosecant is undefined at zero (where sinh equals zero).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic cosecant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately zero (where hyperbolic cosecant is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a61">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ad2ec37ad613eebdab3c0bf8bba3e27ee" name="ad2ec37ad613eebdab3c0bf8bba3e27ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2ec37ad613eebdab3c0bf8bba3e27ee">&#9670;&#160;</a></span>Exp()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Exp </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes e raised to the power of each element (exponential function). </p>
<p>Returns a new tensor where each element is e^x, where e ? 2.71828 (Euler's number) and x is the corresponding element in the original tensor. This is the inverse operation of the natural logarithm.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing exponential values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The exponential function grows very rapidly. Large input values may result in overflow (infinity).</dd>
<dd>
Special values:<ul>
<li>exp(0) = 1</li>
<li>exp(1) = e ? 2.71828</li>
<li>exp(ln(x)) = x </li>
</ul>
</dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a44">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="aecd6af41dcc4e4a825408736216982a9" name="aecd6af41dcc4e4a825408736216982a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aecd6af41dcc4e4a825408736216982a9">&#9670;&#160;</a></span>ExpandRank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::ExpandRank </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Expands the rank of the <a class="el" href="class_tensor.html">Tensor</a> by inserting a dimension of size 1 at a specified axis. </p>
<p>This operation increases the <a class="el" href="class_tensor.html">Tensor</a>'s rank by 1 by inserting a new axis with dimension 1 at the specified position. The data remains unchanged; only the shape metadata is modified. This is analogous to NumPy's <span class="tt">np.expand_dims()</span> function.</p>
<p>The new dimension allows for operations such as broadcasting or stacking without modifying the underlying data. The axis parameter determines where the new dimension is inserted in the shape vector.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The position where the new dimension (of size 1) will be inserted. Must satisfy: <span class="tt">0 ? axis ? rank</span>.<ul>
<li><span class="tt">axis = 0</span>: Insert at the beginning (becomes the new outermost dimension).</li>
<li><span class="tt">axis = rank</span>: Append at the end (becomes the new innermost dimension). Default value is 0.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with rank increased by 1 and a dimension of size 1 at the specified axis.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or greater than the current rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a> via reshaping. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
The total volume (number of elements) remains the same. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a13">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a7037d4e167e55ad888dd1d9dac6b39eb" name="a7037d4e167e55ad888dd1d9dac6b39eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7037d4e167e55ad888dd1d9dac6b39eb">&#9670;&#160;</a></span>Flatten()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Flatten </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis_from</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis_upto</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Flattens a range of consecutive axes into a single dimension. </p>
<p>This operation collapses multiple consecutive dimensions between <span class="tt">axis_from</span> (inclusive) and <span class="tt">axis_upto</span> (exclusive) into a single flattened dimension. The axes before <span class="tt">axis_from</span> and after <span class="tt">axis_upto</span> remain unchanged. The resulting <a class="el" href="class_tensor.html">Tensor</a> has a reduced rank.</p>
<p>The flattened dimension's size is the product of all collapsed dimensions. The data order (row-major) remains unchanged; only the shape metadata is modified.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis_from</td><td>The starting axis index (inclusive) for flattening. Must satisfy: <span class="tt">0 ? axis_from &lt; axis_upto</span>.</td></tr>
    <tr><td class="paramname">axis_upto</td><td>The ending axis index (exclusive) for flattening. Must satisfy: <span class="tt">axis_from &lt; axis_upto ? rank</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with reduced rank where the specified axes are flattened.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the <a class="el" href="class_tensor.html">Tensor</a> is rank-0 (scalar) or rank-1 (already flat, cannot flatten further).</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li><span class="tt">axis_from</span> is negative.</li>
<li><span class="tt">axis_upto</span> is greater than the current rank.</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if <span class="tt">axis_from &gt;= axis_upto</span> (invalid range specification).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
The total volume (number of elements) remains constant. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a14">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a3fe9669c843cf233b390f01befe92280" name="a3fe9669c843cf233b390f01befe92280"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3fe9669c843cf233b390f01befe92280">&#9670;&#160;</a></span>Floor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Floor </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Rounds each element down to the nearest integer (floor function). </p>
<p>Returns a new tensor where each element is rounded down to the largest integer less than or equal to the original value. For example, 2.7 becomes 2, and -2.3 becomes -3.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing floored values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a37">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a847c00a1c549d33cebe3a4ef2f4d3b2f" name="a847c00a1c549d33cebe3a4ef2f4d3b2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a847c00a1c549d33cebe3a4ef2f4d3b2f">&#9670;&#160;</a></span>IsEmpty()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool TensorSlice::IsEmpty </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Checks whether the tensor contains no elements. </p>
<p>A tensor is considered empty if its volume (total number of elements) is zero. This can occur when any dimension in the shape is zero.</p>
<dl class="section return"><dt>Returns</dt><dd>true if the tensor has zero elements (volume = 0), false otherwise.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>An empty tensor is different from a scalar tensor.<ul>
<li>Empty: volume = 0, no data stored</li>
<li>Scalar: volume = 1, single value stored </li>
</ul>
</dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a73">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a25b03c23ebc8f53112bd2b5083d981b7" name="a25b03c23ebc8f53112bd2b5083d981b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25b03c23ebc8f53112bd2b5083d981b7">&#9670;&#160;</a></span>IsScalar()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool TensorSlice::IsScalar </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Checks whether the tensor represents a scalar (single) value. </p>
<p>A tensor is considered scalar if it has rank 0 (empty shape) and contains exactly one element. Scalar tensors represent single numerical values.</p>
<dl class="section return"><dt>Returns</dt><dd>true if the tensor is a scalar (rank 0 and volume 1), false otherwise.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>A scalar tensor has:<ul>
<li>Empty shape: shape = {}</li>
<li>Volume of 1: exactly one element</li>
<li>Rank of 0: zero dimensions </li>
</ul>
</dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a74">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a06db73fa0da2f9e770dcfe21cc14e828" name="a06db73fa0da2f9e770dcfe21cc14e828"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06db73fa0da2f9e770dcfe21cc14e828">&#9670;&#160;</a></span>Log()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Log </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>base</em></span><span class="paramdefsep"> = </span><span class="paramdefval">std::numbers::e</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the logarithm of each element with a specified base. </p>
<p>Returns a new tensor where each element is the logarithm (base-b) of the corresponding element in the original tensor. The operation computes log_b(x) for each element x.</p>
<p>Uses the change of base formula: log_b(x) = ln(x) / ln(b)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">base</td><td>The logarithm base. Must be positive (&gt; 0) and not equal to 1. Common values: e ? 2.71828 (natural log), 10 (common log), 2 (binary log). Default is e (natural logarithm).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing logarithm values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if:<ul>
<li>The base is zero, negative, or approximately zero.</li>
<li>The base is 1 (logarithm base 1 is undefined).</li>
<li>Any element is zero, negative, or approximately zero (log undefined for non-positive values).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Special values:<ul>
<li>log_b(1) = 0 for any valid base b</li>
<li>log_b(b) = 1</li>
<li>log_b(b^n) = n </li>
</ul>
</dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a43">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a30214f0ea0c3c3163bd05ca52c7dc95c" name="a30214f0ea0c3c3163bd05ca52c7dc95c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30214f0ea0c3c3163bd05ca52c7dc95c">&#9670;&#160;</a></span>MatMul()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::MatMul </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication with another tensor. </p>
<p>Convenience method that calls the static MatMul function. Equivalent to: Tensor::MatMul(*this, other)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The right operand tensor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the matrix multiplication result.</dd></dl>
<dl class="section see"><dt>See also</dt><dd>MatMul(const Tensor&amp;, const Tensor&amp;) </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a20">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a40baf8d6e10b1024e654af746e84a649" name="a40baf8d6e10b1024e654af746e84a649"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40baf8d6e10b1024e654af746e84a649">&#9670;&#160;</a></span>Max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double TensorSlice::Max </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Finds the maximum value in the tensor. </p>
<p>Returns the largest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The maximum element value.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a34">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a58d10d1fd229a260e8a9299a6b6208f3" name="a58d10d1fd229a260e8a9299a6b6208f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58d10d1fd229a260e8a9299a6b6208f3">&#9670;&#160;</a></span>MaxPool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::MaxPool </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>pool_shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span><span class="paramdefsep"> = </span><span class="paramdefval">{}</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs max pooling operation by taking the maximum value within sliding windows. </p>
<p>Max pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the maximum value in each region. It is commonly used in convolutional neural networks for spatial dimensionality reduction, feature extraction, and translation invariance.</p>
<p>The operation slides a window (defined by pool_shape) across the input tensor according to the specified strides, and at each position, selects the maximum value within that window to form the output.</p>
<p>The pool_shape can have a rank lower than or equal to the input tensor's rank. When the pool_shape rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>If strides is empty, it defaults to the broadcasted pool_shape, resulting in non-overlapping pooling windows (most common usage). Otherwise, strides must match the tensor's rank.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pool_shape</td><td>A vector specifying the size of the pooling window for each dimension. Must have rank ? this tensor's rank. Each dimension of the pool must be ? the corresponding dimension of the input. All values must be positive (&gt; 0).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool_shape (non-overlapping windows). If provided, must have length equal to this tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the max-pooled result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] - pool_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The pool_shape is not compatible with the tensor (pool dimensions exceed input dimensions).</li>
<li>The strides vector is non-empty and its size does not match the tensor's rank.</li>
<li>Any stride value is non-positive (? 0).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Max pooling provides translation invariance and is robust to small spatial shifts in the input features, making it popular in computer vision tasks.</dd>
<dd>
The output captures the most prominent features within each pooling region. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a22">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a1cc3aa9a38e6baba9ed12371986c45c2" name="a1cc3aa9a38e6baba9ed12371986c45c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cc3aa9a38e6baba9ed12371986c45c2">&#9670;&#160;</a></span>Mean()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double TensorSlice::Mean </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the mean (average) of all elements in the tensor. </p>
<p>Returns the arithmetic mean of all elements as a scalar value. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The mean of all elements.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Formula: Mean = Sum / Volume </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a32">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a0a7fb881f780412a2d39ca26089fb26e" name="a0a7fb881f780412a2d39ca26089fb26e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a7fb881f780412a2d39ca26089fb26e">&#9670;&#160;</a></span>Min()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double TensorSlice::Min </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Finds the minimum value in the tensor. </p>
<p>Returns the smallest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The minimum element value.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a35">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ac7587c1151e35617411a27b786bb420c" name="ac7587c1151e35617411a27b786bb420c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7587c1151e35617411a27b786bb420c">&#9670;&#160;</a></span>MinPool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::MinPool </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>pool_shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span><span class="paramdefsep"> = </span><span class="paramdefval">{}</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs min pooling operation by taking the minimum value within sliding windows. </p>
<p>Min pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the minimum value in each region. While less common than max pooling, it can be useful in specific applications where detecting the lowest activation or darkest features is important, such as certain image processing tasks or anomaly detection.</p>
<p>The operation slides a window (defined by pool_shape) across the input tensor according to the specified strides, and at each position, selects the minimum value within that window to form the output.</p>
<p>The pool_shape can have a rank lower than or equal to the input tensor's rank. When the pool_shape rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>If strides is empty, it defaults to the broadcasted pool_shape, resulting in non-overlapping pooling windows (most common usage). Otherwise, strides must match the tensor's rank.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pool_shape</td><td>A vector specifying the size of the pooling window for each dimension. Must have rank ? this tensor's rank. Each dimension of the pool must be ? the corresponding dimension of the input. All values must be positive (&gt; 0).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool_shape (non-overlapping windows). If provided, must have length equal to this tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the min-pooled result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] - pool_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The pool_shape is not compatible with the tensor (pool dimensions exceed input dimensions).</li>
<li>The strides vector is non-empty and its size does not match the tensor's rank.</li>
<li>Any stride value is non-positive (? 0).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Min pooling is sensitive to the smallest values in each region, making it useful for detecting low-intensity features or for applications requiring conservative feature selection.</dd>
<dd>
The output captures the least prominent (minimum) features within each pooling region. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a23">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a556db8ba686446c0412952d9405f42ba" name="a556db8ba686446c0412952d9405f42ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a556db8ba686446c0412952d9405f42ba">&#9670;&#160;</a></span>Mod()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Mod </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>mod_value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the modulus (remainder) of each element divided by a value. </p>
<p>Returns a new tensor where each element is the remainder of dividing the corresponding element by the specified modulus value. Uses the fmod function which computes the floating-point remainder of the division.</p>
<p>The result has the same sign as the dividend (the tensor element).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mod_value</td><td>The divisor for the modulus operation. Must be non-zero.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing modulus values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if mod_value is approximately zero (division by zero).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The result sign follows the dividend: fmod(-5, 3) = -2, fmod(5, -3) = 2 </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a45">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a55c5c65bc9c909bdad1c45e188c2e99b" name="a55c5c65bc9c909bdad1c45e188c2e99b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55c5c65bc9c909bdad1c45e188c2e99b">&#9670;&#160;</a></span>operator Tensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">TensorSlice::operator <a class="el" href="class_tensor.html">Tensor</a> </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implicit conversion to <a class="el" href="class_tensor.html">Tensor</a> (creates an independent copy). </p>
<p>This conversion operator is called when a <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> is assigned to a <a class="el" href="class_tensor.html">Tensor</a> variable or passed to a function expecting a <a class="el" href="class_tensor.html">Tensor</a>. It creates a deep copy of the sliced data.</p>
<dl class="section return"><dt>Returns</dt><dd>A new independent <a class="el" href="class_tensor.html">Tensor</a> containing the sliced data. </dd></dl>

</div>
</div>
<a id="abd2662558437bf0032085e5a483520d3" name="abd2662558437bf0032085e5a483520d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd2662558437bf0032085e5a483520d3">&#9670;&#160;</a></span>operator*() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator* </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise multiplication of two tensors (Hadamard product). </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the product of corresponding elements from both tensors. If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<p>This is element-wise multiplication (Hadamard product), NOT matrix multiplication.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to multiply with. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise products with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd>
<dd>
This is NOT matrix multiplication. For matrix multiplication, use a separate MatMul method. </dd></dl>

</div>
</div>
<a id="af184ad77fc278974efbbcfce8be97e20" name="af184ad77fc278974efbbcfce8be97e20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af184ad77fc278974efbbcfce8be97e20">&#9670;&#160;</a></span>operator*() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator* </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise multiplication of all tensor elements by a scalar value. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the product of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise products.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a6">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a79372cfb766492f6d4a0beb236eca244" name="a79372cfb766492f6d4a0beb236eca244"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79372cfb766492f6d4a0beb236eca244">&#9670;&#160;</a></span>operator*=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator*= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise multiplication with another tensor (Hadamard product). </p>
<p>Multiplies this tensor with the given tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>This is element-wise multiplication (Hadamard product), NOT matrix multiplication.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to multiply with. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
This is NOT matrix multiplication. For matrix multiplication, use a separate MatMul method. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A * B;</span> </dd></dl>

</div>
</div>
<a id="a6fb8999e863da0cd422494ea8936e3bb" name="a6fb8999e863da0cd422494ea8936e3bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6fb8999e863da0cd422494ea8936e3bb">&#9670;&#160;</a></span>operator*=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator*= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise multiplication by a scalar value. </p>
<p>Multiplies all elements of this tensor by the scalar value in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A * value;</span> </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a10">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a5cbf99706365813b2d14ddf63a9b9624" name="a5cbf99706365813b2d14ddf63a9b9624"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5cbf99706365813b2d14ddf63a9b9624">&#9670;&#160;</a></span>operator+() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator+ </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise addition of two tensors. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the sum of corresponding elements from both tensors. If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<p>Broadcasting allows operations between tensors of different but compatible shapes by automatically expanding dimensions where needed.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to add. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise sums with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd></dl>

</div>
</div>
<a id="a891cda49b0e34178a9abeab88481066f" name="a891cda49b0e34178a9abeab88481066f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a891cda49b0e34178a9abeab88481066f">&#9670;&#160;</a></span>operator+() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator+ </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise addition of a scalar value to all tensor elements. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the sum of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to add to each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise sums.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a4">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="af81661b65d4ef9a66109c5e2354e0621" name="af81661b65d4ef9a66109c5e2354e0621"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af81661b65d4ef9a66109c5e2354e0621">&#9670;&#160;</a></span>operator+=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator+= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise addition with another tensor. </p>
<p>Adds the given tensor to this tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to add. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A + B;</span> </dd></dl>

</div>
</div>
<a id="a0a6c7af8296371c02d00f53b6aa3400a" name="a0a6c7af8296371c02d00f53b6aa3400a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a6c7af8296371c02d00f53b6aa3400a">&#9670;&#160;</a></span>operator+=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator+= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise addition of a scalar value. </p>
<p>Adds the scalar value to all elements of this tensor in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to add to each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A + value;</span> </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a8">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ab31a85076571882207207be11c70cd34" name="ab31a85076571882207207be11c70cd34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab31a85076571882207207be11c70cd34">&#9670;&#160;</a></span>operator-() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator- </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise subtraction of two tensors. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the difference between corresponding elements from both tensors (this - tensor). If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to subtract. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise differences with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd>
<dd>
Order matters: A - B ? B - A </dd></dl>

</div>
</div>
<a id="a30c1e8fe8a68609fda529a1ad6602724" name="a30c1e8fe8a68609fda529a1ad6602724"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30c1e8fe8a68609fda529a1ad6602724">&#9670;&#160;</a></span>operator-() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator- </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise subtraction of a scalar value from all tensor elements. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the difference between the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise differences.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a5">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ad456ffc088943ad62eea57a8c80f05d7" name="ad456ffc088943ad62eea57a8c80f05d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad456ffc088943ad62eea57a8c80f05d7">&#9670;&#160;</a></span>operator-=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator-= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise subtraction with another tensor. </p>
<p>Subtracts the given tensor from this tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to subtract. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A - B;</span> </dd></dl>

</div>
</div>
<a id="a953cf784473905860747b49166078421" name="a953cf784473905860747b49166078421"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a953cf784473905860747b49166078421">&#9670;&#160;</a></span>operator-=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator-= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise subtraction of a scalar value. </p>
<p>Subtracts the scalar value from all elements of this tensor in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A - value;</span> </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a9">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a67aee1af10009acf23649fdae6e3dc49" name="a67aee1af10009acf23649fdae6e3dc49"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67aee1af10009acf23649fdae6e3dc49">&#9670;&#160;</a></span>operator/() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator/ </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise division of two tensors. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the quotient of corresponding elements from both tensors (this / tensor). If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<p>Division by elements close to zero (|value| &lt; epsilon * EPSILON_SCALE) is detected and throws an exception to prevent numerical instability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The divisor tensor. Must be non-empty, broadcast-compatible, and contain no near-zero values.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise quotients with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element in the divisor tensor is close to zero (|value| &lt; epsilon * EPSILON_SCALE).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd>
<dd>
Order matters: A / B ? B / A </dd>
<dd>
Division-by-zero check is performed for each element individually during iteration. </dd></dl>

</div>
</div>
<a id="add3ca72dfa58d4f0d443da639fdb576b" name="add3ca72dfa58d4f0d443da639fdb576b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add3ca72dfa58d4f0d443da639fdb576b">&#9670;&#160;</a></span>operator/() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::operator/ </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise division of all tensor elements by a scalar value. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the quotient of the corresponding element in this tensor divided by the scalar value. The operation is broadcast across all elements.</p>
<p>Division by values very close to zero (|value| &lt; 1e-9) is treated as division by zero to prevent numerical instability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise quotients.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity. </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if the absolute value of the divisor is less than epsilon  EPSILON_SCALE (division by ~zero).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The threshold 1e-9 is used to detect near-zero values and prevent numerical errors. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a7">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a1763727eccb717b5359293923576bf43" name="a1763727eccb717b5359293923576bf43"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1763727eccb717b5359293923576bf43">&#9670;&#160;</a></span>operator/=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator/= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise division by another tensor. </p>
<p>Divides this tensor by the given tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>Division by elements close to zero (|value| &lt; epsilon  EPSILON_SCALE) is detected and throws an exception to prevent numerical instability.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The divisor tensor. Must be non-empty, broadcast-compatible, and contain no near-zero values.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element in the divisor tensor is close to zero (|value| &lt; epsilon  EPSILON_SCALE).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
Division-by-zero check is performed for each element individually during iteration. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A / B;</span> </dd></dl>

</div>
</div>
<a id="ac0cfe800f5166e780913c459085c5240" name="ac0cfe800f5166e780913c459085c5240"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0cfe800f5166e780913c459085c5240">&#9670;&#160;</a></span>operator/=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator/= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise division by a scalar value. </p>
<p>Divides all elements of this tensor by the scalar value in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<p>Division by values very close to zero (|value| &lt; epsilon  EPSILON_SCALE) is treated as division by zero to prevent numerical instability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity. </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if the absolute value of the divisor is less than epsilon  EPSILON_SCALE (division by ~zero).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A / value;</span> </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a11">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a725be809a7e2f9903fe1aa7bbfc7d425" name="a725be809a7e2f9903fe1aa7bbfc7d425"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a725be809a7e2f9903fe1aa7bbfc7d425">&#9670;&#160;</a></span>operator=()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> &amp; TensorSlice::operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Assignment operator that modifies the root parent tensor. </p>
<p>Assigns the given tensor's data to the slice location in the original tensor. This modifies the root tensor through the index chain.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The <a class="el" href="class_tensor.html">Tensor</a> whose data will be copied into the slice. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Reference to this <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> for chaining. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a2">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a36b4453303b38372b6b48b83bead2e45" name="a36b4453303b38372b6b48b83bead2e45"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a36b4453303b38372b6b48b83bead2e45">&#9670;&#160;</a></span>operator[]()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> TensorSlice::operator[] </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>idx</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Non-const indexing for continued chaining with modification capability. </p>
<p>Extends the index chain by one level, allowing nested indexing operations. Used when the slice may be modified.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">idx</td><td>The next index in the chain. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> with the extended index chain. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a3">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a44621cdd09df688b2c5cb4bd000d8f73" name="a44621cdd09df688b2c5cb4bd000d8f73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44621cdd09df688b2c5cb4bd000d8f73">&#9670;&#160;</a></span>Pad()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Pad </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>pad_before</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>pad_after</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.0</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Adds padding elements before and/or after the tensor along a specified axis. </p>
<p>This method creates a new <a class="el" href="class_tensor.html">Tensor</a> with additional elements (padding) inserted before and after the original data along the specified axis. The padding elements are filled with a constant value (default is 0.0).</p>
<p>The resulting tensor has the same rank but an increased dimension along the padded axis: <span class="tt">new_shape[axis] = original_shape[axis] + pad_before_size + pad_after_size</span>.</p>
<p>This operation is commonly used in convolutional neural networks, signal processing, and boundary handling in various algorithms.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to add padding. Must satisfy: <span class="tt">0 ? axis &lt; rank</span>.</td></tr>
    <tr><td class="paramname">pad_before_size</td><td>The number of padding elements to add before the data along the axis. Must be non-negative (? 0).</td></tr>
    <tr><td class="paramname">pad_after_size</td><td>The number of padding elements to add after the data along the axis. Must be non-negative (? 0).</td></tr>
    <tr><td class="paramname">value</td><td>The constant value to fill the padding elements with. Default is 0.0. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with padding added along the specified axis.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if pad_before_size or pad_after_size is negative.</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the resulting shape volume exceeds INT_MAX.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
If both pad_before_size and pad_after_size are 0, the returned tensor is a copy of the original.</dd>
<dd>
Internally, this method uses Concat to join padding tensors with the original data. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a16">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ab3b88de18822c6f21b4f846fc2a08651" name="ab3b88de18822c6f21b4f846fc2a08651"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3b88de18822c6f21b4f846fc2a08651">&#9670;&#160;</a></span>Power()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Power </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>exponent</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Raises each element to a specified power (exponentiation).    </p>
<p>Returns a new tensor where each element is raised to the given exponent. The operation computes x^exponent for each element x.</p>
<p>For negative bases with non-integer exponents, the result would be a complex number, so an exception is thrown to maintain real number semantics.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">exponent</td><td>The power to raise each element to. Can be any real number.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing the results of exponentiation.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is negative and the exponent is non-integer (would result in a complex number).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Special cases:<ul>
<li>x^0 = 1 for any x (including 0)</li>
<li>x^1 = x</li>
<li>0^n = 0 for positive n    </li>
</ul>
</dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a41">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ac4fca8605058c8dd92bc8bbb1eba2969" name="ac4fca8605058c8dd92bc8bbb1eba2969"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac4fca8605058c8dd92bc8bbb1eba2969">&#9670;&#160;</a></span>Print()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void TensorSlice::Print </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>depth</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Prints the tensor contents to standard output in a readable, nested format. </p>
<p>This method displays the tensor's structure and values in a NumPy-like format with appropriate indentation for multi-dimensional tensors. It recursively prints nested structures, making it easy to visualize the tensor's shape and data.</p>
<p>Special cases:</p><ul>
<li>Empty tensors are printed as <span class="tt">[]</span></li>
<li>Scalar tensors print the single value directly</li>
<li>Multi-dimensional tensors use nested brackets with indentation</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">depth</td><td>Internal indentation level used during recursive printing. This parameter is automatically managed and should not be modified by users. Default is 0 (no indentation).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This method is primarily intended for debugging and inspection. For programmatic string representation, consider implementing a ToString() method.</dd>
<dd>
The output format includes:<ul>
<li>Newlines and indentation for readability in multi-dimensional tensors</li>
<li>Commas between elements</li>
<li>Nested brackets representing each dimension</li>
</ul>
</dd>
<dd>
This method uses the const indexing operator <span class="tt">[]</span> internally, which triggers the conversion from <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> to <a class="el" href="class_tensor.html">Tensor</a>, creating temporary copies during recursion. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a75">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a5d66ce8c7e459c2c6e9d2f2cc0c16ee3" name="a5d66ce8c7e459c2c6e9d2f2cc0c16ee3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d66ce8c7e459c2c6e9d2f2cc0c16ee3">&#9670;&#160;</a></span>Rank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int TensorSlice::Rank </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the rank (number of dimensions) of the tensor. </p>
<p>The rank represents the number of axes or dimensions in the tensor. For example, a scalar has rank 0, a vector has rank 1, a matrix has rank 2, etc.</p>
<dl class="section return"><dt>Returns</dt><dd>The rank of the tensor as an integer.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>A scalar tensor (single value) has rank 0. </dd>
<dd>
An empty tensor also reports its rank correctly based on its shape. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a70">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a581bc889132baeaafc6974c523c80189" name="a581bc889132baeaafc6974c523c80189"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a581bc889132baeaafc6974c523c80189">&#9670;&#160;</a></span>ReduceMax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::ReduceMax </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the maximum. </p>
<p>Finds the maximum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to find the maximum. Must satisfy: 0 ? axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing maximum values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a29">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a0bc4030adf64e861696d2033f6fc08bb" name="a0bc4030adf64e861696d2033f6fc08bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0bc4030adf64e861696d2033f6fc08bb">&#9670;&#160;</a></span>ReduceMean()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::ReduceMean </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the mean (average). </p>
<p>Computes the arithmetic mean of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to compute the mean. Must satisfy: 0 ? axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing means.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd>
<dd>
Implemented as ReduceSum(axis) / size. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a27">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a0bd288decf47bfad24af8d46a70f2952" name="a0bd288decf47bfad24af8d46a70f2952"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0bd288decf47bfad24af8d46a70f2952">&#9670;&#160;</a></span>ReduceMin()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::ReduceMin </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the minimum. </p>
<p>Finds the minimum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to find the minimum. Must satisfy: 0 ? axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing minimum values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a30">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="afe2ed01b32773724e684e9fe6090f531" name="afe2ed01b32773724e684e9fe6090f531"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe2ed01b32773724e684e9fe6090f531">&#9670;&#160;</a></span>ReduceSum()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::ReduceSum </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the sum. </p>
<p>Computes the sum of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to compute the sum. Must satisfy: 0 ? axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing sums.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a26">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a0898917704e36edbd2b99779010f945e" name="a0898917704e36edbd2b99779010f945e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0898917704e36edbd2b99779010f945e">&#9670;&#160;</a></span>ReduceVar()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::ReduceVar </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>inference</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the variance. </p>
<p>Computes the variance of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<p>Variance measures how spread out the values are from their mean.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to compute the variance. Must satisfy: 0 ? axis &lt; rank. Default is 0. </td></tr>
    <tr><td class="paramname">inference</td><td>If true, uses Bessel's correction (divides by n-1 for sample variance). If false, divides by n (population variance). Default is false.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing variances.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd>
<dd>
Formula: Var = sum((x - mean)) / n (or n-1 if inference=true) </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a28">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a324cf2ea9cc02476c25de1d4069468b0" name="a324cf2ea9cc02476c25de1d4069468b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a324cf2ea9cc02476c25de1d4069468b0">&#9670;&#160;</a></span>Reshape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Reshape </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>new_shape</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reshapes the <a class="el" href="class_tensor.html">Tensor</a> to a new specified shape without changing data order. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> with the given shape, containing the same data elements in the same row-major order. The total number of elements (volume) must remain constant. This operation does not reorder or modify the data; it only changes how the flat data is interpreted dimensionally.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_shape</td><td>A vector of positive integers representing the desired dimensions. All dimensions must be greater than 0. The product of all dimensions must equal the current volume.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified shape and the same data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The new_shape contains any non-positive dimensions (i.e., any dimension ? 0).</li>
<li>The volume implied by new_shape does not match the current <a class="el" href="class_tensor.html">Tensor</a>'s volume.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
Only the shape metadata changes; data is copied but not reordered. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a12">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ab07074813ba5a5f62a9246fe99d1430c" name="ab07074813ba5a5f62a9246fe99d1430c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab07074813ba5a5f62a9246fe99d1430c">&#9670;&#160;</a></span>Round()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Round </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>decimal_place</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Rounds each element to a specified number of decimal places. </p>
<p>Returns a new tensor where each element is rounded to the nearest value with the specified number of decimal places. Uses standard rounding rules (round half to even / banker's rounding).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">decimal_place</td><td>The number of decimal places to round to. Must be non-negative (? 0). Default is 0 (round to nearest integer).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing rounded values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if decimal_place is negative (&lt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a39">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a0e1f2f379dd0ff1dcdffe924f7f1360c" name="a0e1f2f379dd0ff1dcdffe924f7f1360c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e1f2f379dd0ff1dcdffe924f7f1360c">&#9670;&#160;</a></span>Sec()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Sec </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the secant (reciprocal of cosine) of each element (in radians). </p>
<p>Returns a new tensor where each element is the secant (1/cos(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The secant function is undefined at odd multiples of ?/2 (where cosine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing secant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately an odd multiple of ?/2 (where secant is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a50">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a44053a3ce4683ba4e4000b59555cf361" name="a44053a3ce4683ba4e4000b59555cf361"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44053a3ce4683ba4e4000b59555cf361">&#9670;&#160;</a></span>Sech()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Sech </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic secant (1/cosh(x)) of the corresponding element in the original tensor.</p>
<p>The hyperbolic secant is always positive and has range (0, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic secant values in the range (0, 1].</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if numerical instability is detected (extremely rare).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a62">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="af773875332be2e70344d4a17429166ba" name="af773875332be2e70344d4a17429166ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af773875332be2e70344d4a17429166ba">&#9670;&#160;</a></span>Shape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; int &gt; TensorSlice::Shape </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the shape of the tensor as a vector of dimension sizes. </p>
<p>The shape describes the size of each dimension in the tensor. For example, shape {2, 3, 4} represents a 3D tensor with 2 slices, each containing a 34 matrix.</p>
<dl class="section return"><dt>Returns</dt><dd>A vector of integers representing the size of each dimension.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>For a scalar tensor (rank 0), this returns an empty vector. </dd>
<dd>
The returned vector is a copy; modifying it does not affect the tensor. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a72">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ada3970a1f99f8e389c6272d0e8f54944" name="ada3970a1f99f8e389c6272d0e8f54944"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ada3970a1f99f8e389c6272d0e8f54944">&#9670;&#160;</a></span>Sign()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Sign </td>
          <td>(</td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>heaviside</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the sign function element-wise. </p>
<p>Returns a new tensor where each element is:</p><ul>
<li>1.0 if the original element is positive</li>
<li>-1.0 if the original element is negative</li>
<li>0.0 if the original element is approximately zero (|x| &lt; epsilon  EPSILON_SCALE)</li>
</ul>
<p>If the Heaviside step function mode is enabled, zero values are mapped to 1.0 instead of 0.0.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">heaviside</td><td>If true, uses Heaviside step function (maps 0 ? 1). If false, uses standard sign function (maps 0 ? 0). Default is false.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing sign values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a25">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a13d0676062409a9e032ca58e0bf2d8ff" name="a13d0676062409a9e032ca58e0bf2d8ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13d0676062409a9e032ca58e0bf2d8ff">&#9670;&#160;</a></span>Sin()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Sin </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the sine of each element (in radians). </p>
<p>Returns a new tensor where each element is the sine of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The sine function maps any real number to the range [-1, 1] and is periodic with period 2?.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing sine values in the range [-1, 1].</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a46">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="af9a20344356eae9d28baf7aab314b80b" name="af9a20344356eae9d28baf7aab314b80b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9a20344356eae9d28baf7aab314b80b">&#9670;&#160;</a></span>Sinh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Sinh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic sine of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic sine of the corresponding element in the original tensor. The hyperbolic sine is defined as: sinh(x) = (e^x - e^(-x)) / 2</p>
<p>The hyperbolic sine function is defined for all real numbers and is an odd function.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic sine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a58">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="adebcfb3b75b9a42ddfac2766c6ea0acc" name="adebcfb3b75b9a42ddfac2766c6ea0acc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adebcfb3b75b9a42ddfac2766c6ea0acc">&#9670;&#160;</a></span>Slice() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Slice </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extracts a slice of the <a class="el" href="class_tensor.html">Tensor</a> along a specified axis at a given index. </p>
<p>This method returns a new <a class="el" href="class_tensor.html">Tensor</a> representing a lower-rank slice of the current <a class="el" href="class_tensor.html">Tensor</a>, taken along the specified axis at a particular index position. The operation performs a deep copy of the relevant data region, so the resulting <a class="el" href="class_tensor.html">Tensor</a> is completely independent of the original.</p>
<p>The rank of the returned <a class="el" href="class_tensor.html">Tensor</a> is <span class="tt">rank - 1</span>, as the specified axis is removed. For example, slicing a (2, 3, 4) tensor along axis 1 at index 0 produces a (2, 4) tensor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to slice. Must satisfy: <span class="tt">0 ? axis &lt; rank</span>. </td></tr>
    <tr><td class="paramname">index</td><td>The index position along the given axis to extract. Must satisfy: <span class="tt">0 ? index &lt; shape[axis]</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> slice with one fewer dimension (rank reduced by 1).</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if:<ul>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is empty (volume = 0).</li>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is a scalar (rank = 0).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li>The axis is negative or &gt;= rank.</li>
<li>The index is negative or &gt;= shape[axis].</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a copy-based operation. The returned <a class="el" href="class_tensor.html">Tensor</a> has its own independent data buffer and does not share memory with the original.</dd>
<dd>
This operation efficiently extracts non-contiguous data using stride information. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a15">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ab26b29a1be6c026364c9210307dcffde" name="ab26b29a1be6c026364c9210307dcffde"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab26b29a1be6c026364c9210307dcffde">&#9670;&#160;</a></span>Slice() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Slice </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index_from</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index_upto</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extracts a range of slices from the <a class="el" href="class_tensor.html">Tensor</a> along a given axis. </p>
<p>This method performs slicing between two indices (<span class="tt">index_from</span> inclusive and <span class="tt">index_upto</span> exclusive) along the specified axis. Each individual slice is extracted using the single-index <span class="tt"><a class="el" href="#adebcfb3b75b9a42ddfac2766c6ea0acc" title="Extracts a slice of the Tensor along a specified axis at a given index.">Slice()</a></span> method, and the results are stacked together along the same axis to form a contiguous sub-tensor.</p>
<p>The rank of the returned <a class="el" href="class_tensor.html">Tensor</a> remains the same as the original. The dimension along the specified axis is reduced to <span class="tt">index_upto - index_from</span>.</p>
<p>Like single-index slicing, this is a <b>copy-based</b> operation resulting in an independent <a class="el" href="class_tensor.html">Tensor</a> with no shared data.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to slice. Must satisfy: <span class="tt">0 ? axis &lt; rank</span>.</td></tr>
    <tr><td class="paramname">index_from</td><td>The starting index (inclusive) along the axis. Must satisfy: <span class="tt">0 ? index_from &lt; index_upto</span>.</td></tr>
    <tr><td class="paramname">index_upto</td><td>The ending index (exclusive) along the axis. Must satisfy: <span class="tt">index_from &lt; index_upto ? shape[axis]</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> formed by stacking the specified slices along the same axis.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if:<ul>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is empty (volume = 0).</li>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is a scalar (rank = 0).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li>The axis is negative or &gt;= rank.</li>
<li><span class="tt">index_from</span> is negative or <span class="tt">index_upto</span> is &gt; shape[axis].</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if <span class="tt">index_from &gt;= index_upto</span> (invalid range specification).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a copy-based operation. The returned <a class="el" href="class_tensor.html">Tensor</a> has its own independent data buffer.</dd>
<dd>
Internally, this method calls <span class="tt">Slice(axis, index)</span> for each index in the range and uses <span class="tt">Stack()</span> to combine them. </dd></dl>

</div>
</div>
<a id="a7709875a1c35f01cb88f26bd1ea3cfe1" name="a7709875a1c35f01cb88f26bd1ea3cfe1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7709875a1c35f01cb88f26bd1ea3cfe1">&#9670;&#160;</a></span>Sqrt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Sqrt </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the square root of each element. </p>
<p>Returns a new tensor where each element is the square root of the corresponding element in the original tensor. This is equivalent to raising each element to the power of 0.5.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing square root values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is negative (square root undefined for negative reals).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
For negative values, consider using <a class="el" href="#a4eb8d65d3052ebac6c39c04326830b4b" title="Computes the absolute value of each element.">Abs()</a> first if magnitude is desired. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a42">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a5402ef990f310a0e47a776acc2020656" name="a5402ef990f310a0e47a776acc2020656"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5402ef990f310a0e47a776acc2020656">&#9670;&#160;</a></span>Sum()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double TensorSlice::Sum </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the sum of all elements in the tensor. </p>
<p>Returns the sum of all elements as a scalar value. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The sum of all elements.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a31">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="af56814ea935d8ee7c8945f21d452025d" name="af56814ea935d8ee7c8945f21d452025d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af56814ea935d8ee7c8945f21d452025d">&#9670;&#160;</a></span>Tan()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Tan </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the tangent of each element (in radians). </p>
<p>Returns a new tensor where each element is the tangent of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The tangent function is undefined at odd multiples of ?/2 (where cosine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing tangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately an odd multiple of ?/2 (where tangent is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by ?/180. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a48">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a3298ee780337e0d515fe3b07e090a4bd" name="a3298ee780337e0d515fe3b07e090a4bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3298ee780337e0d515fe3b07e090a4bd">&#9670;&#160;</a></span>Tanh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Tanh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic tangent of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic tangent of the corresponding element in the original tensor. The hyperbolic tangent is defined as: tanh(x) = sinh(x) / cosh(x) = (e^x - e^(-x)) / (e^x + e^(-x))</p>
<p>The hyperbolic tangent function is defined for all real numbers, is an odd function, and has range (-1, 1).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic tangent values in the range (-1, 1).</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a60">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ad0e4432eeecf83eb8f93d026cea106f3" name="ad0e4432eeecf83eb8f93d026cea106f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0e4432eeecf83eb8f93d026cea106f3">&#9670;&#160;</a></span>Tile()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Tile </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>repetitions</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Repeats the entire tensor structure along each axis a specified number of times. </p>
<p>This method creates a new <a class="el" href="class_tensor.html">Tensor</a> by replicating the current tensor along each dimension. The repetitions vector specifies how many times to tile along each axis. The resulting tensor has shape <span class="tt">new_shape[i] = original_shape[i] * repetitions[i]</span> for each axis i.</p>
<p>Unlike element-wise repetition, tiling repeats the entire structure as a block. For example, tiling [1,2,3] twice results in [1,2,3,1,2,3], not [1,1,2,2,3,3].</p>
<p>The operation proceeds from the innermost dimension (last axis) to the outermost (first axis), using concatenation to build up the tiled result incrementally.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">repetitions</td><td>A vector specifying the number of repetitions along each axis. Must have the same length as the tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the tiled structure.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The repetitions vector size does not match the tensor's rank.</li>
<li>Any repetition value is non-positive (? 0).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if:<ul>
<li>The product of repetitions exceeds INT_MAX.</li>
<li>The resulting total volume exceeds INT_MAX.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
The total volume of the result is <span class="tt">original_volume  product(repetitions)</span>.</dd>
<dd>
For large tensors and many repetitions, this operation can be memory-intensive. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a17">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ac0b56c26e6b0638e8be8512df974f2b9" name="ac0b56c26e6b0638e8be8512df974f2b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0b56c26e6b0638e8be8512df974f2b9">&#9670;&#160;</a></span>ToMatrix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::vector&lt; double &gt; &gt; TensorSlice::ToMatrix </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Converts a rank-2 tensor to a 2D vector (matrix). </p>
<p>Extracts all elements from a rank-2 tensor and returns them as a nested std::vector&lt;std::vector&lt;double&gt;&gt;. This is useful for interfacing with standard C++ code that expects 2D arrays or matrices.</p>
<p>The outer vector represents rows, and each inner vector represents the columns of that row.</p>
<dl class="section return"><dt>Returns</dt><dd>A 2D vector containing all tensor elements organized by rows and columns.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is not rank-2 (not a matrix).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This creates a copy of the data. The original tensor is unchanged. </dd>
<dd>
Works correctly with sliced tensors (uses start and stride information). </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a78">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="aacca4d01deff58b2cb00aa0e0de4d3f8" name="aacca4d01deff58b2cb00aa0e0de4d3f8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aacca4d01deff58b2cb00aa0e0de4d3f8">&#9670;&#160;</a></span>ToScalar()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double TensorSlice::ToScalar </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Converts a scalar tensor to a double value. </p>
<p>Extracts and returns the single value from a rank-0 (scalar) tensor. This method only works on tensors with rank 0 and volume 1.</p>
<dl class="section return"><dt>Returns</dt><dd>The scalar value as a double.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is not a scalar (rank &gt; 0 or volume != 1).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a convenience method for extracting scalar values from scalar tensors. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a76">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="a6072465ba590c092c398bded85469fd4" name="a6072465ba590c092c398bded85469fd4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6072465ba590c092c398bded85469fd4">&#9670;&#160;</a></span>ToVector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; double &gt; TensorSlice::ToVector </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Converts a rank-1 tensor to a standard vector. </p>
<p>Extracts all elements from a rank-1 tensor and returns them as a std::vector&lt;double&gt;. This is useful for interfacing with standard C++ code that expects vectors.</p>
<dl class="section return"><dt>Returns</dt><dd>A std::vector&lt;double&gt; containing all tensor elements in order.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is not rank-1 (not a vector).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This creates a copy of the data. The original tensor is unchanged. </dd>
<dd>
Works correctly with sliced tensors (uses start and end indices). </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a77">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ae1ce3b94498a11ea3f83a2c98d0f523f" name="ae1ce3b94498a11ea3f83a2c98d0f523f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1ce3b94498a11ea3f83a2c98d0f523f">&#9670;&#160;</a></span>Transpose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> TensorSlice::Transpose </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>permutation</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Transposes (permutes) the tensor's axes according to a specified permutation. </p>
<p>This method rearranges the tensor's dimensions by permuting its axes according to the provided permutation vector. Each element in the permutation specifies which original axis should be placed at that position in the result.</p>
<p>For example, permutation {1, 0, 2} swaps the first two axes while keeping the third axis unchanged. This is a generalization of matrix transpose to arbitrary dimensions.</p>
<p>The operation creates a new tensor with reordered dimensions and rearranged data to match the new axis order.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">permutation</td><td>A vector specifying the new order of axes. Must have length equal to the tensor's rank. Must be a valid permutation: contain each value from 0 to (rank-1) exactly once.<ul>
<li>permutation[i] = j means the j-th axis of the original tensor becomes the i-th axis of the result.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with permuted axes and reordered data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The permutation size does not match the tensor's rank.</li>
<li>The permutation contains negative values.</li>
<li>The permutation contains values &gt;= rank.</li>
<li>The permutation contains duplicate values (not a valid permutation).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The data is physically reordered to match the new axis layout, making subsequent access efficient. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a19">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="ade9abd7f940b3f1d50b16854f241abc3" name="ade9abd7f940b3f1d50b16854f241abc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade9abd7f940b3f1d50b16854f241abc3">&#9670;&#160;</a></span>Var()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double TensorSlice::Var </td>
          <td>(</td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>inference</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the variance of all elements in the tensor. </p>
<p>Returns the variance of all elements as a scalar value. Variance measures how spread out the values are from their mean. This is a global reduction operation across the entire tensor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inference</td><td>If true, uses Bessel's correction (divides by n-1 for sample variance). If false, divides by n (population variance). Default is false.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The variance of all elements.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Formula: Var = sum((x - mean)) / n (or n-1 if inference=true) </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a33">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<a id="acfa02303d766c0d2399fe34a1943238d" name="acfa02303d766c0d2399fe34a1943238d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acfa02303d766c0d2399fe34a1943238d">&#9670;&#160;</a></span>Volume()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int TensorSlice::Volume </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the total number of elements (volume) in the tensor. </p>
<p>The volume is the product of all dimensions in the tensor's shape. It represents the total count of scalar values stored in the tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The total number of elements as an integer.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>For an empty tensor and scalar tensor, this returns 0. </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#a71">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li><a class="el" href="_tensor_slice_8h_source.html">TensorSlice.h</a></li>
<li><b>TensorSlice.cpp</b></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="class_tensor_slice.html">TensorSlice</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
