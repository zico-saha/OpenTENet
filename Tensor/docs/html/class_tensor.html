<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: Tensor Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('class_tensor.html','','class_tensor-members'); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">Tensor Class Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-pub-methods" class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aec22e6d528af637133d7d17f1d7f8ad5" id="r_aec22e6d528af637133d7d17f1d7f8ad5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aec22e6d528af637133d7d17f1d7f8ad5">Tensor</a> (const std::vector&lt; int &gt; &amp;shape, double value=0)</td></tr>
<tr class="memdesc:aec22e6d528af637133d7d17f1d7f8ad5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="class_tensor.html">Tensor</a> with the specified shape, initialized with a scalar value.  <br /></td></tr>
<tr class="memitem:a2b070e826df180db62c05d0cdfd85b43" id="r_a2b070e826df180db62c05d0cdfd85b43"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2b070e826df180db62c05d0cdfd85b43">Tensor</a> (const std::vector&lt; int &gt; &amp;shape, const std::vector&lt; double &gt; &amp;data)</td></tr>
<tr class="memdesc:a2b070e826df180db62c05d0cdfd85b43"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="class_tensor.html">Tensor</a> from a specified shape and data vector.  <br /></td></tr>
<tr class="memitem:a127562a0fad3d73c672ef0c926a5df02" id="r_a127562a0fad3d73c672ef0c926a5df02"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a127562a0fad3d73c672ef0c926a5df02">Tensor</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a127562a0fad3d73c672ef0c926a5df02"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy constructor (performs a deep copy of the tensor).  <br /></td></tr>
<tr class="memitem:ac9b2a793615586ac29b2e7215261b844" id="r_ac9b2a793615586ac29b2e7215261b844"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac9b2a793615586ac29b2e7215261b844">UniqueData</a> ()</td></tr>
<tr class="memdesc:ac9b2a793615586ac29b2e7215261b844"><td class="mdescLeft">&#160;</td><td class="mdescRight">Ensures this <a class="el" href="class_tensor.html">Tensor</a> has unique ownership of its data buffer.  <br /></td></tr>
<tr class="memitem:a039914aee51bfae847dbe28209ad69ff" id="r_a039914aee51bfae847dbe28209ad69ff"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor_slice.html">TensorSlice</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a039914aee51bfae847dbe28209ad69ff">operator[]</a> (int index)</td></tr>
<tr class="memdesc:a039914aee51bfae847dbe28209ad69ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns a proxy object for accessing and modifying a slice along the first dimension.  <br /></td></tr>
<tr class="memitem:a63f36d923fe1a8bdfa5127dcdb606b35" id="r_a63f36d923fe1a8bdfa5127dcdb606b35"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a63f36d923fe1a8bdfa5127dcdb606b35">operator[]</a> (int index) const</td></tr>
<tr class="memdesc:a63f36d923fe1a8bdfa5127dcdb606b35"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns an independent copy of a slice along the first dimension (const version).  <br /></td></tr>
<tr class="memitem:a0b7d70c72543fd055cdb101b73cec827" id="r_a0b7d70c72543fd055cdb101b73cec827"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0b7d70c72543fd055cdb101b73cec827">operator=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a0b7d70c72543fd055cdb101b73cec827"><td class="mdescLeft">&#160;</td><td class="mdescRight">Assignment operator (deep copy semantics).  <br /></td></tr>
<tr class="memitem:a47812d7a29b100dd87bcd67e91c64482" id="r_a47812d7a29b100dd87bcd67e91c64482"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a47812d7a29b100dd87bcd67e91c64482">operator+</a> (double value) const</td></tr>
<tr class="memdesc:a47812d7a29b100dd87bcd67e91c64482"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise addition of a scalar value to all tensor elements.  <br /></td></tr>
<tr class="memitem:aaab66abb66d3aa8ac54b985cade60f7e" id="r_aaab66abb66d3aa8ac54b985cade60f7e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aaab66abb66d3aa8ac54b985cade60f7e">operator-</a> (double value) const</td></tr>
<tr class="memdesc:aaab66abb66d3aa8ac54b985cade60f7e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise subtraction of a scalar value from all tensor elements.  <br /></td></tr>
<tr class="memitem:a6658b84a8e2b71220c7f55f8610e6bbe" id="r_a6658b84a8e2b71220c7f55f8610e6bbe"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6658b84a8e2b71220c7f55f8610e6bbe">operator*</a> (double value) const</td></tr>
<tr class="memdesc:a6658b84a8e2b71220c7f55f8610e6bbe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise multiplication of all tensor elements by a scalar value.  <br /></td></tr>
<tr class="memitem:ac7a5df6dc6c7857650e0adbf66b4c422" id="r_ac7a5df6dc6c7857650e0adbf66b4c422"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac7a5df6dc6c7857650e0adbf66b4c422">operator/</a> (double value) const</td></tr>
<tr class="memdesc:ac7a5df6dc6c7857650e0adbf66b4c422"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise division of all tensor elements by a scalar value.  <br /></td></tr>
<tr class="memitem:a6bee0bb8cea232b7f2a589e8d48a4d27" id="r_a6bee0bb8cea232b7f2a589e8d48a4d27"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6bee0bb8cea232b7f2a589e8d48a4d27">operator+</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:a6bee0bb8cea232b7f2a589e8d48a4d27"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise addition of two tensors.  <br /></td></tr>
<tr class="memitem:aef9ba3fe1189eb11d47cd8f1dd573a1b" id="r_aef9ba3fe1189eb11d47cd8f1dd573a1b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aef9ba3fe1189eb11d47cd8f1dd573a1b">operator-</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:aef9ba3fe1189eb11d47cd8f1dd573a1b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise subtraction of two tensors.  <br /></td></tr>
<tr class="memitem:a75728ffb3911510ebfb73c113d97f7ec" id="r_a75728ffb3911510ebfb73c113d97f7ec"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a75728ffb3911510ebfb73c113d97f7ec">operator*</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:a75728ffb3911510ebfb73c113d97f7ec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise multiplication of two tensors (Hadamard product).  <br /></td></tr>
<tr class="memitem:a4a881f8f18dbbb2aa29aeec5f81ec018" id="r_a4a881f8f18dbbb2aa29aeec5f81ec018"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4a881f8f18dbbb2aa29aeec5f81ec018">operator/</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:a4a881f8f18dbbb2aa29aeec5f81ec018"><td class="mdescLeft">&#160;</td><td class="mdescRight">Element-wise division of two tensors.  <br /></td></tr>
<tr class="memitem:a45a758479b01bfce56ca3c7bede0493b" id="r_a45a758479b01bfce56ca3c7bede0493b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a45a758479b01bfce56ca3c7bede0493b">operator+=</a> (double value)</td></tr>
<tr class="memdesc:a45a758479b01bfce56ca3c7bede0493b"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise addition of a scalar value.  <br /></td></tr>
<tr class="memitem:a7e6db16f013c048474b050fda7da2a01" id="r_a7e6db16f013c048474b050fda7da2a01"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7e6db16f013c048474b050fda7da2a01">operator-=</a> (double value)</td></tr>
<tr class="memdesc:a7e6db16f013c048474b050fda7da2a01"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise subtraction of a scalar value.  <br /></td></tr>
<tr class="memitem:a81868ded9686e9083f30666e68fdef6e" id="r_a81868ded9686e9083f30666e68fdef6e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a81868ded9686e9083f30666e68fdef6e">operator*=</a> (double value)</td></tr>
<tr class="memdesc:a81868ded9686e9083f30666e68fdef6e"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise multiplication by a scalar value.  <br /></td></tr>
<tr class="memitem:a513698bd5959d9c531849c91ef8c4c6a" id="r_a513698bd5959d9c531849c91ef8c4c6a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a513698bd5959d9c531849c91ef8c4c6a">operator/=</a> (double value)</td></tr>
<tr class="memdesc:a513698bd5959d9c531849c91ef8c4c6a"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise division by a scalar value.  <br /></td></tr>
<tr class="memitem:a634382ed2b871ed0476b7207cdbbbe15" id="r_a634382ed2b871ed0476b7207cdbbbe15"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a634382ed2b871ed0476b7207cdbbbe15">operator+=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a634382ed2b871ed0476b7207cdbbbe15"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise addition with another tensor.  <br /></td></tr>
<tr class="memitem:a609462c373a6263269bfec6c305b38c3" id="r_a609462c373a6263269bfec6c305b38c3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a609462c373a6263269bfec6c305b38c3">operator-=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a609462c373a6263269bfec6c305b38c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise subtraction with another tensor.  <br /></td></tr>
<tr class="memitem:a93f7554458d7ae9a3cad5dc76eb07027" id="r_a93f7554458d7ae9a3cad5dc76eb07027"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a93f7554458d7ae9a3cad5dc76eb07027">operator*=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a93f7554458d7ae9a3cad5dc76eb07027"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise multiplication with another tensor (Hadamard product).  <br /></td></tr>
<tr class="memitem:a21809015e47552d25e7330bd0707cb1d" id="r_a21809015e47552d25e7330bd0707cb1d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a21809015e47552d25e7330bd0707cb1d">operator/=</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a21809015e47552d25e7330bd0707cb1d"><td class="mdescLeft">&#160;</td><td class="mdescRight">In-place element-wise division by another tensor.  <br /></td></tr>
<tr class="memitem:a50ffbfbb2e300be5346c894226d72812" id="r_a50ffbfbb2e300be5346c894226d72812"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a50ffbfbb2e300be5346c894226d72812">Reshape</a> (const std::vector&lt; int &gt; &amp;new_shape) const</td></tr>
<tr class="memdesc:a50ffbfbb2e300be5346c894226d72812"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reshapes the <a class="el" href="class_tensor.html">Tensor</a> to a new specified shape without changing data order.  <br /></td></tr>
<tr class="memitem:aa5215a8751f54d02e66b38c4982537f9" id="r_aa5215a8751f54d02e66b38c4982537f9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa5215a8751f54d02e66b38c4982537f9">ExpandRank</a> (int axis=0) const</td></tr>
<tr class="memdesc:aa5215a8751f54d02e66b38c4982537f9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Expands the rank of the <a class="el" href="class_tensor.html">Tensor</a> by inserting a dimension of size 1 at a specified axis.  <br /></td></tr>
<tr class="memitem:ab580be2efba7d27e6b6da689eee4732e" id="r_ab580be2efba7d27e6b6da689eee4732e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab580be2efba7d27e6b6da689eee4732e">Flatten</a> (int axis_from, int axis_upto) const</td></tr>
<tr class="memdesc:ab580be2efba7d27e6b6da689eee4732e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flattens a range of consecutive axes into a single dimension.  <br /></td></tr>
<tr class="memitem:acdf40158e4bd7edd14f59bfc2c52ff92" id="r_acdf40158e4bd7edd14f59bfc2c52ff92"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acdf40158e4bd7edd14f59bfc2c52ff92">Slice</a> (int axis, int index) const</td></tr>
<tr class="memdesc:acdf40158e4bd7edd14f59bfc2c52ff92"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extracts a slice of the <a class="el" href="class_tensor.html">Tensor</a> along a specified axis at a given index.  <br /></td></tr>
<tr class="memitem:ad2a6207e2f4dcb9571e4530490fcd439" id="r_ad2a6207e2f4dcb9571e4530490fcd439"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad2a6207e2f4dcb9571e4530490fcd439">Slice</a> (int axis, int index_from, int index_upto) const</td></tr>
<tr class="memdesc:ad2a6207e2f4dcb9571e4530490fcd439"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extracts a range of slices from the <a class="el" href="class_tensor.html">Tensor</a> along a given axis.  <br /></td></tr>
<tr class="memitem:a91a2c79fe15521fb9a3742da4263f60c" id="r_a91a2c79fe15521fb9a3742da4263f60c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a91a2c79fe15521fb9a3742da4263f60c">Append</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor, int axis=-1)</td></tr>
<tr class="memdesc:a91a2c79fe15521fb9a3742da4263f60c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Appends a lower-rank <a class="el" href="class_tensor.html">Tensor</a> along a specified axis (in-place operation).  <br /></td></tr>
<tr class="memitem:aee9562ed6e3368ac6cd664373556cca4" id="r_aee9562ed6e3368ac6cd664373556cca4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aee9562ed6e3368ac6cd664373556cca4">Insert</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor, int axis=-1, int index=0)</td></tr>
<tr class="memdesc:aee9562ed6e3368ac6cd664373556cca4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Inserts a lower-rank <a class="el" href="class_tensor.html">Tensor</a> at a specific position along an axis (in-place operation).  <br /></td></tr>
<tr class="memitem:af7dda240cea62631125c2272e38ffaa1" id="r_af7dda240cea62631125c2272e38ffaa1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af7dda240cea62631125c2272e38ffaa1">Pad</a> (int axis, int pad_before_size, int pad_after_size, double value=0.0) const</td></tr>
<tr class="memdesc:af7dda240cea62631125c2272e38ffaa1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds padding elements before and/or after the tensor along a specified axis.  <br /></td></tr>
<tr class="memitem:a52b3acaaf5f1d9bad285fd7ae88399ac" id="r_a52b3acaaf5f1d9bad285fd7ae88399ac"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a52b3acaaf5f1d9bad285fd7ae88399ac">Tile</a> (const std::vector&lt; int &gt; &amp;repetitions) const</td></tr>
<tr class="memdesc:a52b3acaaf5f1d9bad285fd7ae88399ac"><td class="mdescLeft">&#160;</td><td class="mdescRight">Repeats the entire tensor structure along each axis a specified number of times.  <br /></td></tr>
<tr class="memitem:aa5fba58b033578d704f4634977982c66" id="r_aa5fba58b033578d704f4634977982c66"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa5fba58b033578d704f4634977982c66">Broadcast</a> (const std::vector&lt; int &gt; &amp;shape) const</td></tr>
<tr class="memdesc:aa5fba58b033578d704f4634977982c66"><td class="mdescLeft">&#160;</td><td class="mdescRight">Broadcasts the tensor to a target shape following NumPy-style broadcasting rules.  <br /></td></tr>
<tr class="memitem:a699a4b1ec7d7d244e7c10643bf533f98" id="r_a699a4b1ec7d7d244e7c10643bf533f98"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a699a4b1ec7d7d244e7c10643bf533f98">Transpose</a> (const std::vector&lt; int &gt; &amp;permutation) const</td></tr>
<tr class="memdesc:a699a4b1ec7d7d244e7c10643bf533f98"><td class="mdescLeft">&#160;</td><td class="mdescRight">Transposes (permutes) the tensor's axes according to a specified permutation.  <br /></td></tr>
<tr class="memitem:a0adf81cbee9f45641c9c3bd70ec5c2b4" id="r_a0adf81cbee9f45641c9c3bd70ec5c2b4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0adf81cbee9f45641c9c3bd70ec5c2b4">MatMul</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor) const</td></tr>
<tr class="memdesc:a0adf81cbee9f45641c9c3bd70ec5c2b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication with another tensor.  <br /></td></tr>
<tr class="memitem:ae88a978596e4f4d82ca5a27b8b79073f" id="r_ae88a978596e4f4d82ca5a27b8b79073f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae88a978596e4f4d82ca5a27b8b79073f">Convolve</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;filter, const std::vector&lt; int &gt; &amp;strides, const std::vector&lt; int &gt; &amp;padding)</td></tr>
<tr class="memdesc:ae88a978596e4f4d82ca5a27b8b79073f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs N-dimensional convolution between this tensor and a filter kernel.  <br /></td></tr>
<tr class="memitem:ad378cc1c1af81074204c05bc0ff4f00d" id="r_ad378cc1c1af81074204c05bc0ff4f00d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad378cc1c1af81074204c05bc0ff4f00d">MaxPool</a> (const std::vector&lt; int &gt; &amp;pool_shape, const std::vector&lt; int &gt; &amp;strides={})</td></tr>
<tr class="memdesc:ad378cc1c1af81074204c05bc0ff4f00d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs max pooling operation by taking the maximum value within sliding windows.  <br /></td></tr>
<tr class="memitem:ad1f64c43e7267629a150a2cc7d7ad75b" id="r_ad1f64c43e7267629a150a2cc7d7ad75b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad1f64c43e7267629a150a2cc7d7ad75b">MinPool</a> (const std::vector&lt; int &gt; &amp;pool_shape, const std::vector&lt; int &gt; &amp;strides={})</td></tr>
<tr class="memdesc:ad1f64c43e7267629a150a2cc7d7ad75b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs min pooling operation by taking the minimum value within sliding windows.  <br /></td></tr>
<tr class="memitem:a40fb78ab8fbcfab0ab57eeaa5c05676a" id="r_a40fb78ab8fbcfab0ab57eeaa5c05676a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a40fb78ab8fbcfab0ab57eeaa5c05676a">AvgPool</a> (const std::vector&lt; int &gt; &amp;pool_shape, const std::vector&lt; int &gt; &amp;strides={})</td></tr>
<tr class="memdesc:a40fb78ab8fbcfab0ab57eeaa5c05676a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs average pooling operation by computing the mean value within sliding windows.  <br /></td></tr>
<tr class="memitem:af2642442d55d275a7a21fca2e3dfb4b5" id="r_af2642442d55d275a7a21fca2e3dfb4b5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af2642442d55d275a7a21fca2e3dfb4b5">Sign</a> (bool heaviside=false) const</td></tr>
<tr class="memdesc:af2642442d55d275a7a21fca2e3dfb4b5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the sign function element-wise.  <br /></td></tr>
<tr class="memitem:a34014716594913b10f8c606c0b0389de" id="r_a34014716594913b10f8c606c0b0389de"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a34014716594913b10f8c606c0b0389de">ReduceSum</a> (int axis=0) const</td></tr>
<tr class="memdesc:a34014716594913b10f8c606c0b0389de"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the sum.  <br /></td></tr>
<tr class="memitem:a279fd0fb9be2315140b21feeb2e51034" id="r_a279fd0fb9be2315140b21feeb2e51034"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a279fd0fb9be2315140b21feeb2e51034">ReduceMean</a> (int axis=0) const</td></tr>
<tr class="memdesc:a279fd0fb9be2315140b21feeb2e51034"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the mean (average).  <br /></td></tr>
<tr class="memitem:aa5366dcad0b31362b2c4a42c7452adcf" id="r_aa5366dcad0b31362b2c4a42c7452adcf"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa5366dcad0b31362b2c4a42c7452adcf">ReduceVar</a> (int axis=0, bool inference=false) const</td></tr>
<tr class="memdesc:aa5366dcad0b31362b2c4a42c7452adcf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the variance.  <br /></td></tr>
<tr class="memitem:a4f4b299f874a72509a053c270bbb0aa9" id="r_a4f4b299f874a72509a053c270bbb0aa9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4f4b299f874a72509a053c270bbb0aa9">ReduceMax</a> (int axis=0) const</td></tr>
<tr class="memdesc:a4f4b299f874a72509a053c270bbb0aa9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the maximum.  <br /></td></tr>
<tr class="memitem:a3e92b91cfe84cfd666751d7f5431a642" id="r_a3e92b91cfe84cfd666751d7f5431a642"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3e92b91cfe84cfd666751d7f5431a642">ReduceMin</a> (int axis=0) const</td></tr>
<tr class="memdesc:a3e92b91cfe84cfd666751d7f5431a642"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces the tensor along a specified axis by computing the minimum.  <br /></td></tr>
<tr class="memitem:adb9ce076a4629b3bbc897e17f39b7573" id="r_adb9ce076a4629b3bbc897e17f39b7573"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#adb9ce076a4629b3bbc897e17f39b7573">Sum</a> () const</td></tr>
<tr class="memdesc:adb9ce076a4629b3bbc897e17f39b7573"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the sum of all elements in the tensor.  <br /></td></tr>
<tr class="memitem:aac4651bb52521e86e875d2e8c1e8643a" id="r_aac4651bb52521e86e875d2e8c1e8643a"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aac4651bb52521e86e875d2e8c1e8643a">Mean</a> () const</td></tr>
<tr class="memdesc:aac4651bb52521e86e875d2e8c1e8643a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the mean (average) of all elements in the tensor.  <br /></td></tr>
<tr class="memitem:aceb3777b0c462d3596781b6031a234b6" id="r_aceb3777b0c462d3596781b6031a234b6"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aceb3777b0c462d3596781b6031a234b6">Var</a> (bool inference=false) const</td></tr>
<tr class="memdesc:aceb3777b0c462d3596781b6031a234b6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the variance of all elements in the tensor.  <br /></td></tr>
<tr class="memitem:a46e3d36946b41f93fef4b0edcc48ba2e" id="r_a46e3d36946b41f93fef4b0edcc48ba2e"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a46e3d36946b41f93fef4b0edcc48ba2e">Max</a> () const</td></tr>
<tr class="memdesc:a46e3d36946b41f93fef4b0edcc48ba2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finds the maximum value in the tensor.  <br /></td></tr>
<tr class="memitem:a759daa212e3786fda070af4732f3ee15" id="r_a759daa212e3786fda070af4732f3ee15"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a759daa212e3786fda070af4732f3ee15">Min</a> () const</td></tr>
<tr class="memdesc:a759daa212e3786fda070af4732f3ee15"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finds the minimum value in the tensor.  <br /></td></tr>
<tr class="memitem:aa9330e265d36beb2e217c75f6a03a41e" id="r_aa9330e265d36beb2e217c75f6a03a41e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa9330e265d36beb2e217c75f6a03a41e">Abs</a> () const</td></tr>
<tr class="memdesc:aa9330e265d36beb2e217c75f6a03a41e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the absolute value of each element.  <br /></td></tr>
<tr class="memitem:a6ecaeb0e29c326798d82d6a2cccc28cf" id="r_a6ecaeb0e29c326798d82d6a2cccc28cf"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6ecaeb0e29c326798d82d6a2cccc28cf">Floor</a> () const</td></tr>
<tr class="memdesc:a6ecaeb0e29c326798d82d6a2cccc28cf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rounds each element down to the nearest integer (floor function).  <br /></td></tr>
<tr class="memitem:ac1228f81de00883e64f49ee19e7d6021" id="r_ac1228f81de00883e64f49ee19e7d6021"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac1228f81de00883e64f49ee19e7d6021">Ceil</a> () const</td></tr>
<tr class="memdesc:ac1228f81de00883e64f49ee19e7d6021"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rounds each element up to the nearest integer (ceiling function).  <br /></td></tr>
<tr class="memitem:a0f50736794c3594411fe96aeb337b7b5" id="r_a0f50736794c3594411fe96aeb337b7b5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0f50736794c3594411fe96aeb337b7b5">Round</a> (int decimal_place=0) const</td></tr>
<tr class="memdesc:a0f50736794c3594411fe96aeb337b7b5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rounds each element to a specified number of decimal places.  <br /></td></tr>
<tr class="memitem:a7de1cf7ec97265fcb0f776ea47fd9236" id="r_a7de1cf7ec97265fcb0f776ea47fd9236"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7de1cf7ec97265fcb0f776ea47fd9236">Clip</a> (double min_value, double max_value) const</td></tr>
<tr class="memdesc:a7de1cf7ec97265fcb0f776ea47fd9236"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clips (clamps) each element to be within a specified range.  <br /></td></tr>
<tr class="memitem:a0bb8eea690681cb13ffbe53fa66d7183" id="r_a0bb8eea690681cb13ffbe53fa66d7183"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0bb8eea690681cb13ffbe53fa66d7183">Power</a> (double exponent) const</td></tr>
<tr class="memdesc:a0bb8eea690681cb13ffbe53fa66d7183"><td class="mdescLeft">&#160;</td><td class="mdescRight">Raises each element to a specified power (exponentiation).  <br /></td></tr>
<tr class="memitem:a4c7df16dc4a4fc10cbdf5bfa20e25ba7" id="r_a4c7df16dc4a4fc10cbdf5bfa20e25ba7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4c7df16dc4a4fc10cbdf5bfa20e25ba7">Sqrt</a> () const</td></tr>
<tr class="memdesc:a4c7df16dc4a4fc10cbdf5bfa20e25ba7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the square root of each element.  <br /></td></tr>
<tr class="memitem:a40481e1178fdb80dae8934a8ed75adbb" id="r_a40481e1178fdb80dae8934a8ed75adbb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a40481e1178fdb80dae8934a8ed75adbb">Log</a> (double base=std::numbers::e) const</td></tr>
<tr class="memdesc:a40481e1178fdb80dae8934a8ed75adbb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the logarithm of each element with a specified base.  <br /></td></tr>
<tr class="memitem:ae9f79fc49610fe4ba20ade7d3cbafe30" id="r_ae9f79fc49610fe4ba20ade7d3cbafe30"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae9f79fc49610fe4ba20ade7d3cbafe30">Exp</a> () const</td></tr>
<tr class="memdesc:ae9f79fc49610fe4ba20ade7d3cbafe30"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes e raised to the power of each element (exponential function).  <br /></td></tr>
<tr class="memitem:aafd911eab8af5c4ec79593d67f7823df" id="r_aafd911eab8af5c4ec79593d67f7823df"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aafd911eab8af5c4ec79593d67f7823df">Mod</a> (double mod_value) const</td></tr>
<tr class="memdesc:aafd911eab8af5c4ec79593d67f7823df"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the modulus (remainder) of each element divided by a value.  <br /></td></tr>
<tr class="memitem:a7183546c868b2cac8075f0434376dccb" id="r_a7183546c868b2cac8075f0434376dccb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7183546c868b2cac8075f0434376dccb">Sin</a> () const</td></tr>
<tr class="memdesc:a7183546c868b2cac8075f0434376dccb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the sine of each element (in radians).  <br /></td></tr>
<tr class="memitem:a9f691219cdb0a10a8111db8573128666" id="r_a9f691219cdb0a10a8111db8573128666"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9f691219cdb0a10a8111db8573128666">Cos</a> () const</td></tr>
<tr class="memdesc:a9f691219cdb0a10a8111db8573128666"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the cosine of each element (in radians).  <br /></td></tr>
<tr class="memitem:a8148f97acf80f5e6aa685544ecc22be2" id="r_a8148f97acf80f5e6aa685544ecc22be2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8148f97acf80f5e6aa685544ecc22be2">Tan</a> () const</td></tr>
<tr class="memdesc:a8148f97acf80f5e6aa685544ecc22be2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the tangent of each element (in radians).  <br /></td></tr>
<tr class="memitem:a0dfe79c9b87996847a2c898578c240ff" id="r_a0dfe79c9b87996847a2c898578c240ff"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0dfe79c9b87996847a2c898578c240ff">Csc</a> () const</td></tr>
<tr class="memdesc:a0dfe79c9b87996847a2c898578c240ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the cosecant (reciprocal of sine) of each element (in radians).  <br /></td></tr>
<tr class="memitem:a85eaa3e12b1a044e82d5f5912460aee8" id="r_a85eaa3e12b1a044e82d5f5912460aee8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a85eaa3e12b1a044e82d5f5912460aee8">Sec</a> () const</td></tr>
<tr class="memdesc:a85eaa3e12b1a044e82d5f5912460aee8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the secant (reciprocal of cosine) of each element (in radians).  <br /></td></tr>
<tr class="memitem:a9cff3aed7469fd72059da70444170b41" id="r_a9cff3aed7469fd72059da70444170b41"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9cff3aed7469fd72059da70444170b41">Cot</a> () const</td></tr>
<tr class="memdesc:a9cff3aed7469fd72059da70444170b41"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the cotangent (reciprocal of tangent) of each element (in radians).  <br /></td></tr>
<tr class="memitem:ae58831c074bbc7eec61f1ea6a1644d91" id="r_ae58831c074bbc7eec61f1ea6a1644d91"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae58831c074bbc7eec61f1ea6a1644d91">Asin</a> () const</td></tr>
<tr class="memdesc:ae58831c074bbc7eec61f1ea6a1644d91"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arcsine (inverse sine) of each element.  <br /></td></tr>
<tr class="memitem:a8639798951ac43fcf9edbb510b65dd5b" id="r_a8639798951ac43fcf9edbb510b65dd5b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8639798951ac43fcf9edbb510b65dd5b">Acos</a> () const</td></tr>
<tr class="memdesc:a8639798951ac43fcf9edbb510b65dd5b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arccosine (inverse cosine) of each element.  <br /></td></tr>
<tr class="memitem:af9cb1919c5b966567b5d7d485b24dc56" id="r_af9cb1919c5b966567b5d7d485b24dc56"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af9cb1919c5b966567b5d7d485b24dc56">Atan</a> () const</td></tr>
<tr class="memdesc:af9cb1919c5b966567b5d7d485b24dc56"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arctangent (inverse tangent) of each element.  <br /></td></tr>
<tr class="memitem:a7fe84551eed81225a551e784bd528f8c" id="r_a7fe84551eed81225a551e784bd528f8c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7fe84551eed81225a551e784bd528f8c">Acsc</a> () const</td></tr>
<tr class="memdesc:a7fe84551eed81225a551e784bd528f8c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arccosecant (inverse cosecant) of each element.  <br /></td></tr>
<tr class="memitem:aeb8b24b1035217d354520b1aa16117e7" id="r_aeb8b24b1035217d354520b1aa16117e7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aeb8b24b1035217d354520b1aa16117e7">Asec</a> () const</td></tr>
<tr class="memdesc:aeb8b24b1035217d354520b1aa16117e7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arcsecant (inverse secant) of each element.  <br /></td></tr>
<tr class="memitem:a769bd806f3e8a44ccb621b548f617505" id="r_a769bd806f3e8a44ccb621b548f617505"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a769bd806f3e8a44ccb621b548f617505">Acot</a> () const</td></tr>
<tr class="memdesc:a769bd806f3e8a44ccb621b548f617505"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the arccotangent (inverse cotangent) of each element.  <br /></td></tr>
<tr class="memitem:a2cbc29f90925cf18d54d62d9cc6ebbe3" id="r_a2cbc29f90925cf18d54d62d9cc6ebbe3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2cbc29f90925cf18d54d62d9cc6ebbe3">Sinh</a> () const</td></tr>
<tr class="memdesc:a2cbc29f90925cf18d54d62d9cc6ebbe3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic sine of each element.  <br /></td></tr>
<tr class="memitem:a65a86d44bf78501dbdcaa52ba72d7bd3" id="r_a65a86d44bf78501dbdcaa52ba72d7bd3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a65a86d44bf78501dbdcaa52ba72d7bd3">Cosh</a> () const</td></tr>
<tr class="memdesc:a65a86d44bf78501dbdcaa52ba72d7bd3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic cosine of each element.  <br /></td></tr>
<tr class="memitem:aee8ad1fde49129b199ad87b4dd85c07f" id="r_aee8ad1fde49129b199ad87b4dd85c07f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aee8ad1fde49129b199ad87b4dd85c07f">Tanh</a> () const</td></tr>
<tr class="memdesc:aee8ad1fde49129b199ad87b4dd85c07f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic tangent of each element.  <br /></td></tr>
<tr class="memitem:a2ddab39bf92ee11ab318b3d3374b391c" id="r_a2ddab39bf92ee11ab318b3d3374b391c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2ddab39bf92ee11ab318b3d3374b391c">Csch</a> () const</td></tr>
<tr class="memdesc:a2ddab39bf92ee11ab318b3d3374b391c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element.  <br /></td></tr>
<tr class="memitem:a03d0593a8715bad32098cbda433451f1" id="r_a03d0593a8715bad32098cbda433451f1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a03d0593a8715bad32098cbda433451f1">Sech</a> () const</td></tr>
<tr class="memdesc:a03d0593a8715bad32098cbda433451f1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element.  <br /></td></tr>
<tr class="memitem:a4b4030aa4413ca8c4714526965986657" id="r_a4b4030aa4413ca8c4714526965986657"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4b4030aa4413ca8c4714526965986657">Coth</a> () const</td></tr>
<tr class="memdesc:a4b4030aa4413ca8c4714526965986657"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element.  <br /></td></tr>
<tr class="memitem:a7d4ff3c3c4775b55bd8fc94d9d3e4479" id="r_a7d4ff3c3c4775b55bd8fc94d9d3e4479"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7d4ff3c3c4775b55bd8fc94d9d3e4479">Asinh</a> () const</td></tr>
<tr class="memdesc:a7d4ff3c3c4775b55bd8fc94d9d3e4479"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic sine of each element.  <br /></td></tr>
<tr class="memitem:a626ba6c6dc620d5de32c6bc81a594381" id="r_a626ba6c6dc620d5de32c6bc81a594381"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a626ba6c6dc620d5de32c6bc81a594381">Acosh</a> () const</td></tr>
<tr class="memdesc:a626ba6c6dc620d5de32c6bc81a594381"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic cosine of each element.  <br /></td></tr>
<tr class="memitem:ad6e896aed6bc70bfe19fb1f9cd2d527d" id="r_ad6e896aed6bc70bfe19fb1f9cd2d527d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad6e896aed6bc70bfe19fb1f9cd2d527d">Atanh</a> () const</td></tr>
<tr class="memdesc:ad6e896aed6bc70bfe19fb1f9cd2d527d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic tangent of each element.  <br /></td></tr>
<tr class="memitem:ada3b749b1a67fedb986ff69a05350c63" id="r_ada3b749b1a67fedb986ff69a05350c63"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ada3b749b1a67fedb986ff69a05350c63">Acsch</a> () const</td></tr>
<tr class="memdesc:ada3b749b1a67fedb986ff69a05350c63"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic cosecant of each element.  <br /></td></tr>
<tr class="memitem:a5144a947b733c6ca5a5dcc5430f8df29" id="r_a5144a947b733c6ca5a5dcc5430f8df29"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5144a947b733c6ca5a5dcc5430f8df29">Asech</a> () const</td></tr>
<tr class="memdesc:a5144a947b733c6ca5a5dcc5430f8df29"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic secant of each element.  <br /></td></tr>
<tr class="memitem:ad24f26852c9f77f4924bb7f921c470fd" id="r_ad24f26852c9f77f4924bb7f921c470fd"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad24f26852c9f77f4924bb7f921c470fd">Acoth</a> () const</td></tr>
<tr class="memdesc:ad24f26852c9f77f4924bb7f921c470fd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the inverse hyperbolic cotangent of each element.  <br /></td></tr>
<tr class="memitem:ae00c340a459f86d5053466a73ef210e4" id="r_ae00c340a459f86d5053466a73ef210e4"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae00c340a459f86d5053466a73ef210e4">Rank</a> () const</td></tr>
<tr class="memdesc:ae00c340a459f86d5053466a73ef210e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the rank (number of dimensions) of the tensor.  <br /></td></tr>
<tr class="memitem:ad7155b38d35344550fde1eeb7f0fbd61" id="r_ad7155b38d35344550fde1eeb7f0fbd61"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad7155b38d35344550fde1eeb7f0fbd61">Volume</a> () const</td></tr>
<tr class="memdesc:ad7155b38d35344550fde1eeb7f0fbd61"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the total number of elements (volume) in the tensor.  <br /></td></tr>
<tr class="memitem:adb8cd0e538a8410157ca2a17a5055f02" id="r_adb8cd0e538a8410157ca2a17a5055f02"><td class="memItemLeft" align="right" valign="top">std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#adb8cd0e538a8410157ca2a17a5055f02">Shape</a> () const</td></tr>
<tr class="memdesc:adb8cd0e538a8410157ca2a17a5055f02"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the shape of the tensor as a vector of dimension sizes.  <br /></td></tr>
<tr class="memitem:a767884250837a4894e6d8b592a9d3450" id="r_a767884250837a4894e6d8b592a9d3450"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a767884250837a4894e6d8b592a9d3450">IsEmpty</a> () const</td></tr>
<tr class="memdesc:a767884250837a4894e6d8b592a9d3450"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks whether the tensor contains no elements.  <br /></td></tr>
<tr class="memitem:a203a74ae4428ecadfd1efbebd85d753d" id="r_a203a74ae4428ecadfd1efbebd85d753d"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a203a74ae4428ecadfd1efbebd85d753d">IsScalar</a> () const</td></tr>
<tr class="memdesc:a203a74ae4428ecadfd1efbebd85d753d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks whether the tensor represents a scalar (single) value.  <br /></td></tr>
<tr class="memitem:a5fe1cfdcbe51b9df6f87b9f07f98f0ff" id="r_a5fe1cfdcbe51b9df6f87b9f07f98f0ff"><td class="memItemLeft" align="right" valign="top"><a id="a5fe1cfdcbe51b9df6f87b9f07f98f0ff" name="a5fe1cfdcbe51b9df6f87b9f07f98f0ff"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>Clear</b> ()</td></tr>
<tr class="memitem:a5e012653a230fcafd531ac6063e0067a" id="r_a5e012653a230fcafd531ac6063e0067a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5e012653a230fcafd531ac6063e0067a">Print</a> (int depth=0) const</td></tr>
<tr class="memdesc:a5e012653a230fcafd531ac6063e0067a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prints the tensor contents to standard output in a readable, nested format.  <br /></td></tr>
<tr class="memitem:ad3b998f18ac3263bf5e02b88026a166f" id="r_ad3b998f18ac3263bf5e02b88026a166f"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad3b998f18ac3263bf5e02b88026a166f">ToScalar</a> () const</td></tr>
<tr class="memdesc:ad3b998f18ac3263bf5e02b88026a166f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a scalar tensor to a double value.  <br /></td></tr>
<tr class="memitem:a577b089b89971b6ab7a1bfab790e4edc" id="r_a577b089b89971b6ab7a1bfab790e4edc"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a577b089b89971b6ab7a1bfab790e4edc">ToVector</a> () const</td></tr>
<tr class="memdesc:a577b089b89971b6ab7a1bfab790e4edc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a rank-1 tensor to a standard vector.  <br /></td></tr>
<tr class="memitem:abd4b0bfabe2a7c378318d6132ec84936" id="r_abd4b0bfabe2a7c378318d6132ec84936"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; double &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abd4b0bfabe2a7c378318d6132ec84936">ToMatrix</a> () const</td></tr>
<tr class="memdesc:abd4b0bfabe2a7c378318d6132ec84936"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a rank-2 tensor to a 2D vector (matrix).  <br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-pub-static-methods" class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a4d525a3d5051c3a704db5a254b654706" id="r_a4d525a3d5051c3a704db5a254b654706"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4d525a3d5051c3a704db5a254b654706">Concat</a> (const std::vector&lt; <a class="el" href="class_tensor.html">Tensor</a> &gt; &amp;tensors, int axis=-1)</td></tr>
<tr class="memdesc:a4d525a3d5051c3a704db5a254b654706"><td class="mdescLeft">&#160;</td><td class="mdescRight">Concatenates multiple Tensors along a specified axis.  <br /></td></tr>
<tr class="memitem:a7d2ad35ec705991518a2ecbec8ffd318" id="r_a7d2ad35ec705991518a2ecbec8ffd318"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7d2ad35ec705991518a2ecbec8ffd318">Stack</a> (const std::vector&lt; <a class="el" href="class_tensor.html">Tensor</a> &gt; &amp;tensors, int axis=0)</td></tr>
<tr class="memdesc:a7d2ad35ec705991518a2ecbec8ffd318"><td class="mdescLeft">&#160;</td><td class="mdescRight">Stacks multiple Tensors along a new dimension.  <br /></td></tr>
<tr class="memitem:a33ee78056cb83d4381fdcbe3c79cde96" id="r_a33ee78056cb83d4381fdcbe3c79cde96"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a33ee78056cb83d4381fdcbe3c79cde96">MatMul</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor_1, const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor_2)</td></tr>
<tr class="memdesc:a33ee78056cb83d4381fdcbe3c79cde96"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication between two tensors with automatic broadcasting.  <br /></td></tr>
<tr class="memitem:abde6f09589147296a9035bce10cc8c49" id="r_abde6f09589147296a9035bce10cc8c49"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="class_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abde6f09589147296a9035bce10cc8c49">TensorDot</a> (const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor_1, const <a class="el" href="class_tensor.html">Tensor</a> &amp;tensor_2, const std::vector&lt; int &gt; &amp;contract_axes_1, const std::vector&lt; int &gt; &amp;contract_axes_2)</td></tr>
<tr class="memdesc:abde6f09589147296a9035bce10cc8c49"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs generalized tensor contraction over specified axes.  <br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-friends" class="groupheader"><a id="friends" name="friends"></a>
Friends</h2></td></tr>
<tr class="memitem:a290d8628c199bad78fb29560685327bf" id="r_a290d8628c199bad78fb29560685327bf"><td class="memItemLeft" align="right" valign="top"><a id="a290d8628c199bad78fb29560685327bf" name="a290d8628c199bad78fb29560685327bf"></a>
class&#160;</td><td class="memItemRight" valign="bottom"><b>TensorSlice</b></td></tr>
</table>
<a name="details" id="details"></a><h2 id="header-details" class="groupheader">Detailed Description</h2>
<div class="textblock"><dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_c_1_2_users_2saha0_2source_2repos_2_tensor_2_tensor_2_tensor_slice_8h-example.html#_a0">C:/Users/saha0/source/repos/Tensor/Tensor/TensorSlice.h</a>.</dd>
</dl>
</div><a name="doc-constructors" id="doc-constructors"></a><h2 id="header-doc-constructors" class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="aec22e6d528af637133d7d17f1d7f8ad5" name="aec22e6d528af637133d7d17f1d7f8ad5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec22e6d528af637133d7d17f1d7f8ad5">&#9670;&#160;</a></span>Tensor() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor::Tensor </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructs a <a class="el" href="class_tensor.html">Tensor</a> with the specified shape, initialized with a scalar value. </p>
<p>This constructor creates a new <a class="el" href="class_tensor.html">Tensor</a> with the given shape dimensions and fills all elements with the provided scalar value. It handles both scalar tensors (rank-0, empty shape) and multi-dimensional tensors.</p>
<p>For scalar tensors (empty shape), a rank-0 tensor is created containing a single value. For multi-dimensional tensors, all elements are initialized to the same value.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>A vector of positive integers representing the tensor dimensions. For a scalar tensor, pass an empty vector <span class="tt">{}</span>. For example: <span class="tt">{2, 3, 4}</span> creates a 234 tensor.</td></tr>
    <tr><td class="paramname">value</td><td>The scalar value used to initialize all elements. Default is 0.0. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A newly constructed <a class="el" href="class_tensor.html">Tensor</a> object.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The value is NaN or infinity.</li>
<li>The shape contains non-positive dimensions (i.e., any dimension ? 0).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the total volume (product of all dimensions) exceeds INT_MAX, indicating potential memory overflow.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>The tensor's internal data is stored in row-major order. Strides are automatically computed from the shape. </dd></dl>

</div>
</div>
<a id="a2b070e826df180db62c05d0cdfd85b43" name="a2b070e826df180db62c05d0cdfd85b43"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b070e826df180db62c05d0cdfd85b43">&#9670;&#160;</a></span>Tensor() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor::Tensor </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructs a <a class="el" href="class_tensor.html">Tensor</a> from a specified shape and data vector. </p>
<p>This constructor creates a new <a class="el" href="class_tensor.html">Tensor</a> by combining shape metadata with raw data. The provided data vector is copied into the tensor's internal shared storage. All data elements are validated to ensure they are finite values.</p>
<p>For scalar tensors (empty shape), the data vector must contain exactly one element. For multi-dimensional tensors, the total number of elements in the data vector must match the volume implied by the shape (product of all dimensions).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>A vector of positive integers representing the tensor dimensions. For a scalar tensor, pass an empty vector <span class="tt">{}</span>. For example: <span class="tt">{2, 3, 4}</span> creates a 234 tensor.</td></tr>
    <tr><td class="paramname">data</td><td>A vector of doubles containing all tensor elements in row-major order. Must be non-empty and contain only finite values (no NaN or infinity). The size must equal the volume computed from the shape.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A newly constructed <a class="el" href="class_tensor.html">Tensor</a> object with independent data ownership.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The data vector is empty.</li>
<li>The data contains NaN or infinity values.</li>
<li>The shape contains non-positive dimensions (i.e., any dimension ? 0).</li>
<li>For scalar tensors (empty shape), data contains more than one element.</li>
<li>The shape volume does not match the data size.</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the total volume (product of all dimensions) exceeds INT_MAX, indicating potential memory overflow.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>The data is copied, so modifications to the original vector do not affect the tensor. Internal strides are automatically computed from the shape. Data is stored in row-major order. </dd></dl>

</div>
</div>
<a id="a127562a0fad3d73c672ef0c926a5df02" name="a127562a0fad3d73c672ef0c926a5df02"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a127562a0fad3d73c672ef0c926a5df02">&#9670;&#160;</a></span>Tensor() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor::Tensor </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Copy constructor (performs a deep copy of the tensor). </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> that is completely independent from the source tensor. All metadata (rank, shape, strides) is copied, and the data is deep copied into a new shared storage buffer. Modifying the new tensor does not affect the original tensor in any way.</p>
<p>If the source tensor is a view (a slice of another tensor), only the visible data range <span class="tt">[start, end)</span> is copied, not the entire underlying buffer. The resulting tensor is always a complete, standalone tensor (never a view).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The source <a class="el" href="class_tensor.html">Tensor</a> to copy from.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A newly constructed <a class="el" href="class_tensor.html">Tensor</a> object with independent data ownership.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>This is a <b>deep copy operation</b>. For large tensors, this can be expensive in terms of both time and memory. If you need to avoid copying, consider using the indexing operator <span class="tt">[]</span> which returns a view (for const tensors) or using explicit move semantics if available.</dd>
<dd>
The resulting tensor always has <span class="tt">start = 0</span> and <span class="tt">end = volume</span>, meaning it is never a view of another tensor's data. </dd></dl>

</div>
</div>
<a name="doc-func-members" id="doc-func-members"></a><h2 id="header-doc-func-members" class="groupheader">Member Function Documentation</h2>
<a id="aa9330e265d36beb2e217c75f6a03a41e" name="aa9330e265d36beb2e217c75f6a03a41e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9330e265d36beb2e217c75f6a03a41e">&#9670;&#160;</a></span>Abs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Abs </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the absolute value of each element. </p>
<p>Returns a new tensor where each element is the absolute value (magnitude) of the corresponding element in the original tensor. For any value x, the result is |x|, which is always non-negative.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing absolute values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a8639798951ac43fcf9edbb510b65dd5b" name="a8639798951ac43fcf9edbb510b65dd5b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8639798951ac43fcf9edbb510b65dd5b">&#9670;&#160;</a></span>Acos()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Acos </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arccosine (inverse cosine) of each element. </p>
<p>Returns a new tensor where each element is the arccosine of the corresponding element in the original tensor. The result is in radians in the range [0, ].</p>
<p>The arccosine function is only defined for input values in the range [-1, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arccosine values in radians, ranging from 0 to .</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is outside the range [-1, 1].</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/. </dd></dl>

</div>
</div>
<a id="a626ba6c6dc620d5de32c6bc81a594381" name="a626ba6c6dc620d5de32c6bc81a594381"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a626ba6c6dc620d5de32c6bc81a594381">&#9670;&#160;</a></span>Acosh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Acosh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic cosine of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic cosine (also called area hyperbolic cosine) of the corresponding element in the original tensor. It is defined as: acosh(x) = ln(x + sqrt(x - 1))</p>
<p>The inverse hyperbolic cosine is only defined for values  1.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic cosine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is less than 1 (where acosh is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a769bd806f3e8a44ccb621b548f617505" name="a769bd806f3e8a44ccb621b548f617505"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a769bd806f3e8a44ccb621b548f617505">&#9670;&#160;</a></span>Acot()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Acot </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arccotangent (inverse cotangent) of each element. </p>
<p>Returns a new tensor where each element is the arccotangent of the corresponding element in the original tensor. The result is in radians in the range (0, ).</p>
<p>The arccotangent function is defined for all real numbers. For zero, it returns /2. For negative values, the result is adjusted to maintain the range [0, ].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arccotangent values in radians, ranging from 0 to .</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/. </dd></dl>

</div>
</div>
<a id="ad24f26852c9f77f4924bb7f921c470fd" name="ad24f26852c9f77f4924bb7f921c470fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad24f26852c9f77f4924bb7f921c470fd">&#9670;&#160;</a></span>Acoth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Acoth </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic cotangent of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic cotangent of the corresponding element in the original tensor. It is computed as: acoth(x) = atanh(1/x)</p>
<p>The inverse hyperbolic cotangent is only defined for values in (-, -1)  (1, ). Values in the range [-1, 1] are undefined.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic cotangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is in the range [-1, 1] (where acoth is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a7fe84551eed81225a551e784bd528f8c" name="a7fe84551eed81225a551e784bd528f8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fe84551eed81225a551e784bd528f8c">&#9670;&#160;</a></span>Acsc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Acsc </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arccosecant (inverse cosecant) of each element. </p>
<p>Returns a new tensor where each element is the arccosecant of the corresponding element in the original tensor. The result is in radians.</p>
<p>The arccosecant function is only defined for values in (-, -1]  [1, ). It is computed as asin(1/x).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arccosecant values in radians.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is in the range (-1, 1), where arccosecant is undefined.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/. </dd></dl>

</div>
</div>
<a id="ada3b749b1a67fedb986ff69a05350c63" name="ada3b749b1a67fedb986ff69a05350c63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ada3b749b1a67fedb986ff69a05350c63">&#9670;&#160;</a></span>Acsch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Acsch </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic cosecant of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic cosecant of the corresponding element in the original tensor. It is computed as: acsch(x) = asinh(1/x)</p>
<p>The inverse hyperbolic cosecant is undefined at zero.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic cosecant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately zero (where acsch is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a91a2c79fe15521fb9a3742da4263f60c" name="a91a2c79fe15521fb9a3742da4263f60c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a91a2c79fe15521fb9a3742da4263f60c">&#9670;&#160;</a></span>Append()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::Append </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Appends a lower-rank <a class="el" href="class_tensor.html">Tensor</a> along a specified axis (in-place operation). </p>
<p>This method appends a <a class="el" href="class_tensor.html">Tensor</a> of rank <span class="tt">n-1</span> to the current <a class="el" href="class_tensor.html">Tensor</a> of rank <span class="tt">n</span> by inserting it along a specified axis. The appended tensor must match all dimensions of the current tensor except for the append axis, where the dimension is increased by 1.</p>
<p>The operation modifies the current <a class="el" href="class_tensor.html">Tensor</a> in-place by:</p><ol type="1">
<li>Ensuring unique data ownership (calls <a class="el" href="#ac9b2a793615586ac29b2e7215261b844" title="Ensures this Tensor has unique ownership of its data buffer.">UniqueData()</a>).</li>
<li>Interleaving the new tensor's data at the appropriate positions.</li>
<li>Updating shape, strides, and volume metadata.</li>
</ol>
<p>If axis is -1 (default), the method automatically determines the axis by finding the dimension mismatch between the two tensors' shapes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The <a class="el" href="class_tensor.html">Tensor</a> to append. Must have rank = <span class="tt">this-&gt;rank - 1</span>. All dimensions except the append axis must match the current tensor's shape.</td></tr>
    <tr><td class="paramname">axis</td><td>The axis along which to append. Default is -1 (auto-detect). Must satisfy: <span class="tt">-1  axis &lt; rank</span>. If -1, the axis is inferred from the shape mismatch.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is less than -1 or &gt;= rank.</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The tensor's rank is not exactly <span class="tt">rank - 1</span>.</li>
<li>The shapes are not compatible for appending along the specified axis.</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the resulting shape volume exceeds INT_MAX.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an <b>in-place operation</b> that modifies the current <a class="el" href="class_tensor.html">Tensor</a>. The original data is replaced with the merged result.</dd>
<dd>
This method calls <a class="el" href="#ac9b2a793615586ac29b2e7215261b844" title="Ensures this Tensor has unique ownership of its data buffer.">UniqueData()</a> to ensure safe modification without affecting other tensors that might share the data buffer. </dd></dl>

</div>
</div>
<a id="aeb8b24b1035217d354520b1aa16117e7" name="aeb8b24b1035217d354520b1aa16117e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeb8b24b1035217d354520b1aa16117e7">&#9670;&#160;</a></span>Asec()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Asec </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arcsecant (inverse secant) of each element. </p>
<p>Returns a new tensor where each element is the arcsecant of the corresponding element in the original tensor. The result is in radians.</p>
<p>The arcsecant function is only defined for values in (-, -1]  [1, ). It is computed as acos(1/x).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arcsecant values in radians.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is in the range (-1, 1), where arcsecant is undefined.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/. </dd></dl>

</div>
</div>
<a id="a5144a947b733c6ca5a5dcc5430f8df29" name="a5144a947b733c6ca5a5dcc5430f8df29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5144a947b733c6ca5a5dcc5430f8df29">&#9670;&#160;</a></span>Asech()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Asech </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic secant of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic secant of the corresponding element in the original tensor. It is computed as: asech(x) = acosh(1/x)</p>
<p>The inverse hyperbolic secant is only defined for values in the range (0, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic secant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is  0 or &gt; 1 (where asech is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="ae58831c074bbc7eec61f1ea6a1644d91" name="ae58831c074bbc7eec61f1ea6a1644d91"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae58831c074bbc7eec61f1ea6a1644d91">&#9670;&#160;</a></span>Asin()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Asin </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arcsine (inverse sine) of each element. </p>
<p>Returns a new tensor where each element is the arcsine of the corresponding element in the original tensor. The result is in radians in the range [-/2, /2].</p>
<p>The arcsine function is only defined for input values in the range [-1, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arcsine values in radians, ranging from -/2 to /2.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is outside the range [-1, 1].</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/. </dd></dl>

</div>
</div>
<a id="a7d4ff3c3c4775b55bd8fc94d9d3e4479" name="a7d4ff3c3c4775b55bd8fc94d9d3e4479"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d4ff3c3c4775b55bd8fc94d9d3e4479">&#9670;&#160;</a></span>Asinh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Asinh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic sine of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic sine (also called area hyperbolic sine) of the corresponding element in the original tensor. It is defined as: asinh(x) = ln(x + sqrt(x + 1))</p>
<p>The inverse hyperbolic sine is defined for all real numbers.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic sine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="af9cb1919c5b966567b5d7d485b24dc56" name="af9cb1919c5b966567b5d7d485b24dc56"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9cb1919c5b966567b5d7d485b24dc56">&#9670;&#160;</a></span>Atan()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Atan </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the arctangent (inverse tangent) of each element. </p>
<p>Returns a new tensor where each element is the arctangent of the corresponding element in the original tensor. The result is in radians in the range (-/2, /2).</p>
<p>The arctangent function is defined for all real numbers.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing arctangent values in radians, ranging from -/2 to /2.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The output is in radians. To convert to degrees, multiply by 180/. </dd></dl>

</div>
</div>
<a id="ad6e896aed6bc70bfe19fb1f9cd2d527d" name="ad6e896aed6bc70bfe19fb1f9cd2d527d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6e896aed6bc70bfe19fb1f9cd2d527d">&#9670;&#160;</a></span>Atanh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Atanh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the inverse hyperbolic tangent of each element. </p>
<p>Returns a new tensor where each element is the inverse hyperbolic tangent (also called area hyperbolic tangent) of the corresponding element in the original tensor. It is defined as: atanh(x) = 0.5  ln((1 + x) / (1 - x))</p>
<p>The inverse hyperbolic tangent is only defined for values in the open interval (-1, 1).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing inverse hyperbolic tangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is  -1 or  1 (where atanh is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a40fb78ab8fbcfab0ab57eeaa5c05676a" name="a40fb78ab8fbcfab0ab57eeaa5c05676a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40fb78ab8fbcfab0ab57eeaa5c05676a">&#9670;&#160;</a></span>AvgPool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::AvgPool </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>pool_shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span><span class="paramdefsep"> = </span><span class="paramdefval">{}</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs average pooling operation by computing the mean value within sliding windows. </p>
<p>Average pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the arithmetic mean (average) of all values in each region. It provides smoother downsampling compared to max pooling and is commonly used in convolutional neural networks for dimensionality reduction while preserving more global information.</p>
<p>The operation slides a window (defined by pool_shape) across the input tensor according to the specified strides, and at each position, computes the average of all values within that window to form the output.</p>
<p>The pool_shape can have a rank lower than or equal to the input tensor's rank. When the pool_shape rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>If strides is empty, it defaults to the broadcasted pool_shape, resulting in non-overlapping pooling windows (most common usage). Otherwise, strides must match the tensor's rank.</p>
<p>Mathematical formulation for each output element: </p><div class="fragment"><div class="line">output[i,j,...] = (1/N)   input[window elements]</div>
<div class="line">where N = number of elements in the pooling window</div>
</div><!-- fragment --><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pool_shape</td><td>A vector specifying the size of the pooling window for each dimension. Must have rank  this tensor's rank. Each dimension of the pool must be  the corresponding dimension of the input. All values must be positive (&gt; 0).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool_shape (non-overlapping windows). If provided, must have length equal to this tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the average-pooled result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] - pool_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The pool_shape is not compatible with the tensor (pool dimensions exceed input dimensions).</li>
<li>The strides vector is non-empty and its size does not match the tensor's rank.</li>
<li>Any stride value is non-positive ( 0).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Average pooling provides smoother gradients during backpropagation compared to max pooling, as all values in the window contribute to the output.</dd>
<dd>
The output represents the average intensity or activation level within each pooling region. </dd></dl>

</div>
</div>
<a id="aa5fba58b033578d704f4634977982c66" name="aa5fba58b033578d704f4634977982c66"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5fba58b033578d704f4634977982c66">&#9670;&#160;</a></span>Broadcast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Broadcast </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Broadcasts the tensor to a target shape following NumPy-style broadcasting rules. </p>
<p>This method expands the tensor's dimensions to match a target shape by replicating data along singleton dimensions (dimensions of size 1) and adding new leading dimensions as needed. Broadcasting allows operations between tensors of different but compatible shapes.</p>
<p>Broadcasting rules:</p><ul>
<li>Dimensions are aligned from the rightmost (trailing) dimension.</li>
<li>Two dimensions are compatible if they are equal or one of them is 1.</li>
<li>Missing leading dimensions are treated as size 1.</li>
</ul>
<p>For scalar tensors (rank 0), broadcasting simply fills the target shape with the scalar value.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>The target shape to broadcast to. Must contain only positive integers. The shape must be broadcast-compatible with the current tensor's shape.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the broadcasted shape and expanded data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The target shape is empty or contains non-positive values.</li>
<li>The tensor is empty (volume = 0).</li>
<li>The shapes are not broadcast-compatible.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a> with its own data buffer. The original tensor remains unchanged.</dd>
<dd>
For large target shapes, broadcasting can be memory-intensive as data is replicated. </dd></dl>

</div>
</div>
<a id="ac1228f81de00883e64f49ee19e7d6021" name="ac1228f81de00883e64f49ee19e7d6021"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac1228f81de00883e64f49ee19e7d6021">&#9670;&#160;</a></span>Ceil()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Ceil </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Rounds each element up to the nearest integer (ceiling function). </p>
<p>Returns a new tensor where each element is rounded up to the smallest integer greater than or equal to the original value. For example, 2.3 becomes 3, and -2.7 becomes -2.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing ceiled values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a7de1cf7ec97265fcb0f776ea47fd9236" name="a7de1cf7ec97265fcb0f776ea47fd9236"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7de1cf7ec97265fcb0f776ea47fd9236">&#9670;&#160;</a></span>Clip()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Clip </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>min_value</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>max_value</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clips (clamps) each element to be within a specified range. </p>
<p>Returns a new tensor where each element is constrained to lie within the range [min_value, max_value]. Values less than min_value are set to min_value, values greater than max_value are set to max_value, and values within the range remain unchanged.</p>
<p>This operation is useful for gradient clipping in neural networks, enforcing value bounds, and numerical stability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">min_value</td><td>The minimum allowed value. Must be finite and  max_value. </td></tr>
    <tr><td class="paramname">max_value</td><td>The maximum allowed value. Must be finite and  min_value.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing clipped values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>min_value is not finite (NaN or infinity).</li>
<li>max_value is not finite (NaN or infinity).</li>
<li>min_value &gt; max_value (invalid range).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
If min_value equals max_value, all output elements will be set to that value. </dd></dl>

</div>
</div>
<a id="a4d525a3d5051c3a704db5a254b654706" name="a4d525a3d5051c3a704db5a254b654706"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4d525a3d5051c3a704db5a254b654706">&#9670;&#160;</a></span>Concat()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Concat </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="class_tensor.html">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensors</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel static">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Concatenates multiple Tensors along a specified axis. </p>
<p>This static method joins a vector of Tensors along a given axis. All tensors must have the same rank and identical shapes along all axes except the concatenation axis. The dimension along the concatenation axis in the result equals the sum of all input tensors' dimensions along that axis.</p>
<p>If axis is -1 (default), the method automatically detects the concatenation axis by finding the dimension where shapes differ. If all shapes are identical, axis 0 is used by default.</p>
<p>The operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>; input tensors remain unchanged.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensors</td><td>A vector of Tensors to concatenate. Must not be empty. All tensors must have the same rank. Shapes must match on all axes except the concatenation axis.</td></tr>
    <tr><td class="paramname">axis</td><td>The axis along which to concatenate. Default is -1 (auto-detect). Must satisfy: <span class="tt">-1  axis &lt; rank</span>. If -1, the axis is inferred from shape differences, or defaults to 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the concatenated data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The axis is less than -1.</li>
<li>The tensors vector is empty.</li>
<li>Tensors have mismatched ranks.</li>
<li>Shapes are incompatible for concatenation along the specified axis.</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is &gt;= the tensors' rank.</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the resulting shape volume exceeds INT_MAX.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a static method - call it as <span class="tt"><a class="el" href="#a4d525a3d5051c3a704db5a254b654706" title="Concatenates multiple Tensors along a specified axis.">Tensor::Concat</a>({t1, t2, t3})</span>.</dd>
<dd>
The concatenation is performed by copying data in row-major order, using stride calculations for efficient memory layout. </dd></dl>

</div>
</div>
<a id="ae88a978596e4f4d82ca5a27b8b79073f" name="ae88a978596e4f4d82ca5a27b8b79073f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae88a978596e4f4d82ca5a27b8b79073f">&#9670;&#160;</a></span>Convolve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Convolve </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>filter</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>padding</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs N-dimensional convolution between this tensor and a filter kernel. </p>
<p>This method computes the discrete convolution of the current tensor with a given filter kernel, supporting arbitrary dimensions, custom strides, and padding.</p>
<p>The operation applies the filter kernel across the input tensor using a sliding window approach. At each position, element-wise multiplication is performed between the kernel and the corresponding input region, followed by summation to produce a single output value.</p>
<p>The filter kernel can have a rank lower than or equal to the input tensor's rank. When the filter rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>Mathematical formulation for each output element: </p><div class="fragment"><div class="line">output[i,j,...] =  input[i*stride + m, j*stride + n, ...]  kernel[m, n, ...]</div>
<div class="line">                  m,n,...</div>
</div><!-- fragment --><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">filter</td><td>The convolution kernel/filter tensor. Must have rank  this tensor's rank. Each dimension of the filter must be  the corresponding padded dimension of the input tensor (aligned from the rightmost dimension).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. Must have length equal to this tensor's rank. All values must be positive (&gt; 0). Larger strides reduce output size and computational cost. Example: {1, 1} for dense convolution, {2, 2} for downsampling.</td></tr>
    <tr><td class="paramname">padding</td><td>A vector specifying the number of zero-padding elements to add before and after each dimension. Must have length equal to this tensor's rank. All values must be non-negative ( 0). Padding controls output spatial dimensions and edge behavior. Example: {1, 1} adds one zero on each side of each dimension.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the convolution result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] + 2*padding[i] - filter_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The strides vector size does not match this tensor's rank.</li>
<li>The padding vector size does not match this tensor's rank.</li>
<li>Any stride value is non-positive ( 0).</li>
<li>Any padding value is negative (&lt; 0).</li>
<li>The filter shape is not compatible with the padded input shape (filter dimensions exceed corresponding padded input dimensions).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the padded tensor shape would cause integer overflow (total volume exceeds INT_MAX).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The convolution is computed in the spatial domain (direct method), not using FFT. For large kernels or tensors, this may be computationally expensive.</dd>
<dd>
This implements "valid" convolution semantics after padding is applied. For "same" convolution (output size = input size), set padding appropriately: <span class="tt">padding[i] = (filter_shape[i] - 1) / 2</span> for odd-sized filters with stride=1.</dd>
<dd>
The filter kernel is applied as-is without rotation. This is technically cross-correlation rather than true mathematical convolution, which is the standard convention in deep learning frameworks. </dd></dl>

</div>
</div>
<a id="a9f691219cdb0a10a8111db8573128666" name="a9f691219cdb0a10a8111db8573128666"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9f691219cdb0a10a8111db8573128666">&#9670;&#160;</a></span>Cos()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Cos </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the cosine of each element (in radians). </p>
<p>Returns a new tensor where each element is the cosine of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The cosine function maps any real number to the range [-1, 1] and is periodic with period 2.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing cosine values in the range [-1, 1].</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by /180. </dd></dl>

</div>
</div>
<a id="a65a86d44bf78501dbdcaa52ba72d7bd3" name="a65a86d44bf78501dbdcaa52ba72d7bd3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65a86d44bf78501dbdcaa52ba72d7bd3">&#9670;&#160;</a></span>Cosh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Cosh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic cosine of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic cosine of the corresponding element in the original tensor. The hyperbolic cosine is defined as: cosh(x) = (e^x + e^(-x)) / 2</p>
<p>The hyperbolic cosine function is defined for all real numbers and is an even function.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic cosine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a9cff3aed7469fd72059da70444170b41" name="a9cff3aed7469fd72059da70444170b41"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9cff3aed7469fd72059da70444170b41">&#9670;&#160;</a></span>Cot()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Cot </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the cotangent (reciprocal of tangent) of each element (in radians). </p>
<p>Returns a new tensor where each element is the cotangent (1/tan(x) or cos(x)/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The cotangent function is undefined at multiples of  (where sine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing cotangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately a multiple of  (where cotangent is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by /180. </dd></dl>

</div>
</div>
<a id="a4b4030aa4413ca8c4714526965986657" name="a4b4030aa4413ca8c4714526965986657"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4b4030aa4413ca8c4714526965986657">&#9670;&#160;</a></span>Coth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Coth </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic cotangent (reciprocal of hyperbolic tangent) of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic cotangent (1/tanh(x) or cosh(x)/sinh(x)) of the corresponding element in the original tensor.</p>
<p>The hyperbolic cotangent is undefined at zero (where sinh equals zero).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic cotangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately zero (where hyperbolic cotangent is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a0dfe79c9b87996847a2c898578c240ff" name="a0dfe79c9b87996847a2c898578c240ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0dfe79c9b87996847a2c898578c240ff">&#9670;&#160;</a></span>Csc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Csc </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the cosecant (reciprocal of sine) of each element (in radians). </p>
<p>Returns a new tensor where each element is the cosecant (1/sin(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The cosecant function is undefined at multiples of  (where sine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing cosecant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately a multiple of  (where cosecant is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by /180. </dd></dl>

</div>
</div>
<a id="a2ddab39bf92ee11ab318b3d3374b391c" name="a2ddab39bf92ee11ab318b3d3374b391c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2ddab39bf92ee11ab318b3d3374b391c">&#9670;&#160;</a></span>Csch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Csch </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic cosecant (reciprocal of hyperbolic sine) of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic cosecant (1/sinh(x)) of the corresponding element in the original tensor.</p>
<p>The hyperbolic cosecant is undefined at zero (where sinh equals zero).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic cosecant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately zero (where hyperbolic cosecant is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="ae9f79fc49610fe4ba20ade7d3cbafe30" name="ae9f79fc49610fe4ba20ade7d3cbafe30"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9f79fc49610fe4ba20ade7d3cbafe30">&#9670;&#160;</a></span>Exp()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Exp </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes e raised to the power of each element (exponential function). </p>
<p>Returns a new tensor where each element is e^x, where e  2.71828 (Euler's number) and x is the corresponding element in the original tensor. This is the inverse operation of the natural logarithm.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing exponential values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The exponential function grows very rapidly. Large input values may result in overflow (infinity).</dd>
<dd>
Special values:<ul>
<li>exp(0) = 1</li>
<li>exp(1) = e  2.71828</li>
<li>exp(ln(x)) = x </li>
</ul>
</dd></dl>

</div>
</div>
<a id="aa5215a8751f54d02e66b38c4982537f9" name="aa5215a8751f54d02e66b38c4982537f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5215a8751f54d02e66b38c4982537f9">&#9670;&#160;</a></span>ExpandRank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::ExpandRank </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Expands the rank of the <a class="el" href="class_tensor.html">Tensor</a> by inserting a dimension of size 1 at a specified axis. </p>
<p>This operation increases the <a class="el" href="class_tensor.html">Tensor</a>'s rank by 1 by inserting a new axis with dimension 1 at the specified position. The data remains unchanged; only the shape metadata is modified. This is analogous to NumPy's <span class="tt">np.expand_dims()</span> function.</p>
<p>The new dimension allows for operations such as broadcasting or stacking without modifying the underlying data. The axis parameter determines where the new dimension is inserted in the shape vector.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The position where the new dimension (of size 1) will be inserted. Must satisfy: <span class="tt">0  axis  rank</span>.<ul>
<li><span class="tt">axis = 0</span>: Insert at the beginning (becomes the new outermost dimension).</li>
<li><span class="tt">axis = rank</span>: Append at the end (becomes the new innermost dimension). Default value is 0.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with rank increased by 1 and a dimension of size 1 at the specified axis.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or greater than the current rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a> via reshaping. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
The total volume (number of elements) remains the same. </dd></dl>

</div>
</div>
<a id="ab580be2efba7d27e6b6da689eee4732e" name="ab580be2efba7d27e6b6da689eee4732e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab580be2efba7d27e6b6da689eee4732e">&#9670;&#160;</a></span>Flatten()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Flatten </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis_from</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis_upto</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Flattens a range of consecutive axes into a single dimension. </p>
<p>This operation collapses multiple consecutive dimensions between <span class="tt">axis_from</span> (inclusive) and <span class="tt">axis_upto</span> (exclusive) into a single flattened dimension. The axes before <span class="tt">axis_from</span> and after <span class="tt">axis_upto</span> remain unchanged. The resulting <a class="el" href="class_tensor.html">Tensor</a> has a reduced rank.</p>
<p>The flattened dimension's size is the product of all collapsed dimensions. The data order (row-major) remains unchanged; only the shape metadata is modified.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis_from</td><td>The starting axis index (inclusive) for flattening. Must satisfy: <span class="tt">0  axis_from &lt; axis_upto</span>.</td></tr>
    <tr><td class="paramname">axis_upto</td><td>The ending axis index (exclusive) for flattening. Must satisfy: <span class="tt">axis_from &lt; axis_upto  rank</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with reduced rank where the specified axes are flattened.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the <a class="el" href="class_tensor.html">Tensor</a> is rank-0 (scalar) or rank-1 (already flat, cannot flatten further).</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li><span class="tt">axis_from</span> is negative.</li>
<li><span class="tt">axis_upto</span> is greater than the current rank.</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if <span class="tt">axis_from &gt;= axis_upto</span> (invalid range specification).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
The total volume (number of elements) remains constant. </dd></dl>

</div>
</div>
<a id="a6ecaeb0e29c326798d82d6a2cccc28cf" name="a6ecaeb0e29c326798d82d6a2cccc28cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ecaeb0e29c326798d82d6a2cccc28cf">&#9670;&#160;</a></span>Floor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Floor </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Rounds each element down to the nearest integer (floor function). </p>
<p>Returns a new tensor where each element is rounded down to the largest integer less than or equal to the original value. For example, 2.7 becomes 2, and -2.3 becomes -3.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing floored values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="aee9562ed6e3368ac6cd664373556cca4" name="aee9562ed6e3368ac6cd664373556cca4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee9562ed6e3368ac6cd664373556cca4">&#9670;&#160;</a></span>Insert()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::Insert </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Inserts a lower-rank <a class="el" href="class_tensor.html">Tensor</a> at a specific position along an axis (in-place operation). </p>
<p>This method inserts a <a class="el" href="class_tensor.html">Tensor</a> of rank <span class="tt">n-1</span> into the current <a class="el" href="class_tensor.html">Tensor</a> of rank <span class="tt">n</span> at a specified position along a given axis. The inserted tensor must match all dimensions of the current tensor except for the insertion axis, where the dimension is increased by 1.</p>
<p>Unlike Append (which adds at the end), Insert allows placement at any valid position, including the beginning (index = 0), middle, or end (index = shape[axis]).</p>
<p>If axis is -1 (default), the method automatically determines the axis by finding the dimension mismatch between the two tensors' shapes.</p>
<p>The operation modifies the current <a class="el" href="class_tensor.html">Tensor</a> in-place by:</p><ol type="1">
<li>Ensuring unique data ownership (calls <a class="el" href="#ac9b2a793615586ac29b2e7215261b844" title="Ensures this Tensor has unique ownership of its data buffer.">UniqueData()</a>).</li>
<li>Interleaving data: elements before insertion, inserted tensor, elements after insertion.</li>
<li>Updating shape, strides, and volume metadata.</li>
</ol>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The <a class="el" href="class_tensor.html">Tensor</a> to insert. Must have rank = <span class="tt">this-&gt;rank - 1</span>. All dimensions except the insertion axis must match the current tensor's shape.</td></tr>
    <tr><td class="paramname">axis</td><td>The axis along which to insert. Default is -1 (auto-detect). Must satisfy: <span class="tt">-1  axis &lt; rank</span>. If -1, the axis is inferred from the shape mismatch.</td></tr>
    <tr><td class="paramname">index</td><td>The position along the axis where the tensor will be inserted. Must satisfy: <span class="tt">0  index  shape[axis]</span>.<ul>
<li>index = 0: Insert at the beginning.</li>
<li>index = shape[axis]: Insert at the end (equivalent to Append).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li>The axis is less than -1 or &gt;= rank.</li>
<li>The index is negative or &gt; shape[axis].</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The tensor's rank is not exactly <span class="tt">rank - 1</span>.</li>
<li>The shapes are not compatible for insertion along the specified axis.</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the resulting shape volume exceeds INT_MAX.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an <b>in-place operation</b> that modifies the current <a class="el" href="class_tensor.html">Tensor</a>. The original data is replaced with the merged result.</dd>
<dd>
This method calls <a class="el" href="#ac9b2a793615586ac29b2e7215261b844" title="Ensures this Tensor has unique ownership of its data buffer.">UniqueData()</a> to ensure safe modification without affecting other tensors that might share the data buffer. </dd></dl>

</div>
</div>
<a id="a767884250837a4894e6d8b592a9d3450" name="a767884250837a4894e6d8b592a9d3450"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a767884250837a4894e6d8b592a9d3450">&#9670;&#160;</a></span>IsEmpty()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool Tensor::IsEmpty </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Checks whether the tensor contains no elements. </p>
<p>A tensor is considered empty if its volume (total number of elements) is zero. This can occur when any dimension in the shape is zero.</p>
<dl class="section return"><dt>Returns</dt><dd>true if the tensor has zero elements (volume = 0), false otherwise.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>An empty tensor is different from a scalar tensor.<ul>
<li>Empty: volume = 0, no data stored</li>
<li>Scalar: volume = 1, single value stored </li>
</ul>
</dd></dl>

</div>
</div>
<a id="a203a74ae4428ecadfd1efbebd85d753d" name="a203a74ae4428ecadfd1efbebd85d753d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a203a74ae4428ecadfd1efbebd85d753d">&#9670;&#160;</a></span>IsScalar()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool Tensor::IsScalar </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Checks whether the tensor represents a scalar (single) value. </p>
<p>A tensor is considered scalar if it has rank 0 (empty shape) and contains exactly one element. Scalar tensors represent single numerical values.</p>
<dl class="section return"><dt>Returns</dt><dd>true if the tensor is a scalar (rank 0 and volume 1), false otherwise.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>A scalar tensor has:<ul>
<li>Empty shape: shape = {}</li>
<li>Volume of 1: exactly one element</li>
<li>Rank of 0: zero dimensions </li>
</ul>
</dd></dl>

</div>
</div>
<a id="a40481e1178fdb80dae8934a8ed75adbb" name="a40481e1178fdb80dae8934a8ed75adbb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40481e1178fdb80dae8934a8ed75adbb">&#9670;&#160;</a></span>Log()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Log </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>base</em></span><span class="paramdefsep"> = </span><span class="paramdefval">std::numbers::e</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the logarithm of each element with a specified base. </p>
<p>Returns a new tensor where each element is the logarithm (base-b) of the corresponding element in the original tensor. The operation computes log_b(x) for each element x.</p>
<p>Uses the change of base formula: log_b(x) = ln(x) / ln(b)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">base</td><td>The logarithm base. Must be positive (&gt; 0) and not equal to 1. Common values: e  2.71828 (natural log), 10 (common log), 2 (binary log). Default is e (natural logarithm).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing logarithm values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if:<ul>
<li>The base is zero, negative, or approximately zero.</li>
<li>The base is 1 (logarithm base 1 is undefined).</li>
<li>Any element is zero, negative, or approximately zero (log undefined for non-positive values).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Special values:<ul>
<li>log_b(1) = 0 for any valid base b</li>
<li>log_b(b) = 1</li>
<li>log_b(b^n) = n </li>
</ul>
</dd></dl>

</div>
</div>
<a id="a0adf81cbee9f45641c9c3bd70ec5c2b4" name="a0adf81cbee9f45641c9c3bd70ec5c2b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0adf81cbee9f45641c9c3bd70ec5c2b4">&#9670;&#160;</a></span>MatMul() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::MatMul </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication with another tensor. </p>
<p>Convenience method that calls the static MatMul function. Equivalent to: Tensor::MatMul(*this, other)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The right operand tensor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the matrix multiplication result.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#a33ee78056cb83d4381fdcbe3c79cde96" title="Performs matrix multiplication between two tensors with automatic broadcasting.">MatMul(const Tensor&amp;, const Tensor&amp;)</a> </dd></dl>

</div>
</div>
<a id="a33ee78056cb83d4381fdcbe3c79cde96" name="a33ee78056cb83d4381fdcbe3c79cde96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33ee78056cb83d4381fdcbe3c79cde96">&#9670;&#160;</a></span>MatMul() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::MatMul </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor_1</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor_2</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel static">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs matrix multiplication between two tensors with automatic broadcasting. </p>
<p>This static method implements batched matrix multiplication following NumPy-style broadcasting rules. It handles vectors (rank-1), matrices (rank-2), and higher-dimensional tensors by treating the last two dimensions as matrix dimensions and broadcasting over batch dimensions.</p>
<p>Rank-1 tensors (vectors) are automatically expanded:</p><ul>
<li>Left vector: (n,)  (1, n)</li>
<li>Right vector: (n,)  (n, 1)</li>
</ul>
<p>For higher-rank tensors, the last two dimensions are treated as matrix dimensions, and earlier dimensions are treated as batch dimensions that are broadcast together.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor_1</td><td>The left operand tensor. Must have rank  1. </td></tr>
    <tr><td class="paramname">tensor_2</td><td>The right operand tensor. Must have rank  1.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the matrix multiplication result.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>Either tensor has rank 0 (scalar).</li>
<li>Inner matrix dimensions don't match (tensor_1's last dim  tensor_2's second-to-last dim).</li>
<li>Batch dimensions are not broadcast-compatible.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Input tensors remain unchanged.</dd>
<dd>
Broadcasting rules apply only to batch dimensions (all dimensions except the last two). Matrix dimensions must satisfy the standard matrix multiplication constraint. </dd></dl>

</div>
</div>
<a id="a46e3d36946b41f93fef4b0edcc48ba2e" name="a46e3d36946b41f93fef4b0edcc48ba2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46e3d36946b41f93fef4b0edcc48ba2e">&#9670;&#160;</a></span>Max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Tensor::Max </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Finds the maximum value in the tensor. </p>
<p>Returns the largest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The maximum element value.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad378cc1c1af81074204c05bc0ff4f00d" name="ad378cc1c1af81074204c05bc0ff4f00d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad378cc1c1af81074204c05bc0ff4f00d">&#9670;&#160;</a></span>MaxPool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::MaxPool </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>pool_shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span><span class="paramdefsep"> = </span><span class="paramdefval">{}</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs max pooling operation by taking the maximum value within sliding windows. </p>
<p>Max pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the maximum value in each region. It is commonly used in convolutional neural networks for spatial dimensionality reduction, feature extraction, and translation invariance.</p>
<p>The operation slides a window (defined by pool_shape) across the input tensor according to the specified strides, and at each position, selects the maximum value within that window to form the output.</p>
<p>The pool_shape can have a rank lower than or equal to the input tensor's rank. When the pool_shape rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>If strides is empty, it defaults to the broadcasted pool_shape, resulting in non-overlapping pooling windows (most common usage). Otherwise, strides must match the tensor's rank.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pool_shape</td><td>A vector specifying the size of the pooling window for each dimension. Must have rank  this tensor's rank. Each dimension of the pool must be  the corresponding dimension of the input. All values must be positive (&gt; 0).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool_shape (non-overlapping windows). If provided, must have length equal to this tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the max-pooled result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] - pool_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The pool_shape is not compatible with the tensor (pool dimensions exceed input dimensions).</li>
<li>The strides vector is non-empty and its size does not match the tensor's rank.</li>
<li>Any stride value is non-positive ( 0).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Max pooling provides translation invariance and is robust to small spatial shifts in the input features, making it popular in computer vision tasks.</dd>
<dd>
The output captures the most prominent features within each pooling region. </dd></dl>

</div>
</div>
<a id="aac4651bb52521e86e875d2e8c1e8643a" name="aac4651bb52521e86e875d2e8c1e8643a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac4651bb52521e86e875d2e8c1e8643a">&#9670;&#160;</a></span>Mean()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Tensor::Mean </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the mean (average) of all elements in the tensor. </p>
<p>Returns the arithmetic mean of all elements as a scalar value. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The mean of all elements.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Formula: Mean = Sum / Volume </dd></dl>

</div>
</div>
<a id="a759daa212e3786fda070af4732f3ee15" name="a759daa212e3786fda070af4732f3ee15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a759daa212e3786fda070af4732f3ee15">&#9670;&#160;</a></span>Min()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Tensor::Min </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Finds the minimum value in the tensor. </p>
<p>Returns the smallest element value in the tensor as a scalar. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The minimum element value.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad1f64c43e7267629a150a2cc7d7ad75b" name="ad1f64c43e7267629a150a2cc7d7ad75b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1f64c43e7267629a150a2cc7d7ad75b">&#9670;&#160;</a></span>MinPool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::MinPool </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>pool_shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>strides</em></span><span class="paramdefsep"> = </span><span class="paramdefval">{}</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs min pooling operation by taking the minimum value within sliding windows. </p>
<p>Min pooling is a downsampling technique that partitions the input tensor into pooling regions and computes the minimum value in each region. While less common than max pooling, it can be useful in specific applications where detecting the lowest activation or darkest features is important, such as certain image processing tasks or anomaly detection.</p>
<p>The operation slides a window (defined by pool_shape) across the input tensor according to the specified strides, and at each position, selects the minimum value within that window to form the output.</p>
<p>The pool_shape can have a rank lower than or equal to the input tensor's rank. When the pool_shape rank is lower, it is automatically broadcast to match the input tensor's rank by prepending dimensions of size 1.</p>
<p>If strides is empty, it defaults to the broadcasted pool_shape, resulting in non-overlapping pooling windows (most common usage). Otherwise, strides must match the tensor's rank.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pool_shape</td><td>A vector specifying the size of the pooling window for each dimension. Must have rank  this tensor's rank. Each dimension of the pool must be  the corresponding dimension of the input. All values must be positive (&gt; 0).</td></tr>
    <tr><td class="paramname">strides</td><td>A vector specifying the stride (step size) for each dimension. If empty (default), strides are set equal to the broadcasted pool_shape (non-overlapping windows). If provided, must have length equal to this tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing the min-pooled result with shape computed as: <span class="tt">output_shape[i] = ((input_shape[i] - pool_shape[i]) / strides[i]) + 1</span> for each dimension i.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The pool_shape is not compatible with the tensor (pool dimensions exceed input dimensions).</li>
<li>The strides vector is non-empty and its size does not match the tensor's rank.</li>
<li>Any stride value is non-positive ( 0).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Min pooling is sensitive to the smallest values in each region, making it useful for detecting low-intensity features or for applications requiring conservative feature selection.</dd>
<dd>
The output captures the least prominent (minimum) features within each pooling region. </dd></dl>

</div>
</div>
<a id="aafd911eab8af5c4ec79593d67f7823df" name="aafd911eab8af5c4ec79593d67f7823df"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aafd911eab8af5c4ec79593d67f7823df">&#9670;&#160;</a></span>Mod()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Mod </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>mod_value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the modulus (remainder) of each element divided by a value. </p>
<p>Returns a new tensor where each element is the remainder of dividing the corresponding element by the specified modulus value. Uses the fmod function which computes the floating-point remainder of the division.</p>
<p>The result has the same sign as the dividend (the tensor element).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mod_value</td><td>The divisor for the modulus operation. Must be non-zero.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing modulus values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if mod_value is approximately zero (division by zero).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The result sign follows the dividend: fmod(-5, 3) = -2, fmod(5, -3) = 2 </dd></dl>

</div>
</div>
<a id="a75728ffb3911510ebfb73c113d97f7ec" name="a75728ffb3911510ebfb73c113d97f7ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a75728ffb3911510ebfb73c113d97f7ec">&#9670;&#160;</a></span>operator*() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator* </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise multiplication of two tensors (Hadamard product). </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the product of corresponding elements from both tensors. If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<p>This is element-wise multiplication (Hadamard product), NOT matrix multiplication.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to multiply with. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise products with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd>
<dd>
This is NOT matrix multiplication. For matrix multiplication, use a separate MatMul method. </dd></dl>

</div>
</div>
<a id="a6658b84a8e2b71220c7f55f8610e6bbe" name="a6658b84a8e2b71220c7f55f8610e6bbe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6658b84a8e2b71220c7f55f8610e6bbe">&#9670;&#160;</a></span>operator*() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator* </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise multiplication of all tensor elements by a scalar value. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the product of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise products.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a93f7554458d7ae9a3cad5dc76eb07027" name="a93f7554458d7ae9a3cad5dc76eb07027"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a93f7554458d7ae9a3cad5dc76eb07027">&#9670;&#160;</a></span>operator*=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator*= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise multiplication with another tensor (Hadamard product). </p>
<p>Multiplies this tensor with the given tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>This is element-wise multiplication (Hadamard product), NOT matrix multiplication.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to multiply with. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
This is NOT matrix multiplication. For matrix multiplication, use a separate MatMul method. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A * B;</span> </dd></dl>

</div>
</div>
<a id="a81868ded9686e9083f30666e68fdef6e" name="a81868ded9686e9083f30666e68fdef6e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a81868ded9686e9083f30666e68fdef6e">&#9670;&#160;</a></span>operator*=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator*= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise multiplication by a scalar value. </p>
<p>Multiplies all elements of this tensor by the scalar value in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to multiply each element by. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A * value;</span> </dd></dl>

</div>
</div>
<a id="a6bee0bb8cea232b7f2a589e8d48a4d27" name="a6bee0bb8cea232b7f2a589e8d48a4d27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6bee0bb8cea232b7f2a589e8d48a4d27">&#9670;&#160;</a></span>operator+() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator+ </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise addition of two tensors. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the sum of corresponding elements from both tensors. If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<p>Broadcasting allows operations between tensors of different but compatible shapes by automatically expanding dimensions where needed.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to add. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise sums with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd></dl>

</div>
</div>
<a id="a47812d7a29b100dd87bcd67e91c64482" name="a47812d7a29b100dd87bcd67e91c64482"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47812d7a29b100dd87bcd67e91c64482">&#9670;&#160;</a></span>operator+() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator+ </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise addition of a scalar value to all tensor elements. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the sum of the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to add to each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise sums.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a634382ed2b871ed0476b7207cdbbbe15" name="a634382ed2b871ed0476b7207cdbbbe15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a634382ed2b871ed0476b7207cdbbbe15">&#9670;&#160;</a></span>operator+=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator+= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise addition with another tensor. </p>
<p>Adds the given tensor to this tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to add. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A + B;</span> </dd></dl>

</div>
</div>
<a id="a45a758479b01bfce56ca3c7bede0493b" name="a45a758479b01bfce56ca3c7bede0493b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45a758479b01bfce56ca3c7bede0493b">&#9670;&#160;</a></span>operator+=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator+= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise addition of a scalar value. </p>
<p>Adds the scalar value to all elements of this tensor in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to add to each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A + value;</span> </dd></dl>

</div>
</div>
<a id="aef9ba3fe1189eb11d47cd8f1dd573a1b" name="aef9ba3fe1189eb11d47cd8f1dd573a1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef9ba3fe1189eb11d47cd8f1dd573a1b">&#9670;&#160;</a></span>operator-() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator- </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise subtraction of two tensors. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the difference between corresponding elements from both tensors (this - tensor). If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to subtract. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise differences with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd>
<dd>
Order matters: A - B  B - A </dd></dl>

</div>
</div>
<a id="aaab66abb66d3aa8ac54b985cade60f7e" name="aaab66abb66d3aa8ac54b985cade60f7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaab66abb66d3aa8ac54b985cade60f7e">&#9670;&#160;</a></span>operator-() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator- </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise subtraction of a scalar value from all tensor elements. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the difference between the corresponding element in this tensor and the scalar value. The operation is broadcast across all elements.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise differences.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a609462c373a6263269bfec6c305b38c3" name="a609462c373a6263269bfec6c305b38c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a609462c373a6263269bfec6c305b38c3">&#9670;&#160;</a></span>operator-=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator-= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise subtraction with another tensor. </p>
<p>Subtracts the given tensor from this tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to subtract. Must be non-empty and broadcast-compatible.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A - B;</span> </dd></dl>

</div>
</div>
<a id="a7e6db16f013c048474b050fda7da2a01" name="a7e6db16f013c048474b050fda7da2a01"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7e6db16f013c048474b050fda7da2a01">&#9670;&#160;</a></span>operator-=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator-= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise subtraction of a scalar value. </p>
<p>Subtracts the scalar value from all elements of this tensor in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar value to subtract from each element. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A - value;</span> </dd></dl>

</div>
</div>
<a id="a4a881f8f18dbbb2aa29aeec5f81ec018" name="a4a881f8f18dbbb2aa29aeec5f81ec018"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a881f8f18dbbb2aa29aeec5f81ec018">&#9670;&#160;</a></span>operator/() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator/ </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise division of two tensors. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the quotient of corresponding elements from both tensors (this / tensor). If the shapes don't match, automatic broadcasting is applied following NumPy-style broadcasting rules.</p>
<p>Division by elements close to zero (|value| &lt; epsilon * EPSILON_SCALE) is detected and throws an exception to prevent numerical instability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The divisor tensor. Must be non-empty, broadcast-compatible, and contain no near-zero values.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing element-wise quotients with the broadcasted shape.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element in the divisor tensor is close to zero (|value| &lt; epsilon * EPSILON_SCALE).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Both input tensors remain unchanged. </dd>
<dd>
Automatic broadcasting may create temporary copies for shape alignment. </dd>
<dd>
Order matters: A / B  B / A </dd>
<dd>
Division-by-zero check is performed for each element individually during iteration. </dd></dl>

</div>
</div>
<a id="ac7a5df6dc6c7857650e0adbf66b4c422" name="ac7a5df6dc6c7857650e0adbf66b4c422"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7a5df6dc6c7857650e0adbf66b4c422">&#9670;&#160;</a></span>operator/() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator/ </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Element-wise division of all tensor elements by a scalar value. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> where each element is the quotient of the corresponding element in this tensor divided by the scalar value. The operation is broadcast across all elements.</p>
<p>Division by values very close to zero (|value| &lt; 1e-9) is treated as division by zero to prevent numerical instability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape, containing element-wise quotients.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity. </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if the absolute value of the divisor is less than epsilon  EPSILON_SCALE (division by ~zero).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The threshold 1e-9 is used to detect near-zero values and prevent numerical errors. </dd></dl>

</div>
</div>
<a id="a21809015e47552d25e7330bd0707cb1d" name="a21809015e47552d25e7330bd0707cb1d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a21809015e47552d25e7330bd0707cb1d">&#9670;&#160;</a></span>operator/=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator/= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise division by another tensor. </p>
<p>Divides this tensor by the given tensor element-wise, modifying this tensor in-place. If the shapes don't match, this tensor is first broadcast to match the resulting shape, and the other tensor is broadcast as needed.</p>
<p>Division by elements close to zero (|value| &lt; epsilon  EPSILON_SCALE) is detected and throws an exception to prevent numerical instability.</p>
<p>The operation modifies the underlying data directly. If this tensor shares its data buffer with other tensors, all will see the changes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The divisor tensor. Must be non-empty, broadcast-compatible, and contain no near-zero values.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if either tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the shapes are not broadcast-compatible (thrown by Broadcast method). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element in the divisor tensor is close to zero (|value| &lt; epsilon  EPSILON_SCALE).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that may change the tensor's shape via broadcasting. </dd>
<dd>
If shapes differ, this tensor is reassigned to the broadcast result. </dd>
<dd>
Division-by-zero check is performed for each element individually during iteration. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> C = A / B;</span> </dd></dl>

</div>
</div>
<a id="a513698bd5959d9c531849c91ef8c4c6a" name="a513698bd5959d9c531849c91ef8c4c6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a513698bd5959d9c531849c91ef8c4c6a">&#9670;&#160;</a></span>operator/=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::operator/= </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>In-place element-wise division by a scalar value. </p>
<p>Divides all elements of this tensor by the scalar value in-place, modifying the tensor directly. If this tensor shares its data buffer with other tensors (via shared_ptr), all tensors sharing the same data will see the changes.</p>
<p>Division by values very close to zero (|value| &lt; epsilon  EPSILON_SCALE) is treated as division by zero to prevent numerical instability.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The scalar divisor. Must be a finite number (not NaN or infinity) and not close to zero.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if the value is NaN or infinity. </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if the absolute value of the divisor is less than epsilon  EPSILON_SCALE (division by ~zero).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is an in-place operation that modifies the underlying data directly. </dd>
<dd>
If multiple tensors share this data buffer, all will be affected. To create an independent result, use the non-modifying operator: <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> B = A / value;</span> </dd></dl>

</div>
</div>
<a id="a0b7d70c72543fd055cdb101b73cec827" name="a0b7d70c72543fd055cdb101b73cec827"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b7d70c72543fd055cdb101b73cec827">&#9670;&#160;</a></span>operator=()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Assignment operator (deep copy semantics). </p>
<p>Assigns the contents of another <a class="el" href="class_tensor.html">Tensor</a> to the current <a class="el" href="class_tensor.html">Tensor</a> by performing a deep copy. The right-hand side tensor is copied completely, including all metadata (rank, shape, strides) and data. The resulting tensors are completely independent  modifying one does not affect the other.</p>
<p>If the right-hand side tensor represents a data range from a larger buffer, only the relevant data range [start, end) is copied into the new buffer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">T</td><td>The source <a class="el" href="class_tensor.html">Tensor</a> to assign from.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the current <a class="el" href="class_tensor.html">Tensor</a> (*this), allowing assignment chaining.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>This operator performs a deep copy, which can be expensive for large tensors in terms of both time and memory. Each assignment allocates a new data buffer.</dd>
<dd>
Self-assignment (e.g., <span class="tt">A = A;</span>) is detected and handled efficiently with no unnecessary copying.</dd>
<dd>
After assignment, the tensor always has <span class="tt">start = 0</span> and <span class="tt">end = volume</span>, representing a complete, non-sliced tensor. </dd></dl>

</div>
</div>
<a id="a039914aee51bfae847dbe28209ad69ff" name="a039914aee51bfae847dbe28209ad69ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a039914aee51bfae847dbe28209ad69ff">&#9670;&#160;</a></span>operator[]() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor_slice.html">TensorSlice</a> Tensor::operator[] </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns a proxy object for accessing and modifying a slice along the first dimension. </p>
<p>This operator indexes the <a class="el" href="class_tensor.html">Tensor</a> along the first dimension (axis 0) and returns a <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> proxy object. The proxy enables two key behaviors:</p>
<ol type="1">
<li><b>Independent copy on conversion</b>: When converted to a <a class="el" href="class_tensor.html">Tensor</a> (e.g., <span class="tt"><a class="el" href="class_tensor.html">Tensor</a> t = A[i];</span>), it creates an independent copy of the slice data.</li>
<li><b>Modification of the original</b>: When assigned to (e.g., <span class="tt">A[i] = other_tensor;</span>), the assignment modifies the original <a class="el" href="class_tensor.html">Tensor</a> at that index.</li>
</ol>
<p>The proxy also supports chaining of index operations (e.g., <span class="tt">A[i][j][k] = value;</span>) through its own <span class="tt">operator[]</span> methods.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The zero-based index along the first dimension. Must satisfy: <span class="tt">0 ? index &lt; shape[0]</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> proxy object that references this <a class="el" href="class_tensor.html">Tensor</a> and the given index.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the <a class="el" href="class_tensor.html">Tensor</a> is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the index is negative or &gt;= shape[0].</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operator uses the proxy pattern to enable both copy and reference semantics. Chaining is supported: <span class="tt">A[i][j][k]</span> creates nested proxies with index chains. </dd></dl>

</div>
</div>
<a id="a63f36d923fe1a8bdfa5127dcdb606b35" name="a63f36d923fe1a8bdfa5127dcdb606b35"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63f36d923fe1a8bdfa5127dcdb606b35">&#9670;&#160;</a></span>operator[]() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::operator[] </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns an independent copy of a slice along the first dimension (const version). </p>
<p>This const-qualified operator indexes a const <a class="el" href="class_tensor.html">Tensor</a> along the first dimension and returns an independent copy of the slice as a new <a class="el" href="class_tensor.html">Tensor</a>. Since this is a const operation, only read-only access is possible, and modifications to the returned <a class="el" href="class_tensor.html">Tensor</a> do not affect the original.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The zero-based index along the first dimension. Must satisfy: <span class="tt">0 ? index &lt; shape[0]</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> containing an independent copy of the slice data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the <a class="el" href="class_tensor.html">Tensor</a> is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the index is negative or &gt;= shape[0].</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This returns a complete <a class="el" href="class_tensor.html">Tensor</a>, not a proxy. The returned <a class="el" href="class_tensor.html">Tensor</a> is always independent with its own data buffer.</dd>
<dd>
Chaining is supported on const tensors: <span class="tt">const_A[i][j][k]</span> returns a <a class="el" href="class_tensor.html">Tensor</a>. </dd></dl>

</div>
</div>
<a id="af7dda240cea62631125c2272e38ffaa1" name="af7dda240cea62631125c2272e38ffaa1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af7dda240cea62631125c2272e38ffaa1">&#9670;&#160;</a></span>Pad()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Pad </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>pad_before_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>pad_after_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>value</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.0</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Adds padding elements before and/or after the tensor along a specified axis. </p>
<p>This method creates a new <a class="el" href="class_tensor.html">Tensor</a> with additional elements (padding) inserted before and after the original data along the specified axis. The padding elements are filled with a constant value (default is 0.0).</p>
<p>The resulting tensor has the same rank but an increased dimension along the padded axis: <span class="tt">new_shape[axis] = original_shape[axis] + pad_before_size + pad_after_size</span>.</p>
<p>This operation is commonly used in convolutional neural networks, signal processing, and boundary handling in various algorithms.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to add padding. Must satisfy: <span class="tt">0  axis &lt; rank</span>.</td></tr>
    <tr><td class="paramname">pad_before_size</td><td>The number of padding elements to add before the data along the axis. Must be non-negative ( 0).</td></tr>
    <tr><td class="paramname">pad_after_size</td><td>The number of padding elements to add after the data along the axis. Must be non-negative ( 0).</td></tr>
    <tr><td class="paramname">value</td><td>The constant value to fill the padding elements with. Default is 0.0. Must be a finite number (not NaN or infinity).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with padding added along the specified axis.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if pad_before_size or pad_after_size is negative.</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if the resulting shape volume exceeds INT_MAX.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
If both pad_before_size and pad_after_size are 0, the returned tensor is a copy of the original.</dd>
<dd>
Internally, this method uses Concat to join padding tensors with the original data. </dd></dl>

</div>
</div>
<a id="a0bb8eea690681cb13ffbe53fa66d7183" name="a0bb8eea690681cb13ffbe53fa66d7183"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0bb8eea690681cb13ffbe53fa66d7183">&#9670;&#160;</a></span>Power()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Power </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>exponent</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Raises each element to a specified power (exponentiation). </p>
<p>Returns a new tensor where each element is raised to the given exponent. The operation computes x^exponent for each element x.</p>
<p>For negative bases with non-integer exponents, the result would be a complex number, so an exception is thrown to maintain real number semantics.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">exponent</td><td>The power to raise each element to. Can be any real number.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing the results of exponentiation.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is negative and the exponent is non-integer (would result in a complex number).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
Special cases:<ul>
<li>x^0 = 1 for any x (including 0)</li>
<li>x^1 = x</li>
<li>0^n = 0 for positive n </li>
</ul>
</dd></dl>

</div>
</div>
<a id="a5e012653a230fcafd531ac6063e0067a" name="a5e012653a230fcafd531ac6063e0067a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e012653a230fcafd531ac6063e0067a">&#9670;&#160;</a></span>Print()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::Print </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>depth</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Prints the tensor contents to standard output in a readable, nested format. </p>
<p>This method displays the tensor's structure and values in a NumPy-like format with appropriate indentation for multi-dimensional tensors. It recursively prints nested structures, making it easy to visualize the tensor's shape and data.</p>
<p>Special cases:</p><ul>
<li>Empty tensors are printed as <span class="tt">[]</span></li>
<li>Scalar tensors print the single value directly</li>
<li>Multi-dimensional tensors use nested brackets with indentation</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">depth</td><td>Internal indentation level used during recursive printing. This parameter is automatically managed and should not be modified by users. Default is 0 (no indentation).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This method is primarily intended for debugging and inspection. For programmatic string representation, consider implementing a ToString() method.</dd>
<dd>
The output format includes:<ul>
<li>Newlines and indentation for readability in multi-dimensional tensors</li>
<li>Commas between elements</li>
<li>Nested brackets representing each dimension</li>
</ul>
</dd>
<dd>
This method uses the const indexing operator <span class="tt">[]</span> internally, which triggers the conversion from <a class="el" href="class_tensor_slice.html" title="Proxy class for tensor indexing that enables both copy and reference semantics.">TensorSlice</a> to <a class="el" href="class_tensor.html">Tensor</a>, creating temporary copies during recursion. </dd></dl>

</div>
</div>
<a id="ae00c340a459f86d5053466a73ef210e4" name="ae00c340a459f86d5053466a73ef210e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae00c340a459f86d5053466a73ef210e4">&#9670;&#160;</a></span>Rank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Tensor::Rank </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the rank (number of dimensions) of the tensor. </p>
<p>The rank represents the number of axes or dimensions in the tensor. For example, a scalar has rank 0, a vector has rank 1, a matrix has rank 2, etc.</p>
<dl class="section return"><dt>Returns</dt><dd>The rank of the tensor as an integer.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>A scalar tensor (single value) has rank 0. </dd>
<dd>
An empty tensor also reports its rank correctly based on its shape. </dd></dl>

</div>
</div>
<a id="a4f4b299f874a72509a053c270bbb0aa9" name="a4f4b299f874a72509a053c270bbb0aa9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f4b299f874a72509a053c270bbb0aa9">&#9670;&#160;</a></span>ReduceMax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::ReduceMax </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the maximum. </p>
<p>Finds the maximum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to find the maximum. Must satisfy: 0  axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing maximum values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd></dl>

</div>
</div>
<a id="a279fd0fb9be2315140b21feeb2e51034" name="a279fd0fb9be2315140b21feeb2e51034"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a279fd0fb9be2315140b21feeb2e51034">&#9670;&#160;</a></span>ReduceMean()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::ReduceMean </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the mean (average). </p>
<p>Computes the arithmetic mean of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to compute the mean. Must satisfy: 0  axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing means.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd>
<dd>
Implemented as ReduceSum(axis) / size. </dd></dl>

</div>
</div>
<a id="a3e92b91cfe84cfd666751d7f5431a642" name="a3e92b91cfe84cfd666751d7f5431a642"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e92b91cfe84cfd666751d7f5431a642">&#9670;&#160;</a></span>ReduceMin()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::ReduceMin </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the minimum. </p>
<p>Finds the minimum value along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to find the minimum. Must satisfy: 0  axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing minimum values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd></dl>

</div>
</div>
<a id="a34014716594913b10f8c606c0b0389de" name="a34014716594913b10f8c606c0b0389de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34014716594913b10f8c606c0b0389de">&#9670;&#160;</a></span>ReduceSum()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::ReduceSum </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the sum. </p>
<p>Computes the sum of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to compute the sum. Must satisfy: 0  axis &lt; rank. Default is 0.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing sums.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd></dl>

</div>
</div>
<a id="aa5366dcad0b31362b2c4a42c7452adcf" name="aa5366dcad0b31362b2c4a42c7452adcf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5366dcad0b31362b2c4a42c7452adcf">&#9670;&#160;</a></span>ReduceVar()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::ReduceVar </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>inference</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reduces the tensor along a specified axis by computing the variance. </p>
<p>Computes the variance of elements along the given axis, returning a tensor with that axis removed. The resulting tensor has rank reduced by 1.</p>
<p>Variance measures how spread out the values are from their mean.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to compute the variance. Must satisfy: 0  axis &lt; rank. Default is 0. </td></tr>
    <tr><td class="paramname">inference</td><td>If true, uses Bessel's correction (divides by n-1 for sample variance). If false, divides by n (population variance). Default is false.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified axis removed, containing variances.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is rank-0 (scalar) or empty. </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if the axis is negative or &gt;= rank.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. </dd>
<dd>
Formula: Var = sum((x - mean)) / n (or n-1 if inference=true) </dd></dl>

</div>
</div>
<a id="a50ffbfbb2e300be5346c894226d72812" name="a50ffbfbb2e300be5346c894226d72812"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50ffbfbb2e300be5346c894226d72812">&#9670;&#160;</a></span>Reshape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Reshape </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>new_shape</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reshapes the <a class="el" href="class_tensor.html">Tensor</a> to a new specified shape without changing data order. </p>
<p>Creates a new <a class="el" href="class_tensor.html">Tensor</a> with the given shape, containing the same data elements in the same row-major order. The total number of elements (volume) must remain constant. This operation does not reorder or modify the data; it only changes how the flat data is interpreted dimensionally.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_shape</td><td>A vector of positive integers representing the desired dimensions. All dimensions must be greater than 0. The product of all dimensions must equal the current volume.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the specified shape and the same data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The new_shape contains any non-positive dimensions (i.e., any dimension ? 0).</li>
<li>The volume implied by new_shape does not match the current <a class="el" href="class_tensor.html">Tensor</a>'s volume.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
Only the shape metadata changes; data is copied but not reordered. </dd></dl>

</div>
</div>
<a id="a0f50736794c3594411fe96aeb337b7b5" name="a0f50736794c3594411fe96aeb337b7b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f50736794c3594411fe96aeb337b7b5">&#9670;&#160;</a></span>Round()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Round </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>decimal_place</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Rounds each element to a specified number of decimal places. </p>
<p>Returns a new tensor where each element is rounded to the nearest value with the specified number of decimal places. Uses standard rounding rules (round half to even / banker's rounding).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">decimal_place</td><td>The number of decimal places to round to. Must be non-negative ( 0). Default is 0 (round to nearest integer).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing rounded values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if decimal_place is negative (&lt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a85eaa3e12b1a044e82d5f5912460aee8" name="a85eaa3e12b1a044e82d5f5912460aee8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85eaa3e12b1a044e82d5f5912460aee8">&#9670;&#160;</a></span>Sec()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Sec </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the secant (reciprocal of cosine) of each element (in radians). </p>
<p>Returns a new tensor where each element is the secant (1/cos(x)) of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The secant function is undefined at odd multiples of /2 (where cosine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing secant values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately an odd multiple of /2 (where secant is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by /180. </dd></dl>

</div>
</div>
<a id="a03d0593a8715bad32098cbda433451f1" name="a03d0593a8715bad32098cbda433451f1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03d0593a8715bad32098cbda433451f1">&#9670;&#160;</a></span>Sech()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Sech </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic secant (reciprocal of hyperbolic cosine) of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic secant (1/cosh(x)) of the corresponding element in the original tensor.</p>
<p>The hyperbolic secant is always positive and has range (0, 1].</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic secant values in the range (0, 1].</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if numerical instability is detected (extremely rare).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="adb8cd0e538a8410157ca2a17a5055f02" name="adb8cd0e538a8410157ca2a17a5055f02"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb8cd0e538a8410157ca2a17a5055f02">&#9670;&#160;</a></span>Shape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; int &gt; Tensor::Shape </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the shape of the tensor as a vector of dimension sizes. </p>
<p>The shape describes the size of each dimension in the tensor. For example, shape {2, 3, 4} represents a 3D tensor with 2 slices, each containing a 34 matrix.</p>
<dl class="section return"><dt>Returns</dt><dd>A vector of integers representing the size of each dimension.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>For a scalar tensor (rank 0), this returns an empty vector. </dd>
<dd>
The returned vector is a copy; modifying it does not affect the tensor. </dd></dl>

</div>
</div>
<a id="af2642442d55d275a7a21fca2e3dfb4b5" name="af2642442d55d275a7a21fca2e3dfb4b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2642442d55d275a7a21fca2e3dfb4b5">&#9670;&#160;</a></span>Sign()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Sign </td>
          <td>(</td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>heaviside</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the sign function element-wise. </p>
<p>Returns a new tensor where each element is:</p><ul>
<li>1.0 if the original element is positive</li>
<li>-1.0 if the original element is negative</li>
<li>0.0 if the original element is approximately zero (|x| &lt; epsilon  EPSILON_SCALE)</li>
</ul>
<p>If the Heaviside step function mode is enabled, zero values are mapped to 1.0 instead of 0.0.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">heaviside</td><td>If true, uses Heaviside step function (maps 0  1). If false, uses standard sign function (maps 0  0). Default is false.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing sign values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="a7183546c868b2cac8075f0434376dccb" name="a7183546c868b2cac8075f0434376dccb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7183546c868b2cac8075f0434376dccb">&#9670;&#160;</a></span>Sin()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Sin </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the sine of each element (in radians). </p>
<p>Returns a new tensor where each element is the sine of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The sine function maps any real number to the range [-1, 1] and is periodic with period 2.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing sine values in the range [-1, 1].</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by /180. </dd></dl>

</div>
</div>
<a id="a2cbc29f90925cf18d54d62d9cc6ebbe3" name="a2cbc29f90925cf18d54d62d9cc6ebbe3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2cbc29f90925cf18d54d62d9cc6ebbe3">&#9670;&#160;</a></span>Sinh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Sinh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic sine of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic sine of the corresponding element in the original tensor. The hyperbolic sine is defined as: sinh(x) = (e^x - e^(-x)) / 2</p>
<p>The hyperbolic sine function is defined for all real numbers and is an odd function.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic sine values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="acdf40158e4bd7edd14f59bfc2c52ff92" name="acdf40158e4bd7edd14f59bfc2c52ff92"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdf40158e4bd7edd14f59bfc2c52ff92">&#9670;&#160;</a></span>Slice() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Slice </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extracts a slice of the <a class="el" href="class_tensor.html">Tensor</a> along a specified axis at a given index. </p>
<p>This method returns a new <a class="el" href="class_tensor.html">Tensor</a> representing a lower-rank slice of the current <a class="el" href="class_tensor.html">Tensor</a>, taken along the specified axis at a particular index position. The operation performs a deep copy of the relevant data region, so the resulting <a class="el" href="class_tensor.html">Tensor</a> is completely independent of the original.</p>
<p>The rank of the returned <a class="el" href="class_tensor.html">Tensor</a> is <span class="tt">rank - 1</span>, as the specified axis is removed. For example, slicing a (2, 3, 4) tensor along axis 1 at index 0 produces a (2, 4) tensor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to slice. Must satisfy: <span class="tt">0  axis &lt; rank</span>. </td></tr>
    <tr><td class="paramname">index</td><td>The index position along the given axis to extract. Must satisfy: <span class="tt">0  index &lt; shape[axis]</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> slice with one fewer dimension (rank reduced by 1).</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if:<ul>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is empty (volume = 0).</li>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is a scalar (rank = 0).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li>The axis is negative or &gt;= rank.</li>
<li>The index is negative or &gt;= shape[axis].</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a copy-based operation. The returned <a class="el" href="class_tensor.html">Tensor</a> has its own independent data buffer and does not share memory with the original.</dd>
<dd>
This operation efficiently extracts non-contiguous data using stride information. </dd></dl>

</div>
</div>
<a id="ad2a6207e2f4dcb9571e4530490fcd439" name="ad2a6207e2f4dcb9571e4530490fcd439"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2a6207e2f4dcb9571e4530490fcd439">&#9670;&#160;</a></span>Slice() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Slice </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index_from</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>index_upto</em></span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extracts a range of slices from the <a class="el" href="class_tensor.html">Tensor</a> along a given axis. </p>
<p>This method performs slicing between two indices (<span class="tt">index_from</span> inclusive and <span class="tt">index_upto</span> exclusive) along the specified axis. Each individual slice is extracted using the single-index <span class="tt"><a class="el" href="#acdf40158e4bd7edd14f59bfc2c52ff92" title="Extracts a slice of the Tensor along a specified axis at a given index.">Slice()</a></span> method, and the results are stacked together along the same axis to form a contiguous sub-tensor.</p>
<p>The rank of the returned <a class="el" href="class_tensor.html">Tensor</a> remains the same as the original. The dimension along the specified axis is reduced to <span class="tt">index_upto - index_from</span>.</p>
<p>Like single-index slicing, this is a <b>copy-based</b> operation resulting in an independent <a class="el" href="class_tensor.html">Tensor</a> with no shared data.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">axis</td><td>The axis along which to slice. Must satisfy: <span class="tt">0  axis &lt; rank</span>.</td></tr>
    <tr><td class="paramname">index_from</td><td>The starting index (inclusive) along the axis. Must satisfy: <span class="tt">0  index_from &lt; index_upto</span>.</td></tr>
    <tr><td class="paramname">index_upto</td><td>The ending index (exclusive) along the axis. Must satisfy: <span class="tt">index_from &lt; index_upto  shape[axis]</span>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> formed by stacking the specified slices along the same axis.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if:<ul>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is empty (volume = 0).</li>
<li>The <a class="el" href="class_tensor.html">Tensor</a> is a scalar (rank = 0).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li>The axis is negative or &gt;= rank.</li>
<li><span class="tt">index_from</span> is negative or <span class="tt">index_upto</span> is &gt; shape[axis].</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if <span class="tt">index_from &gt;= index_upto</span> (invalid range specification).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a copy-based operation. The returned <a class="el" href="class_tensor.html">Tensor</a> has its own independent data buffer.</dd>
<dd>
Internally, this method calls <span class="tt">Slice(axis, index)</span> for each index in the range and uses <span class="tt"><a class="el" href="#a7d2ad35ec705991518a2ecbec8ffd318" title="Stacks multiple Tensors along a new dimension.">Stack()</a></span> to combine them. </dd></dl>

</div>
</div>
<a id="a4c7df16dc4a4fc10cbdf5bfa20e25ba7" name="a4c7df16dc4a4fc10cbdf5bfa20e25ba7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c7df16dc4a4fc10cbdf5bfa20e25ba7">&#9670;&#160;</a></span>Sqrt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Sqrt </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the square root of each element. </p>
<p>Returns a new tensor where each element is the square root of the corresponding element in the original tensor. This is equivalent to raising each element to the power of 0.5.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing square root values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is negative (square root undefined for negative reals).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
For negative values, consider using <a class="el" href="#aa9330e265d36beb2e217c75f6a03a41e" title="Computes the absolute value of each element.">Abs()</a> first if magnitude is desired. </dd></dl>

</div>
</div>
<a id="a7d2ad35ec705991518a2ecbec8ffd318" name="a7d2ad35ec705991518a2ecbec8ffd318"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d2ad35ec705991518a2ecbec8ffd318">&#9670;&#160;</a></span>Stack()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Stack </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="class_tensor.html">Tensor</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensors</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel static">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Stacks multiple Tensors along a new dimension. </p>
<p>This static method combines a vector of Tensors by introducing a new axis at the specified position. Unlike concatenation (which joins along an existing axis), stacking creates a new dimension and increases the rank by 1.</p>
<p>All input tensors must have identical shapes. Each tensor is first expanded to include a new dimension of size 1 at the specified axis position using <a class="el" href="#aa5215a8751f54d02e66b38c4982537f9" title="Expands the rank of the Tensor by inserting a dimension of size 1 at a specified axis.">ExpandRank()</a>, then all expanded tensors are concatenated along that new axis.</p>
<p>The resulting tensor has rank = <span class="tt">original_rank + 1</span>, with the new dimension's size equal to the number of tensors being stacked.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensors</td><td>A vector of Tensors to stack. Must not be empty. All tensors must have identical shapes.</td></tr>
    <tr><td class="paramname">axis</td><td>The position where the new dimension will be inserted. Must satisfy: <span class="tt">0  axis  rank</span>. Default is 0 (stack along the outermost dimension).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with rank increased by 1, containing all stacked tensors.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The tensors vector is empty.</li>
<li>Tensors have different shapes (all shapes must match exactly).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>if:<ul>
<li>The axis is negative.</li>
<li>The axis is greater than the tensors' rank.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a static method - call it as <span class="tt"><a class="el" href="#a7d2ad35ec705991518a2ecbec8ffd318" title="Stacks multiple Tensors along a new dimension.">Tensor::Stack</a>({t1, t2, t3})</span>.</dd>
<dd>
Internally, this method expands each tensor's rank at the specified axis, then concatenates them using <a class="el" href="#a4d525a3d5051c3a704db5a254b654706" title="Concatenates multiple Tensors along a specified axis.">Concat()</a>. </dd></dl>

</div>
</div>
<a id="adb9ce076a4629b3bbc897e17f39b7573" name="adb9ce076a4629b3bbc897e17f39b7573"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb9ce076a4629b3bbc897e17f39b7573">&#9670;&#160;</a></span>Sum()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Tensor::Sum </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the sum of all elements in the tensor. </p>
<p>Returns the sum of all elements as a scalar value. This is a global reduction operation across the entire tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The sum of all elements.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a8148f97acf80f5e6aa685544ecc22be2" name="a8148f97acf80f5e6aa685544ecc22be2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8148f97acf80f5e6aa685544ecc22be2">&#9670;&#160;</a></span>Tan()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Tan </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the tangent of each element (in radians). </p>
<p>Returns a new tensor where each element is the tangent of the corresponding element in the original tensor. The input is interpreted as angles in radians.</p>
<p>The tangent function is undefined at odd multiples of /2 (where cosine equals zero) and has vertical asymptotes at these points.</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing tangent values.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0). </td></tr>
    <tr><td class="paramname">std::domain_error</td><td>if any element is approximately an odd multiple of /2 (where tangent is undefined).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The input is interpreted as radians. To convert degrees to radians, multiply by /180. </dd></dl>

</div>
</div>
<a id="aee8ad1fde49129b199ad87b4dd85c07f" name="aee8ad1fde49129b199ad87b4dd85c07f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee8ad1fde49129b199ad87b4dd85c07f">&#9670;&#160;</a></span>Tanh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Tanh </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the hyperbolic tangent of each element. </p>
<p>Returns a new tensor where each element is the hyperbolic tangent of the corresponding element in the original tensor. The hyperbolic tangent is defined as: tanh(x) = sinh(x) / cosh(x) = (e^x - e^(-x)) / (e^x + e^(-x))</p>
<p>The hyperbolic tangent function is defined for all real numbers, is an odd function, and has range (-1, 1).</p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the same shape containing hyperbolic tangent values in the range (-1, 1).</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged. </dd></dl>

</div>
</div>
<a id="abde6f09589147296a9035bce10cc8c49" name="abde6f09589147296a9035bce10cc8c49"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abde6f09589147296a9035bce10cc8c49">&#9670;&#160;</a></span>TensorDot()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::TensorDot </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor_1</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_tensor.html">Tensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor_2</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>contract_axes_1</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>contract_axes_2</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel static">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs generalized tensor contraction over specified axes. </p>
<p>TensorDot computes a generalized dot product by contracting (summing over) specified axes of two tensors. The contracted axes must have matching dimensions and are paired in order: contract_axes_1[i] contracts with contract_axes_2[i].</p>
<p>This is a generalization of matrix multiplication, where you can choose which axes to contract. The contracted axes disappear from the result, and the remaining axes from both tensors are concatenated: [remaining_axes_1, remaining_axes_2].</p>
<p>Mathematical formulation: </p><div class="fragment"><div class="line">result[i,j,...,m,n,...] =  tensor_1[i,j,...,k,k,...]  tensor_2[k,k,...,m,n,...]</div>
<div class="line">                           k,k,...</div>
</div><!-- fragment --><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor_1</td><td>The first tensor. </td></tr>
    <tr><td class="paramname">tensor_2</td><td>The second tensor. </td></tr>
    <tr><td class="paramname">contract_axes_1</td><td>Axes of tensor_1 to contract. Must contain unique values in range [0, rank_1). </td></tr>
    <tr><td class="paramname">contract_axes_2</td><td>Axes of tensor_2 to contract. Must contain unique values in range [0, rank_2).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with contracted axes removed and remaining axes concatenated.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>if any axis index is negative or &gt;= tensor rank. </td></tr>
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>Either contract_axes vector contains duplicate values.</li>
<li>The number of axes to contract doesn't match (contract_axes_1.size() != contract_axes_2.size()).</li>
<li>Paired axes have different dimensions (tensor_1.shape[contract_axes_1[i]] != tensor_2.shape[contract_axes_2[i]]).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Axes are contracted pairwise in order: contract_axes_1[i] contracts with contract_axes_2[i]. </dd>
<dd>
Empty axes vectors are valid and result in an outer product (no contraction). </dd>
<dd>
This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. Input tensors remain unchanged. </dd></dl>

</div>
</div>
<a id="a52b3acaaf5f1d9bad285fd7ae88399ac" name="a52b3acaaf5f1d9bad285fd7ae88399ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a52b3acaaf5f1d9bad285fd7ae88399ac">&#9670;&#160;</a></span>Tile()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Tile </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>repetitions</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Repeats the entire tensor structure along each axis a specified number of times. </p>
<p>This method creates a new <a class="el" href="class_tensor.html">Tensor</a> by replicating the current tensor along each dimension. The repetitions vector specifies how many times to tile along each axis. The resulting tensor has shape <span class="tt">new_shape[i] = original_shape[i] * repetitions[i]</span> for each axis i.</p>
<p>Unlike element-wise repetition, tiling repeats the entire structure as a block. For example, tiling [1,2,3] twice results in [1,2,3,1,2,3], not [1,1,2,2,3,3].</p>
<p>The operation proceeds from the innermost dimension (last axis) to the outermost (first axis), using concatenation to build up the tiled result incrementally.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">repetitions</td><td>A vector specifying the number of repetitions along each axis. Must have the same length as the tensor's rank. All values must be positive (&gt; 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with the tiled structure.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The repetitions vector size does not match the tensor's rank.</li>
<li>Any repetition value is non-positive ( 0).</li>
</ul>
</td></tr>
    <tr><td class="paramname">std::overflow_error</td><td>if:<ul>
<li>The product of repetitions exceeds INT_MAX.</li>
<li>The resulting total volume exceeds INT_MAX.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original <a class="el" href="class_tensor.html">Tensor</a> is unchanged.</dd>
<dd>
The total volume of the result is <span class="tt">original_volume  product(repetitions)</span>.</dd>
<dd>
For large tensors and many repetitions, this operation can be memory-intensive. </dd></dl>

</div>
</div>
<a id="abd4b0bfabe2a7c378318d6132ec84936" name="abd4b0bfabe2a7c378318d6132ec84936"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd4b0bfabe2a7c378318d6132ec84936">&#9670;&#160;</a></span>ToMatrix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::vector&lt; double &gt; &gt; Tensor::ToMatrix </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Converts a rank-2 tensor to a 2D vector (matrix). </p>
<p>Extracts all elements from a rank-2 tensor and returns them as a nested std::vector&lt;std::vector&lt;double&gt;&gt;. This is useful for interfacing with standard C++ code that expects 2D arrays or matrices.</p>
<p>The outer vector represents rows, and each inner vector represents the columns of that row.</p>
<dl class="section return"><dt>Returns</dt><dd>A 2D vector containing all tensor elements organized by rows and columns.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is not rank-2 (not a matrix).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This creates a copy of the data. The original tensor is unchanged. </dd>
<dd>
Works correctly with sliced tensors (uses start and stride information). </dd></dl>

</div>
</div>
<a id="ad3b998f18ac3263bf5e02b88026a166f" name="ad3b998f18ac3263bf5e02b88026a166f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3b998f18ac3263bf5e02b88026a166f">&#9670;&#160;</a></span>ToScalar()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Tensor::ToScalar </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Converts a scalar tensor to a double value. </p>
<p>Extracts and returns the single value from a rank-0 (scalar) tensor. This method only works on tensors with rank 0 and volume 1.</p>
<dl class="section return"><dt>Returns</dt><dd>The scalar value as a double.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is not a scalar (rank &gt; 0 or volume != 1).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This is a convenience method for extracting scalar values from scalar tensors. </dd></dl>

</div>
</div>
<a id="a577b089b89971b6ab7a1bfab790e4edc" name="a577b089b89971b6ab7a1bfab790e4edc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a577b089b89971b6ab7a1bfab790e4edc">&#9670;&#160;</a></span>ToVector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; double &gt; Tensor::ToVector </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Converts a rank-1 tensor to a standard vector. </p>
<p>Extracts all elements from a rank-1 tensor and returns them as a std::vector&lt;double&gt;. This is useful for interfacing with standard C++ code that expects vectors.</p>
<dl class="section return"><dt>Returns</dt><dd>A std::vector&lt;double&gt; containing all tensor elements in order.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is not rank-1 (not a vector).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This creates a copy of the data. The original tensor is unchanged. </dd>
<dd>
Works correctly with sliced tensors (uses start and end indices). </dd></dl>

</div>
</div>
<a id="a699a4b1ec7d7d244e7c10643bf533f98" name="a699a4b1ec7d7d244e7c10643bf533f98"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a699a4b1ec7d7d244e7c10643bf533f98">&#9670;&#160;</a></span>Transpose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_tensor.html">Tensor</a> Tensor::Transpose </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>permutation</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Transposes (permutes) the tensor's axes according to a specified permutation. </p>
<p>This method rearranges the tensor's dimensions by permuting its axes according to the provided permutation vector. Each element in the permutation specifies which original axis should be placed at that position in the result.</p>
<p>For example, permutation {1, 0, 2} swaps the first two axes while keeping the third axis unchanged. This is a generalization of matrix transpose to arbitrary dimensions.</p>
<p>The operation creates a new tensor with reordered dimensions and rearranged data to match the new axis order.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">permutation</td><td>A vector specifying the new order of axes. Must have length equal to the tensor's rank. Must be a valid permutation: contain each value from 0 to (rank-1) exactly once.<ul>
<li>permutation[i] = j means the j-th axis of the original tensor becomes the i-th axis of the result.</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="class_tensor.html">Tensor</a> with permuted axes and reordered data.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if:<ul>
<li>The permutation size does not match the tensor's rank.</li>
<li>The permutation contains negative values.</li>
<li>The permutation contains values &gt;= rank.</li>
<li>The permutation contains duplicate values (not a valid permutation).</li>
</ul>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>This operation creates a new independent <a class="el" href="class_tensor.html">Tensor</a>. The original tensor is unchanged.</dd>
<dd>
The data is physically reordered to match the new axis layout, making subsequent access efficient. </dd></dl>

</div>
</div>
<a id="ac9b2a793615586ac29b2e7215261b844" name="ac9b2a793615586ac29b2e7215261b844"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9b2a793615586ac29b2e7215261b844">&#9670;&#160;</a></span>UniqueData()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Tensor::UniqueData </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Ensures this <a class="el" href="class_tensor.html">Tensor</a> has unique ownership of its data buffer. </p>
<p>If the underlying data buffer is shared with other <a class="el" href="class_tensor.html">Tensor</a> objects (use_count() &gt; 1), this method creates an independent copy of the data range [start, end) and detaches from the shared buffer. After this call, modifications to this <a class="el" href="class_tensor.html">Tensor</a>'s data will not affect any other <a class="el" href="class_tensor.html">Tensor</a>.</p>
<p>If the <a class="el" href="class_tensor.html">Tensor</a> already has unique ownership (use_count() == 1) or is empty, this method does nothing.</p>
<dl class="section note"><dt>Note</dt><dd>This method is called internally before in-place modifications to ensure safe data manipulation without affecting other tensors that may share the buffer.</dd>
<dd>
After calling this method, start is reset to 0 and end is set to volume, ensuring the tensor represents the complete data range.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">None</td><td> this method never throws exceptions.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd>SetSlice(), SetSliceChain(), AppendInplace() </dd></dl>

</div>
</div>
<a id="aceb3777b0c462d3596781b6031a234b6" name="aceb3777b0c462d3596781b6031a234b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aceb3777b0c462d3596781b6031a234b6">&#9670;&#160;</a></span>Var()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Tensor::Var </td>
          <td>(</td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>inference</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the variance of all elements in the tensor. </p>
<p>Returns the variance of all elements as a scalar value. Variance measures how spread out the values are from their mean. This is a global reduction operation across the entire tensor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inference</td><td>If true, uses Bessel's correction (divides by n-1 for sample variance). If false, divides by n (population variance). Default is false.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The variance of all elements.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if the tensor is empty (volume = 0).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Formula: Var = sum((x - mean)) / n (or n-1 if inference=true) </dd></dl>

</div>
</div>
<a id="ad7155b38d35344550fde1eeb7f0fbd61" name="ad7155b38d35344550fde1eeb7f0fbd61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad7155b38d35344550fde1eeb7f0fbd61">&#9670;&#160;</a></span>Volume()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Tensor::Volume </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the total number of elements (volume) in the tensor. </p>
<p>The volume is the product of all dimensions in the tensor's shape. It represents the total count of scalar values stored in the tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>The total number of elements as an integer.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>For an empty tensor and scalar tensor, this returns 0. </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li><a class="el" href="_tensor_8h_source.html">Tensor.h</a></li>
<li><b>Tensor.cpp</b></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="class_tensor.html">Tensor</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
